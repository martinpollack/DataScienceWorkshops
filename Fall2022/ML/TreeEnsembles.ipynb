{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JPYaq5eWQ4n"
      },
      "source": [
        "# Tree Ensembles\n",
        "### Workshop 2 of DASIL's series on \"Introduction to Machine Learning\"\n",
        "### Created by Martin Pollack, Yusen He, and Declan O'Reilly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0FGuCgcWQ4p"
      },
      "source": [
        "In this Jupyter notebook we will teach you how to fit the machine learning models we talked about today in the lecture using the `scikit-learn` package in Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B4_h-5j_Wqc"
      },
      "source": [
        "All of our example datasets come from the `datasets` sub-package within `scikit-learn`. So we import them now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UiT01kfZWQ4q"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SarBlYm2WQ4x"
      },
      "source": [
        "## Supervised Learning - Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULypkTWU9hEp"
      },
      "source": [
        "#### Dataset Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29YqLUpTWQ4z"
      },
      "source": [
        "Again, we will look at a classification problem, where the outcome can only take on 2 or more discrete values. But of course our predictors can be either continuous or discrete.\n",
        "\n",
        "Now we use `scikit-learn`'s breast cancer dataset. Here the outcome can take on a 0, for no breast cancer, or 1, for breast cancer. \n",
        "\n",
        "So in this case we actually have a *binary classification* problem, meaning our category can only take on 2 discrete values. In most binary classification problems, like in this case, the categories are 0 and 1 indiciating the presence or absence of some trait."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Jmrv4VMWQ41"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "breast_cancer = load_breast_cancer(as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZau-rgMWQ41",
        "outputId": "9bdfadbc-4068-4302-f45a-b8635c2671a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    357\n",
              "0    212\n",
              "Name: target, dtype: int64"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "breast_cancer.target.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6Kl5F0QBtSa"
      },
      "source": [
        "The `breast cancer` dataset contains 30 predictive variables. For example:\n",
        "\n",
        "\n",
        "\n",
        "*    radius (mean of distances from center to points on the perimeter)\n",
        "\n",
        "*    texture (standard deviation of gray-scale values)\n",
        "\n",
        "*    perimeter\n",
        "\n",
        "*    area\n",
        "\n",
        "*    smoothness (local variation in radius lengths)\n",
        "\n",
        "*    compactness (perimeter^2 / area - 1.0)\n",
        "\n",
        "*    concavity (severity of concave portions of the contour)\n",
        "\n",
        "*    concave points (number of concave portions of the contour)\n",
        "\n",
        "*    symmetry\n",
        "\n",
        "*    fractal dimension (“coastline approximation” - 1)\n",
        "\n",
        "\n",
        "\n",
        "The mean, standard error, and “worst” or largest (mean of the three worst/largest values) of these features were computed for each image, resulting in 30 features. For instance, field 0 is Mean Radius, field 10 is Radius SE, field 20 is Worst Radius.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "NU-R05ZjXEbr",
        "outputId": "0f2977d9-51a3-4893-9fa2-f2d6b8884e45"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "0                   0.07871  ...        25.380          17.33   \n",
              "1                   0.05667  ...        24.990          23.41   \n",
              "2                   0.05999  ...        23.570          25.53   \n",
              "3                   0.09744  ...        14.910          26.50   \n",
              "4                   0.05883  ...        22.540          16.67   \n",
              "..                      ...  ...           ...            ...   \n",
              "564                 0.05623  ...        25.450          26.40   \n",
              "565                 0.05533  ...        23.690          38.25   \n",
              "566                 0.05648  ...        18.980          34.12   \n",
              "567                 0.07016  ...        25.740          39.42   \n",
              "568                 0.05884  ...         9.456          30.37   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "0             184.60      2019.0           0.16220            0.66560   \n",
              "1             158.80      1956.0           0.12380            0.18660   \n",
              "2             152.50      1709.0           0.14440            0.42450   \n",
              "3              98.87       567.7           0.20980            0.86630   \n",
              "4             152.20      1575.0           0.13740            0.20500   \n",
              "..               ...         ...               ...                ...   \n",
              "564           166.10      2027.0           0.14100            0.21130   \n",
              "565           155.00      1731.0           0.11660            0.19220   \n",
              "566           126.70      1124.0           0.11390            0.30940   \n",
              "567           184.60      1821.0           0.16500            0.86810   \n",
              "568            59.16       268.6           0.08996            0.06444   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "0             0.7119                0.2654          0.4601   \n",
              "1             0.2416                0.1860          0.2750   \n",
              "2             0.4504                0.2430          0.3613   \n",
              "3             0.6869                0.2575          0.6638   \n",
              "4             0.4000                0.1625          0.2364   \n",
              "..               ...                   ...             ...   \n",
              "564           0.4107                0.2216          0.2060   \n",
              "565           0.3215                0.1628          0.2572   \n",
              "566           0.3403                0.1418          0.2218   \n",
              "567           0.9387                0.2650          0.4087   \n",
              "568           0.0000                0.0000          0.2871   \n",
              "\n",
              "     worst fractal dimension  \n",
              "0                    0.11890  \n",
              "1                    0.08902  \n",
              "2                    0.08758  \n",
              "3                    0.17300  \n",
              "4                    0.07678  \n",
              "..                       ...  \n",
              "564                  0.07115  \n",
              "565                  0.06637  \n",
              "566                  0.07820  \n",
              "567                  0.12400  \n",
              "568                  0.07039  \n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "breast_cancer.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnasUbL_9xOg"
      },
      "source": [
        "#### Define the predictor variable set and a target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQALRlB997O7"
      },
      "source": [
        "For the regression tasks, a feature set `X` and a target set `y` need to be defined first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eWj12b_r98X8"
      },
      "outputs": [],
      "source": [
        "X = breast_cancer.data\n",
        "Y = breast_cancer.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56eOA-Y_9lcz"
      },
      "source": [
        "#### Split the dataset into training and test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89bteG4dHsXY"
      },
      "source": [
        "We can use the `sklearn.model_selection.train_test_split()` function to do the random split for the training and testing dataset.\n",
        "\n",
        "We just pass our input and output data, the proportion of the dataset that should go in the testing dataset, and here, `stratify` assures that the testing dataset has equal numbers of 0's and 1's in the outcome."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HU4MmjqLHtaQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3, stratify=Y,  random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Random Forest for Binary Classification"
      ],
      "metadata": {
        "id": "w3p6WpHu-xBo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first ensemble model we will try is a random forest.\n",
        "\n",
        "We start by importing the model we want.\n",
        "\n",
        "Then, let's see what hyperparameters we have to consider when creating our random forest."
      ],
      "metadata": {
        "id": "luF3cD_n-6p4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "RandomForestClassifier().get_params()"
      ],
      "metadata": {
        "id": "AKAWMkYL_R45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now go ahead and fit a random forest!\n",
        "\n",
        "Like on Tuesday, all we have to do is create the model object and then fit it with data. Remember, however, that the default hyperparameters are used."
      ],
      "metadata": {
        "id": "hTBPA008_gy6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_rf = RandomForestClassifier(random_state=0)\n",
        "\n",
        "classifier_rf.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "vhCEP4IJ_etI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our `classifier_rfc` object has been created and fit, we can get information about our random forest model.\n",
        "\n",
        "To see its accuracy, we can call the score method on the object and pass in data to use for the scoring. Below we calculate the accuracy for both the training and testing datasets."
      ],
      "metadata": {
        "id": "P_URavGn_3mB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy for training dataset:\")\n",
        "print(classifier_rf.score(X_train, Y_train))\n",
        "print(\"Accuracy for testing dataset:\")\n",
        "print(classifier_rf.score(X_test, Y_test))"
      ],
      "metadata": {
        "id": "M168TtojALnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These results seem fine, but we could get better results if we find better values for the hyperparameters, or if we \"tune\" the hyperparameters.\n",
        "\n",
        "We now introduce one way to tune hyperparameters using `GridSearchCV`. We can list explicit values to try for each hyperparameter, and then scikit-learn will fit a model with each combination of hyperparameters. Using cross validation, we can then find the combination that delivers the best results and use that as our final model.\n",
        "\n",
        "This process is shown below."
      ],
      "metadata": {
        "id": "Ea5ZPp_QBcue"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "tuned_rf = RandomForestClassifier(random_state=0)\n",
        "parameters = {'max_depth':[1, 2, 3, 5], 'min_impurity_decrease':[0, 0.01, 0.1, 0.2]}\n",
        "classifier_rf_tuned_grid = GridSearchCV(tuned_rf, parameters)\n",
        "\n",
        "classifier_rf_tuned_grid.fit(X_train, Y_train)"
      ],
      "metadata": {
        "id": "Ylv04OQ7CLcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see the best combination of hyperparameters, we can access the `best_estimator_` field of our fitted object `regressor_rf_tuned_grid`. \n",
        "\n",
        "Then, if we use our fit `GridSearchCV` object to calculate the score from data, the best model will be considered."
      ],
      "metadata": {
        "id": "nCrYfzfXDZkX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classifier_rf_tuned_grid.best_params_)\n",
        "print(\"Training R-squared:\")\n",
        "print(classifier_rf_tuned_grid.score(X_train, Y_train))\n",
        "print(\"Testing R-squared:\")\n",
        "print(classifier_rf_tuned_grid.score(X_test, Y_test))"
      ],
      "metadata": {
        "id": "eW5YZnk2DXHm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, if we use our object to predict the outcomes of new input data, the best model will be used to do this."
      ],
      "metadata": {
        "id": "eIcTIgGOEK-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rf_pred = classifier_rf_tuned_grid.predict(X_test)"
      ],
      "metadata": {
        "id": "KRCC89HNEQcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elJ87AHnKp0t"
      },
      "source": [
        "#### XGBoost for Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoavtYx4_WrN"
      },
      "source": [
        "The next classification model we will try is XGBoost, considered one of the best models out there.\n",
        "\n",
        "Again we start by seeing what hyperparameters we can possibly tune."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yvLrjCf_WrN",
        "outputId": "0c7a6b01-ef06-40c7-bcb4-9db4bcbabd07"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'ccp_alpha': 0.0,\n",
              " 'criterion': 'friedman_mse',\n",
              " 'init': None,\n",
              " 'learning_rate': 0.1,\n",
              " 'loss': 'deviance',\n",
              " 'max_depth': 3,\n",
              " 'max_features': None,\n",
              " 'max_leaf_nodes': None,\n",
              " 'min_impurity_decrease': 0.0,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'min_weight_fraction_leaf': 0.0,\n",
              " 'n_estimators': 100,\n",
              " 'n_iter_no_change': None,\n",
              " 'random_state': None,\n",
              " 'subsample': 1.0,\n",
              " 'tol': 0.0001,\n",
              " 'validation_fraction': 0.1,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "GradientBoostingClassifier().get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX6uFoxntutW"
      },
      "source": [
        "Now let's create a model with specific hyperparameters. We will name it as `classifier_XGB`.\n",
        "\n",
        "Again, we start by creating the model object. Then we fit it. Then we can get the score both for the training and testing dataset.\n",
        "\n",
        "Notice that the \"score\" of our model is the overall accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apugvOWmtt8G",
        "outputId": "09c94242-e227-4dec-f6d8-9fedce599f6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for training dataset:\n",
            "0.9949748743718593\n",
            "Accuracy for testing dataset:\n",
            "0.9590643274853801\n"
          ]
        }
      ],
      "source": [
        "classifier_XGB = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,max_depth=1, random_state=0)\n",
        "\n",
        "classifier_XGB.fit(X_train, Y_train)\n",
        "\n",
        "print(\"Accuracy for training dataset:\")\n",
        "print(classifier_XGB.score(X_train, Y_train))\n",
        "print(\"Accuracy for testing dataset:\")\n",
        "print(classifier_XGB.score(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvJDUYxk_WrO"
      },
      "source": [
        "But again we probably want to do some hyperparameter tuning.\n",
        "\n",
        "The second main way to do this is `RandomizedSearchCV()`. Here we give distributions for our hyperparameters instead of specific values. Python will then randomly choose hyperparameters to try based on the given distributions.\n",
        "\n",
        "For example, for XGBoost we will use a normal distribution with mean of 0.5 and standard deviation of 0.1 for the \"minimum impurity decrease\". This means we will mostly try values close to 0.5, but occasionally some further from 0.5. We will then consider a uniform distribution for learning rate between 0 and 1, meaning any number in this range is equally likely to be chosen. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A0jgh8n-_WrO"
      },
      "outputs": [],
      "source": [
        "XGB = GradientBoostingClassifier(n_estimators=100)\n",
        "\n",
        "from scipy.stats import norm, uniform\n",
        "distributions = {\"min_impurity_decrease\":norm(loc=0.5, scale=0.1), \"learning_rate\":uniform(loc=0.5, scale=0.5)}\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "classifier_XGB_tuned_random = RandomizedSearchCV(XGB, distributions, n_iter=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ga87hbM_WrQ"
      },
      "source": [
        "Now we fit our `RandomizedSearchCV` object. Since `n_iter` is 10 above, we will grab 10 combinations of hyperparameters from our two distributions. Then we will fit an XGBoost model for each combination, Python choosing the best one for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOBVHyUC_WrQ",
        "outputId": "c6392c04-ab40-4324-c703-ebcf4ada5da2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'learning_rate': 0.6462933398888173, 'min_impurity_decrease': 0.5342229738705377}\n",
            "Accuracy for training dataset:\n",
            "0.9849246231155779\n",
            "Accuracy for testing dataset:\n",
            "0.9239766081871345\n"
          ]
        }
      ],
      "source": [
        "classifier_XGB_tuned_random.fit(X_train, Y_train)\n",
        "XGB_pred = classifier_XGB_tuned_random.predict(X_test)\n",
        "\n",
        "print(classifier_XGB_tuned_random.best_params_)\n",
        "print(\"Accuracy for training dataset:\")\n",
        "print(classifier_XGB_tuned_random.score(X_train, Y_train))\n",
        "print(\"Accuracy for testing dataset:\")\n",
        "print(classifier_XGB_tuned_random.score(X_test, Y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1fxh88pvQzj"
      },
      "source": [
        "#### Further Performance Assessment using Testing Data\n",
        "\n",
        "*   Confusion Matrix\n",
        "*   Accuracy\n",
        "*   Sensitivity\n",
        "*   Specificity\n",
        "*   AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzFKn04NEh3e"
      },
      "source": [
        "Next we assess our Random Forest:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "outputId": "e7f0a179-90e6-4843-c06c-898aeb2c7bc7",
        "id": "peGYi4BZEh3f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix for XGB: \n",
            " [[ 56   8]\n",
            " [  5 102]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#Compute the confusion matrix\n",
        "cmRF = confusion_matrix(Y_test,rf_pred)\n",
        "print('Confusion Matrix for rf: \\n', cmRF)\n",
        "\n",
        "#Plot the confusion matrix using seaborn\n",
        "import seaborn as sns\n",
        "sns.heatmap(cmRF, annot=True,fmt=\"d\", cmap=\"YlGnBu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12b1f99b-89ca-4bb4-90d9-4de94eeae55b",
        "id": "Z6v5FuhhEh3g"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for XGB:  0.9239766081871345\n",
            "Specificity for XGB:  0.9532710280373832\n",
            "Sensitivity for XGB:  0.875\n"
          ]
        }
      ],
      "source": [
        "#Compute total test cases\n",
        "totalRF=sum(sum(cmRF))\n",
        "#####from confusion matrix calculate accuracy\n",
        "accuracyRF=(cmRF[0,0]+cmRF[1,1])/totalRF\n",
        "print ('Accuracy for Random Forest: ', accuracyRF)\n",
        "\n",
        "sensitivityRF = cmRF[1,1]/(cmRF[1,0]+cmRF[1,1])\n",
        "print('Specificity for Random Forest: ', sensitivityRF)\n",
        "\n",
        "specificityRF = cmRF[0,0]/(cmRF[0,0]+cmRF[0,1])\n",
        "print('Sensitivity for Random Forest: ', specificityRF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-S68sfWmEh3g"
      },
      "source": [
        "Then, we compute the AUC. We use the `roc_auc_score` from `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ca8b341e-4e8c-4961-de5c-a452f4facc34",
        "id": "LHVfQ2O_Eh3g"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC for XGB:  0.9763434579439252\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#We first compute the probability output from the Random Forest classifier\n",
        "RF_prob = classifier_rf_tuned_grid.predict_proba(X_test)\n",
        "\n",
        "#We compute the AUC score\n",
        "aucRF = roc_auc_score(Y_test,RF_prob[:,1])\n",
        "print('AUC for Random Forest: ', aucRF)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDaIRwwW4BZi"
      },
      "source": [
        "Next we assess XGBoost:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "sqsmOh8fz9Gn",
        "outputId": "e7f0a179-90e6-4843-c06c-898aeb2c7bc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix for XGB: \n",
            " [[ 56   8]\n",
            " [  5 102]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<AxesSubplot:>"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#Compute the confusion matrix\n",
        "cmXGB = confusion_matrix(Y_test,XGB_pred)\n",
        "print('Confusion Matrix for XGB: \\n', cmXGB)\n",
        "\n",
        "#Plot the confusion matrix using seaborn\n",
        "import seaborn as sns\n",
        "sns.heatmap(cmXGB, annot=True,fmt=\"d\", cmap=\"YlGnBu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ7FFlnwElfz",
        "outputId": "12b1f99b-89ca-4bb4-90d9-4de94eeae55b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for XGB:  0.9239766081871345\n",
            "Specificity for XGB:  0.9532710280373832\n",
            "Sensitivity for XGB:  0.875\n"
          ]
        }
      ],
      "source": [
        "#Compute total test cases\n",
        "totalXGB=sum(sum(cmXGB))\n",
        "#####from confusion matrix calculate accuracy\n",
        "accuracyXGB=(cmXGB[0,0]+cmXGB[1,1])/totalXGB\n",
        "print ('Accuracy for XGB: ', accuracyXGB)\n",
        "\n",
        "sensitivityXGB = cmXGB[1,1]/(cmXGB[1,0]+cmXGB[1,1])\n",
        "print('Specificity for XGB: ', sensitivityXGB)\n",
        "\n",
        "specificityXGB = cmXGB[0,0]/(cmXGB[0,0]+cmXGB[0,1])\n",
        "print('Sensitivity for XGB: ', specificityXGB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ekaseon1kDu"
      },
      "source": [
        "Then, we compute the AUC. We use the `roc_auc_score` from `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8eqsAS210uf",
        "outputId": "ca8b341e-4e8c-4961-de5c-a452f4facc34"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC for XGB:  0.9763434579439252\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#We first compute the probability output from the SVM classifier\n",
        "XGB_prob = classifier_XGB_tuned_random.predict_proba(X_test)\n",
        "\n",
        "#We compute the AUC score\n",
        "aucXGB = roc_auc_score(Y_test,XGB_prob[:,1])\n",
        "print('AUC for XGB: ', aucXGB)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6e5r4Un57I2-"
      ],
      "provenance": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}