{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JPYaq5eWQ4n"
      },
      "source": [
        "# Applied Machine Learning\n",
        "### Workshop 3 of DASIL's series on \"Data Science with Python\"\n",
        "### Created by Martin Pollack, Yusen He, and Declan O'Reilly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0FGuCgcWQ4p"
      },
      "source": [
        "In this Jupyter notebook we will teach you how to fit the machine learning models we talked about last week in Python using the `scikit-learn` package."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B4_h-5j_Wqc"
      },
      "source": [
        "All of our example datasets come from the `datasets` sub-package within `scikit-learn`. So we import them now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UiT01kfZWQ4q"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEOwnQpUWQ4t"
      },
      "source": [
        "## Supervised Learning - Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NHTB5d26lQO"
      },
      "source": [
        "#### Dataset introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7L_N9Q6WQ4u"
      },
      "source": [
        "Remember that in a regression problem the outcome variable is numeric and continuous. However, the predictor variables can either be continuous or discrete.\n",
        "\n",
        "An example of a regression problem can be found in the diabetes dataset within sklearn. Our outcome is a quantitative measure of disease progression that takes on numbers between 25 and 346."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3ffUxHDLWQ4v"
      },
      "outputs": [],
      "source": [
        "diabetes = datasets.load_diabetes(as_frame=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuLcLCoQ_Wqk"
      },
      "source": [
        "`diabetes` is a special scikit-learn dataset. Its `target` field is a pandas Series with our continuous outcome variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "gAset6_s_Wqm",
        "outputId": "5c2e5d05-d471-42df-c74b-21bd0b0b87c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      151.0\n",
              "1       75.0\n",
              "2      141.0\n",
              "3      206.0\n",
              "4      135.0\n",
              "       ...  \n",
              "437    178.0\n",
              "438    104.0\n",
              "439    132.0\n",
              "440    220.0\n",
              "441     57.0\n",
              "Name: target, Length: 442, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "diabetes.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Re8w01hY86c"
      },
      "source": [
        "And its `data` field is a pandas Dataframe of all of our potential predictor variables. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `diabetes` dataset contains the following variables:\n",
        "\n",
        "\n",
        "\n",
        "*   **age:** age in years\n",
        "*   **sex:** gender\n",
        "*   **bmi:** body mass index\n",
        "*   **bp:** average blood pressure\n",
        "*   **s1 tc:** total serum cholesterol\n",
        "*   **s2 ldl:** low-density lipoproteins\n",
        "*   **s3 hdl:** high-density lipoproteins\n",
        "*   **s4 tch:** total cholesterol / HDL\n",
        "*   **s5 ltg:** possibly log of serum triglycerides level\n",
        "*   **s6 glu:** blood sugar level\n",
        "\n",
        "Here, all 10 variables inside `diabetes` dataset have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n"
      ],
      "metadata": {
        "id": "cjrEfXZuATy5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uZND0mNpYxjS",
        "outputId": "e3da8fcf-db83-4704-d9b7-4b079ffa2d22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          age       sex       bmi        bp        s1        s2        s3  \\\n",
              "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
              "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
              "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
              "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
              "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
              "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
              "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
              "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
              "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
              "\n",
              "           s4        s5        s6  \n",
              "0   -0.002592  0.019908 -0.017646  \n",
              "1   -0.039493 -0.068330 -0.092204  \n",
              "2   -0.002592  0.002864 -0.025930  \n",
              "3    0.034309  0.022692 -0.009362  \n",
              "4   -0.002592 -0.031991 -0.046641  \n",
              "..        ...       ...       ...  \n",
              "437 -0.002592  0.031193  0.007207  \n",
              "438  0.034309 -0.018118  0.044485  \n",
              "439 -0.011080 -0.046879  0.015491  \n",
              "440  0.026560  0.044528 -0.025930  \n",
              "441 -0.039493 -0.004220  0.003064  \n",
              "\n",
              "[442 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f7c7457e-9420-45f8-bc44-efa36e08501b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>bp</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.038076</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.061696</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>-0.044223</td>\n",
              "      <td>-0.034821</td>\n",
              "      <td>-0.043401</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.019908</td>\n",
              "      <td>-0.017646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.001882</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.051474</td>\n",
              "      <td>-0.026328</td>\n",
              "      <td>-0.008449</td>\n",
              "      <td>-0.019163</td>\n",
              "      <td>0.074412</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.068330</td>\n",
              "      <td>-0.092204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.085299</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.044451</td>\n",
              "      <td>-0.005671</td>\n",
              "      <td>-0.045599</td>\n",
              "      <td>-0.034194</td>\n",
              "      <td>-0.032356</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>-0.025930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.089063</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.011595</td>\n",
              "      <td>-0.036656</td>\n",
              "      <td>0.012191</td>\n",
              "      <td>0.024991</td>\n",
              "      <td>-0.036038</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>0.022692</td>\n",
              "      <td>-0.009362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.005383</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.036385</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>0.003935</td>\n",
              "      <td>0.015596</td>\n",
              "      <td>0.008142</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>-0.031991</td>\n",
              "      <td>-0.046641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>0.041708</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.019662</td>\n",
              "      <td>0.059744</td>\n",
              "      <td>-0.005697</td>\n",
              "      <td>-0.002566</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.031193</td>\n",
              "      <td>0.007207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>-0.005515</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>-0.067642</td>\n",
              "      <td>0.049341</td>\n",
              "      <td>0.079165</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>-0.018118</td>\n",
              "      <td>0.044485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>0.041708</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>0.017282</td>\n",
              "      <td>-0.037344</td>\n",
              "      <td>-0.013840</td>\n",
              "      <td>-0.024993</td>\n",
              "      <td>-0.011080</td>\n",
              "      <td>-0.046879</td>\n",
              "      <td>0.015491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>-0.045472</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>0.001215</td>\n",
              "      <td>0.016318</td>\n",
              "      <td>0.015283</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>0.026560</td>\n",
              "      <td>0.044528</td>\n",
              "      <td>-0.025930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>-0.045472</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.073030</td>\n",
              "      <td>-0.081414</td>\n",
              "      <td>0.083740</td>\n",
              "      <td>0.027809</td>\n",
              "      <td>0.173816</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.004220</td>\n",
              "      <td>0.003064</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>442 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f7c7457e-9420-45f8-bc44-efa36e08501b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f7c7457e-9420-45f8-bc44-efa36e08501b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f7c7457e-9420-45f8-bc44-efa36e08501b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "diabetes.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLh59zKN_Wqr"
      },
      "source": [
        "To make things easier, we will just rename our `target` to `Y` and our predictors to `X`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mvjfRKLu_Wqs"
      },
      "outputs": [],
      "source": [
        "Y = diabetes.target\n",
        "X = diabetes.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amRvAyBZaNez"
      },
      "source": [
        "#### Splitting the dataset into Training and Test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ro8jKDFpwSh"
      },
      "source": [
        "To evaluate the performance of our models, we need to randomly split our features dataset `X` and outcomes `Y` into a training set `X_train`/`y_train` and testing set `X_test`/`Y_test`. Randomly, we will use some observations to train our models and others see how our model generalizes to new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40iJCmxjcLVC"
      },
      "source": [
        "The `sklearn.model_selection.train_test_split()` does the random split for the training and testing dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VADJGmpq-96"
      },
      "source": [
        "The `test_size` option controls proportion of the observations in our original data that we want to include in our test dataset. The `random_state` parameter controls the random selection process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "NZBrjZyeaTxa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ3sh-bKq0ko",
        "outputId": "e4995f49-13e6-4fba-9aa3-ed36140ab08e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(442, 10)\n",
            "(331, 10)\n",
            "(111, 10)\n",
            "(442,)\n",
            "(331,)\n",
            "(111,)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "print(Y.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19ntU4ger8wA"
      },
      "source": [
        "#### Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjXs3btQvjH_"
      },
      "source": [
        "Let's fit our first machine learning model! We are going to first fit a linear regression, which is the simplest model we will consider since it has no hyperparameters.\n",
        "\n",
        "At a minimum this process takes two steps.\n",
        "\n",
        "First we create the model object, specifying any hyperparameters (but there are none for now). In this case we want to use the `LinearRegression` object from `sklearn.linear_model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0ArrMz1IthGn"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor_LinReg = LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF0zkZimvm2Q"
      },
      "source": [
        "Second we have to actually fit the linear regression model using our training data. This is done by calling the `fit()` method on our model object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKYPHVBJvsnB",
        "outputId": "086177ac-c8e0-4b75-88b0-0eafe4700c39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "regressor_LinReg.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQlOWLImv3tr"
      },
      "source": [
        "We can now make predictions for our test dataset using our model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eJt3Ymrsv6iI",
        "outputId": "fddba52b-f1e0-4dfb-85b7-b3a6bc48e5cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([241.84730258, 250.12303941, 164.96456549, 119.11639346,\n",
              "       188.23120303, 260.56079379, 113.07583812, 190.54117538,\n",
              "       151.8883747 , 236.50848375, 168.76844138, 180.52719713,\n",
              "       109.16037049,  90.20148392, 244.73990469,  90.58113696,\n",
              "       152.51268196,  66.97735025,  98.0467335 , 215.39557064,\n",
              "       197.70737206, 160.9176914 , 162.88584001, 158.25373793,\n",
              "       202.44823294, 168.46663088, 119.87243699,  83.05669211,\n",
              "       189.9839726 , 163.02279586, 177.07828326,  82.6702699 ,\n",
              "       144.53204953, 146.07901596, 141.73841253, 195.18658206,\n",
              "       164.18043648, 189.14768927, 128.13330927, 206.12996392,\n",
              "        82.64273523, 164.94912645, 144.46057692, 182.0519825 ,\n",
              "       178.41355601,  72.5504089 , 142.69750371, 140.43671531,\n",
              "       121.75256103, 233.70553551, 162.07809758,  76.90270416,\n",
              "       155.68916375, 156.64052259, 238.11357481, 175.75735587,\n",
              "       190.82555855, 119.48230582, 131.3142863 , 172.2453037 ,\n",
              "       214.44479397, 171.30900357, 156.69146772, 110.9755974 ,\n",
              "       257.79427463, 154.6473623 ,  81.10560078, 227.26610365,\n",
              "       205.445138  ,  46.92383044,  78.28098211, 131.5335209 ,\n",
              "       105.63850688, 145.15896592, 133.85511669, 189.31799802,\n",
              "        99.29573544, 202.16752252, 221.67724342, 189.36681415,\n",
              "       150.25345002, 208.85311584,  48.03404661, 206.61925845,\n",
              "        76.63162703,  92.70630395, 148.19321808, 194.60105182,\n",
              "       133.07986975, 148.57002105,  97.51272455, 124.56889921,\n",
              "        82.48851826, 151.41937342, 124.81463753, 105.29002279,\n",
              "       236.2130895 , 227.49222218, 128.37518135, 164.29601063,\n",
              "       193.35752892, 111.83831907, 204.3691    ,  84.7480368 ,\n",
              "       217.70082325, 113.6130274 , 221.22851097, 267.69707418,\n",
              "       115.62235754, 113.98308423, 195.01301149])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "LinReg_pred = regressor_LinReg.predict(X_test)\n",
        "LinReg_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "artWZM1Q_Wqz"
      },
      "source": [
        "Also, we can use the `score()` method to get a quick idea of how our model did. For regression, the evaluation metric used is $R^2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TiMcKvQ2_Wq0",
        "outputId": "fa7d9e3b-272b-4f61-bded-bd9483d75f37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-7c0502902d81>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLinReg_pred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'score'"
          ]
        }
      ],
      "source": [
        "LinReg_pred.score(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1_xHJYlKcK-"
      },
      "source": [
        "#### Artificial Neural Network for regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhMzhu83KcK_"
      },
      "source": [
        "Now we are going to fit a much more complicated model to our data: an artificial neural network (ANN). ANNs can be very accurate; however, they have lots of hyperparameters that are hard to get right.\n",
        "\n",
        "We start by seeing what possible hyperparameters an ANN has and what their default values are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Les6YL4T_Wq1",
        "outputId": "603b0cf2-f045-4c8f-efc0-7008923d9209",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'alpha': 0.0001,\n",
              " 'batch_size': 'auto',\n",
              " 'beta_1': 0.9,\n",
              " 'beta_2': 0.999,\n",
              " 'early_stopping': False,\n",
              " 'epsilon': 1e-08,\n",
              " 'hidden_layer_sizes': (100,),\n",
              " 'learning_rate': 'constant',\n",
              " 'learning_rate_init': 0.001,\n",
              " 'max_fun': 15000,\n",
              " 'max_iter': 200,\n",
              " 'momentum': 0.9,\n",
              " 'n_iter_no_change': 10,\n",
              " 'nesterovs_momentum': True,\n",
              " 'power_t': 0.5,\n",
              " 'random_state': None,\n",
              " 'shuffle': True,\n",
              " 'solver': 'adam',\n",
              " 'tol': 0.0001,\n",
              " 'validation_fraction': 0.1,\n",
              " 'verbose': False,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "MLPRegressor().get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXtJC-Gf_Wq2"
      },
      "source": [
        "Now we can set up an ANN model, this time specifying specific values for hyperparameters like the number of hidden layers. All hyperparameters that we don't specify values for will have their default values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "u1IhG5bQKcK_"
      },
      "outputs": [],
      "source": [
        "regressor_ANN_default = MLPRegressor(hidden_layer_sizes=(40,1), solver='lbfgs', max_iter=2000, learning_rate_init=0.000001, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kkFO9OI_Wq2"
      },
      "source": [
        "Next we fit this specific model with the `fit()` method and evaluate it with `score()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "VKZVws6t_Wq3",
        "outputId": "1067ea09-20d0-4559-f23b-1cafdad72b3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.34888647829370967"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "regressor_ANN_default.fit(X_train, Y_train)\n",
        "regressor_ANN_default.score(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r27sd4IPZsW"
      },
      "source": [
        "So we just fit an ANN with one set of hyperparameters.\n",
        "\n",
        "But our choice of hyperparameters is going to have a big effect on how well our model does. Thus, ideally we want to try multiple combinations of hyperparameters and then pick the best one.\n",
        "\n",
        "The first method we use for \"hyperparameter tuning\" is the `GridSearchCV()` function. We give it specific values of hyperparameters we want to be considered. These hyperparameters are detailed using a dictionary of lists.\n",
        "\n",
        "Then when we fit our `GridSearchCV` object, we will actually be fitting many ANNs at once, one for each combination of hyperparameters. As part of the fitting process, Python does cross validation (CV) on each model and picks the best combination based on the model with the best overall evaluation metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R-sVlyILri3",
        "outputId": "85efc1e6-d2d3-4fc1-a6e4-67272badb897"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=MLPRegressor(max_iter=5000, solver='lbfgs'),\n",
              "             param_grid={'hidden_layer_sizes': [(5, 1), (35, 1), (40, 1),\n",
              "                                                (200, 1)],\n",
              "                         'learning_rate_init': [0.0001, 1e-06]})"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "ANN = MLPRegressor(solver='lbfgs', max_iter=5000)\n",
        "parameters = {'learning_rate_init':[0.0001, 0.000001], 'hidden_layer_sizes':[(5,1), (35,1), (40,1), (200,1)]}\n",
        "regressor_ANN_tuned_grid = GridSearchCV(ANN, parameters)\n",
        "regressor_ANN_tuned_grid.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJoaF_SB_Wq8"
      },
      "source": [
        "To see all the results, access the `cv_results_` field of our `GridSearchCV` object. And to see the best combination, access the `best_estimator_` field of the same object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "PcrkGy2h_Wq9",
        "outputId": "84f9cb63-eca3-4f4a-b4f4-67868eda6a70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPRegressor(hidden_layer_sizes=(5, 1), learning_rate_init=0.0001,\n",
            "             max_iter=5000, solver='lbfgs')\n",
            "0.23194780499662615\n"
          ]
        }
      ],
      "source": [
        "print(regressor_ANN_tuned_grid.best_estimator_)\n",
        "print(regressor_ANN_tuned_grid.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHSGQkqh_Wq-"
      },
      "source": [
        "Again we can what are model predicts using the `predict()` method on our model object. Although we trained multiple ANNs at once, it will by default give us predictions from the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKeB6KumRoQ0",
        "outputId": "ac59f00a-024c-4cd5-ab2f-11da2163bd35"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "ANN_pred = regressor_ANN_tuned_grid.predict(X_test)\n",
        "ANN_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbtu3t5bwXWf"
      },
      "source": [
        "#### Performance Assessment using Testing Data\n",
        "\n",
        "We will compare the two models using these four metrics:\n",
        "*   Mean Absolute Error\n",
        "*   Mean Absolute Percentage Error\n",
        "*   Mean Square Error\n",
        "*   Root-Mean-Square Error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEexDKqYx3cA"
      },
      "source": [
        "First, let's compute Mean Absolute Error (MAE) for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr21dcF-wqao",
        "outputId": "e80fdb91-3d5a-44ad-ebf5-0336351f8a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MAE of predictions provided by GLM is :\n",
            "45.120987683251\n",
            "The MAE of predictions provided by ANN is :\n",
            "58.31036172123786\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "MAE_GLM = mean_absolute_error(Y_test, LinReg_pred)\n",
        "MAE_ANN = mean_absolute_error(Y_test, ANN_pred)\n",
        "\n",
        "print(\"The MAE of predictions provided by GLM is :\")\n",
        "print(MAE_GLM)\n",
        "\n",
        "print(\"The MAE of predictions provided by ANN is :\")\n",
        "print(MAE_ANN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZCsUF1EyATg"
      },
      "source": [
        "Second, let's compute Mean Absolute Percentage Error (MAPE) for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpCMtL9S3U0h",
        "outputId": "86e7fac7-ae32-4890-f0d0-633fcb418572"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MAPE of predictions provided by GLM is :\n",
            "0.37961401187552524\n",
            "The MAPE of predictions provided by ANN is :\n",
            "0.5261272203265065\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "MAPE_GLM = mean_absolute_percentage_error(Y_test, LinReg_pred)\n",
        "MAPE_ANN = mean_absolute_percentage_error(Y_test, ANN_pred)\n",
        "\n",
        "print(\"The MAPE of predictions provided by GLM is :\")\n",
        "print(MAPE_GLM)\n",
        "\n",
        "print(\"The MAPE of predictions provided by ANN is :\")\n",
        "print(MAPE_ANN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2neFZEkyIJh"
      },
      "source": [
        "Third, let's compute Mean Square Error (MSE) for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v44igycf39JO",
        "outputId": "21e4f91c-2340-4657-fe7b-a2b96c28b851"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MSE of predictions provided by GLM is :\n",
            "3180.1988368427265\n",
            "The MSE of predictions provided by ANN is :\n",
            "4965.1264716492215\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "MSE_GLM = mean_squared_error(Y_test, LinReg_pred)\n",
        "MSE_ANN = mean_squared_error(Y_test, ANN_pred)\n",
        "\n",
        "print(\"The MSE of predictions provided by GLM is :\")\n",
        "print(MSE_GLM)\n",
        "\n",
        "print(\"The MSE of predictions provided by ANN is :\")\n",
        "print(MSE_ANN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKo8f8k5yOEh"
      },
      "source": [
        "Last, let's compute Root-Mean-Suqare-Error (RMSE) for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aBlPKXL5oAh",
        "outputId": "5233a380-3078-4330-fd66-3810cdcc868f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The RMSE of predictions provided by GLM is :\n",
            "56.39325169594964\n",
            "The RMSE of predictions provided by ANN is :\n",
            "70.46365355024689\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "RMSE_GLM = mean_squared_error(Y_test, LinReg_pred, squared=False)\n",
        "RMSE_ANN = mean_squared_error(Y_test, ANN_pred, squared=False)\n",
        "\n",
        "print(\"The RMSE of predictions provided by GLM is :\")\n",
        "print(RMSE_GLM)\n",
        "\n",
        "print(\"The RMSE of predictions provided by ANN is :\")\n",
        "print(RMSE_ANN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SarBlYm2WQ4x"
      },
      "source": [
        "## Supervised Learning - Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULypkTWU9hEp"
      },
      "source": [
        "#### Dataset Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29YqLUpTWQ4z"
      },
      "source": [
        "Now let's look at a classification problem, where the outcome can only take on 2 or more discrete values. But of course our predictors can be either continuous or discrete.\n",
        "\n",
        "Now we use `scikit-learn`'s breast cancer dataset. Here the outcome can take on a 0, for no breast cancer, or 1, for breast cancer. \n",
        "\n",
        "So in this case we actually have a *binary classification* problem, meaning our category can only take on 2 discrete values. In most binary classification problems, like in this case, the categories are 0 and 1 indiciating the presence or absence of some trait."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "0Jmrv4VMWQ41"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "breast_cancer = load_breast_cancer(as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZau-rgMWQ41",
        "outputId": "773bf2e0-10d1-42f5-9b7f-27984c77b5fc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    357\n",
              "0    212\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "breast_cancer.target.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `breast cancer` dataset contains 30 predictive variables. For example:\n",
        "\n",
        "\n",
        "\n",
        "*    radius (mean of distances from center to points on the perimeter)\n",
        "\n",
        "*    texture (standard deviation of gray-scale values)\n",
        "\n",
        "*    perimeter\n",
        "\n",
        "*    area\n",
        "\n",
        "*    smoothness (local variation in radius lengths)\n",
        "\n",
        "*    compactness (perimeter^2 / area - 1.0)\n",
        "\n",
        "*    concavity (severity of concave portions of the contour)\n",
        "\n",
        "*    concave points (number of concave portions of the contour)\n",
        "\n",
        "*    symmetry\n",
        "\n",
        "*    fractal dimension (“coastline approximation” - 1)\n",
        "\n",
        "\n",
        "\n",
        "The mean, standard error, and “worst” or largest (mean of the three worst/largest values) of these features were computed for each image, resulting in 30 features. For instance, field 0 is Mean Radius, field 10 is Radius SE, field 20 is Worst Radius.\n",
        "\n"
      ],
      "metadata": {
        "id": "y6Kl5F0QBtSa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "NU-R05ZjXEbr",
        "outputId": "a58050ff-1bb5-49cb-84cc-cc751add3a54"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "0                   0.07871  ...        25.380          17.33   \n",
              "1                   0.05667  ...        24.990          23.41   \n",
              "2                   0.05999  ...        23.570          25.53   \n",
              "3                   0.09744  ...        14.910          26.50   \n",
              "4                   0.05883  ...        22.540          16.67   \n",
              "..                      ...  ...           ...            ...   \n",
              "564                 0.05623  ...        25.450          26.40   \n",
              "565                 0.05533  ...        23.690          38.25   \n",
              "566                 0.05648  ...        18.980          34.12   \n",
              "567                 0.07016  ...        25.740          39.42   \n",
              "568                 0.05884  ...         9.456          30.37   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "0             184.60      2019.0           0.16220            0.66560   \n",
              "1             158.80      1956.0           0.12380            0.18660   \n",
              "2             152.50      1709.0           0.14440            0.42450   \n",
              "3              98.87       567.7           0.20980            0.86630   \n",
              "4             152.20      1575.0           0.13740            0.20500   \n",
              "..               ...         ...               ...                ...   \n",
              "564           166.10      2027.0           0.14100            0.21130   \n",
              "565           155.00      1731.0           0.11660            0.19220   \n",
              "566           126.70      1124.0           0.11390            0.30940   \n",
              "567           184.60      1821.0           0.16500            0.86810   \n",
              "568            59.16       268.6           0.08996            0.06444   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "0             0.7119                0.2654          0.4601   \n",
              "1             0.2416                0.1860          0.2750   \n",
              "2             0.4504                0.2430          0.3613   \n",
              "3             0.6869                0.2575          0.6638   \n",
              "4             0.4000                0.1625          0.2364   \n",
              "..               ...                   ...             ...   \n",
              "564           0.4107                0.2216          0.2060   \n",
              "565           0.3215                0.1628          0.2572   \n",
              "566           0.3403                0.1418          0.2218   \n",
              "567           0.9387                0.2650          0.4087   \n",
              "568           0.0000                0.0000          0.2871   \n",
              "\n",
              "     worst fractal dimension  \n",
              "0                    0.11890  \n",
              "1                    0.08902  \n",
              "2                    0.08758  \n",
              "3                    0.17300  \n",
              "4                    0.07678  \n",
              "..                       ...  \n",
              "564                  0.07115  \n",
              "565                  0.06637  \n",
              "566                  0.07820  \n",
              "567                  0.12400  \n",
              "568                  0.07039  \n",
              "\n",
              "[569 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-616c6052-6924-4346-92e4-1be7f1ec69c9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-616c6052-6924-4346-92e4-1be7f1ec69c9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-616c6052-6924-4346-92e4-1be7f1ec69c9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-616c6052-6924-4346-92e4-1be7f1ec69c9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "breast_cancer.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnasUbL_9xOg"
      },
      "source": [
        "#### Define the predictor variable set and a target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQALRlB997O7"
      },
      "source": [
        "For the regression tasks, a feature set `X` and a target set `y` need to be defined first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "eWj12b_r98X8",
        "outputId": "9e0a4e08-2e89-4f1b-ccb4-bf9e785d161b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "0                   0.07871  ...        25.380          17.33   \n",
              "1                   0.05667  ...        24.990          23.41   \n",
              "2                   0.05999  ...        23.570          25.53   \n",
              "3                   0.09744  ...        14.910          26.50   \n",
              "4                   0.05883  ...        22.540          16.67   \n",
              "..                      ...  ...           ...            ...   \n",
              "564                 0.05623  ...        25.450          26.40   \n",
              "565                 0.05533  ...        23.690          38.25   \n",
              "566                 0.05648  ...        18.980          34.12   \n",
              "567                 0.07016  ...        25.740          39.42   \n",
              "568                 0.05884  ...         9.456          30.37   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "0             184.60      2019.0           0.16220            0.66560   \n",
              "1             158.80      1956.0           0.12380            0.18660   \n",
              "2             152.50      1709.0           0.14440            0.42450   \n",
              "3              98.87       567.7           0.20980            0.86630   \n",
              "4             152.20      1575.0           0.13740            0.20500   \n",
              "..               ...         ...               ...                ...   \n",
              "564           166.10      2027.0           0.14100            0.21130   \n",
              "565           155.00      1731.0           0.11660            0.19220   \n",
              "566           126.70      1124.0           0.11390            0.30940   \n",
              "567           184.60      1821.0           0.16500            0.86810   \n",
              "568            59.16       268.6           0.08996            0.06444   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "0             0.7119                0.2654          0.4601   \n",
              "1             0.2416                0.1860          0.2750   \n",
              "2             0.4504                0.2430          0.3613   \n",
              "3             0.6869                0.2575          0.6638   \n",
              "4             0.4000                0.1625          0.2364   \n",
              "..               ...                   ...             ...   \n",
              "564           0.4107                0.2216          0.2060   \n",
              "565           0.3215                0.1628          0.2572   \n",
              "566           0.3403                0.1418          0.2218   \n",
              "567           0.9387                0.2650          0.4087   \n",
              "568           0.0000                0.0000          0.2871   \n",
              "\n",
              "     worst fractal dimension  \n",
              "0                    0.11890  \n",
              "1                    0.08902  \n",
              "2                    0.08758  \n",
              "3                    0.17300  \n",
              "4                    0.07678  \n",
              "..                       ...  \n",
              "564                  0.07115  \n",
              "565                  0.06637  \n",
              "566                  0.07820  \n",
              "567                  0.12400  \n",
              "568                  0.07039  \n",
              "\n",
              "[569 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-02d25366-0b99-4e63-b1d3-48d7f0164c8d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02d25366-0b99-4e63-b1d3-48d7f0164c8d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-02d25366-0b99-4e63-b1d3-48d7f0164c8d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-02d25366-0b99-4e63-b1d3-48d7f0164c8d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "X = breast_cancer.data\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkzBmuh6-B6J",
        "outputId": "9c634bfb-5362-4e4a-f20c-f28e0f1715a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "564    0\n",
              "565    0\n",
              "566    0\n",
              "567    0\n",
              "568    1\n",
              "Name: target, Length: 569, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "Y = breast_cancer.target\n",
        "Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56eOA-Y_9lcz"
      },
      "source": [
        "#### Split the dataset into training and test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89bteG4dHsXY"
      },
      "source": [
        "The `sklearn.model_selection.train_test_split` does the random split for the training and testing dataset.\n",
        "\n",
        "Note: Here, `stratify` means the test set has equal numbers of 0 & 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "HU4MmjqLHtaQ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3, stratify=Y,  random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB6c_jrmIdF4"
      },
      "source": [
        "To evaluate the model performance, we need to randomly split the feature set `X` and the target set `y` into the training set `X_train` & `y_train` and test set `X_test` & `y_test`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qayqpBTIdp3"
      },
      "source": [
        "The `test_size` option controls the size of the test set. The `random_state` parameter controls the shuffling applied which can be ignored in this work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elJ87AHnKp0t"
      },
      "source": [
        "#### XGBoost for Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoavtYx4_WrN"
      },
      "source": [
        "The first classification model we will try is XGBoost, considered one of the best models out there.\n",
        "\n",
        "Again we start by seeing what hyperparameters we can possibly tune."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "5yvLrjCf_WrN",
        "outputId": "47667591-c113-417f-fbba-8bd493eeca35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ccp_alpha': 0.0,\n",
              " 'criterion': 'friedman_mse',\n",
              " 'init': None,\n",
              " 'learning_rate': 0.1,\n",
              " 'loss': 'deviance',\n",
              " 'max_depth': 3,\n",
              " 'max_features': None,\n",
              " 'max_leaf_nodes': None,\n",
              " 'min_impurity_decrease': 0.0,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'min_weight_fraction_leaf': 0.0,\n",
              " 'n_estimators': 100,\n",
              " 'n_iter_no_change': None,\n",
              " 'random_state': None,\n",
              " 'subsample': 1.0,\n",
              " 'tol': 0.0001,\n",
              " 'validation_fraction': 0.1,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "GradientBoostingClassifier().get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX6uFoxntutW"
      },
      "source": [
        "Now let's create a model with specific hyperparameters. We will name it as `classifier_XGB`.\n",
        "\n",
        "In this case, the score we get is the overall accuracy of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apugvOWmtt8G",
        "outputId": "cee2fdc1-971c-41fc-9497-4e5572b1d97c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9949748743718593"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "classifier_XGB = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,max_depth=1, random_state=0)\n",
        "classifier_XGB.fit(X_train, Y_train)\n",
        "classifier_XGB.score(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvJDUYxk_WrO"
      },
      "source": [
        "But again we probably want to do some hyperparameter tuning.\n",
        "\n",
        "The second main way to do this is `RandomizedSearchCV()`. Here we give distributions for our hyperparameters instead of specific values. Python will then randomly choose hyperparameters to try based on the given distributions.\n",
        "\n",
        "For example, for XGBoost we will use a normal distribution with mean of 0.5 and standard deviation of 0.1 for the \"minimum impurity decrease\". This means we will mostly try values close to 0.5, but occasionally some further from 0.5. We will then consider a uniform distribution for learning rate between 0 and 1, meaning any number in this range is equally likely to be chosen. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "A0jgh8n-_WrO"
      },
      "outputs": [],
      "source": [
        "XGB = GradientBoostingClassifier(n_estimators=100)\n",
        "\n",
        "from scipy.stats import norm, uniform\n",
        "distributions = {\"min_impurity_decrease\":norm(loc=0.5, scale=0.1), \"learning_rate\":uniform(loc=0.5, scale=0.5)}\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "classifier_XGB_tuned_random = RandomizedSearchCV(XGB, distributions, n_iter=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ga87hbM_WrQ"
      },
      "source": [
        "Now we fit our `RandomizedSearchCV` object. Since `n_iter` is 10 above, we will grab 10 combinations of hyperparameters from our two distributions. Then we will fit an XGBoost model for each combination, Python choosing the best one for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "QOBVHyUC_WrQ",
        "outputId": "3db0edeb-df82-4af9-d6b3-93a6eab6f17a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'learning_rate': 0.8440089431838143, 'min_impurity_decrease': 0.4778342204983586}\n",
            "0.9422784810126581\n"
          ]
        }
      ],
      "source": [
        "classifier_XGB_tuned_random.fit(X_train, Y_train)\n",
        "XGB_pred = classifier_XGB_tuned_random.predict(X_test)\n",
        "\n",
        "print(classifier_XGB_tuned_random.best_params_)\n",
        "print(classifier_XGB_tuned_random.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIQhfBLiK0Zn"
      },
      "source": [
        "#### Support Vector Machine for Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp-UWCS8uBY0"
      },
      "source": [
        "Lastly, we will create an SVM model. \n",
        "\n",
        "We will just go back to using `GridSearchCV()` for our hyperparameter tuning. To know what to tune, let's see what the hyperparameters are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-RYcxNYuQRJ",
        "outputId": "1d20e9f3-ee67-49c1-d347-f275f705a5b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1.0,\n",
              " 'break_ties': False,\n",
              " 'cache_size': 200,\n",
              " 'class_weight': None,\n",
              " 'coef0': 0.0,\n",
              " 'decision_function_shape': 'ovr',\n",
              " 'degree': 3,\n",
              " 'gamma': 'scale',\n",
              " 'kernel': 'rbf',\n",
              " 'max_iter': -1,\n",
              " 'probability': False,\n",
              " 'random_state': None,\n",
              " 'shrinking': True,\n",
              " 'tol': 0.001,\n",
              " 'verbose': False}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "SVC().get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enxTf2PI_WrS"
      },
      "source": [
        "We will now create and fit our model, leaving `gamma` fixed at `auto` and tuning `C`, which is by far the most important hyperparameter to get right."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "OKgykWtx_WrT",
        "outputId": "ac80d2b0-74cc-4f76-e1e0-e7f79c42acdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 0.001}\n",
            "0.6281645569620252\n"
          ]
        }
      ],
      "source": [
        "SVC_model = SVC(gamma='auto', probability=True)\n",
        "\n",
        "parameters = {\"C\":[0.001, 0.1, 0.5, 1, 1.5]}\n",
        "\n",
        "classifier_SVM_tuned_grid = GridSearchCV(SVC_model, parameters)\n",
        "\n",
        "classifier_SVM_tuned_grid.fit(X_train, Y_train)\n",
        "print(classifier_SVM_tuned_grid.best_params_)\n",
        "print(classifier_SVM_tuned_grid.best_score_)\n",
        "\n",
        "SVM_pred = classifier_SVM_tuned_grid.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1fxh88pvQzj"
      },
      "source": [
        "#### Performance Assessment\n",
        "\n",
        "*   Confusion Matrix\n",
        "*   Accuracy\n",
        "*   Sensitivity\n",
        "*   Specificity\n",
        "*   AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDaIRwwW4BZi"
      },
      "source": [
        "We start by assessing XGBoost:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "id": "sqsmOh8fz9Gn",
        "outputId": "e88ea874-af58-4630-fac2-9b4c4618717a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for XGB: \n",
            " [[ 58   6]\n",
            " [  7 100]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f15ae2fd1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#Compute the confusion matrix\n",
        "cmXGB = confusion_matrix(Y_test,XGB_pred)\n",
        "print('Confusion Matrix for XGB: \\n', cmXGB)\n",
        "\n",
        "#Plot the confusion matrix using seaborn\n",
        "import seaborn as sns\n",
        "sns.heatmap(cmXGB, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute total test cases\n",
        "totalXGB=sum(sum(cmXGB))\n",
        "#####from confusion matrix calculate accuracy\n",
        "accuracyXGB=(cmXGB[0,0]+cmXGB[1,1])/totalXGB\n",
        "print ('Accuracy for XGB: ', accuracyXGB)\n",
        "\n",
        "sensitivityXGB = cmXGB[1,1]/(cmXGB[1,0]+cmXGB[1,1])\n",
        "print('Specificity for XGB: ', sensitivityXGB)\n",
        "\n",
        "specificityXGB = cmXGB[0,0]/(cmXGB[0,0]+cmXGB[0,1])\n",
        "print('Sensitivity for XGB: ', specificityXGB)"
      ],
      "metadata": {
        "id": "EJ7FFlnwElfz",
        "outputId": "a561aed9-be6b-4108-e4b6-65fce9784080",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for XGB:  0.9239766081871345\n",
            "Specificity for XGB:  0.9345794392523364\n",
            "Sensitivity for XGB:  0.90625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ekaseon1kDu"
      },
      "source": [
        "Then, we compute the AUC. We use the `roc_auc_score` from `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8eqsAS210uf",
        "outputId": "3b305600-d60a-4d18-ceb6-f974ce561e71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC for XGB:  0.9616676401869159\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#We first compute the probability output from the SVM classifier\n",
        "XGB_prob = classifier_XGB_tuned_random.predict_proba(X_test)\n",
        "\n",
        "#We compute the AUC score\n",
        "aucSVM = roc_auc_score(Y_test,XGB_prob[:,1])\n",
        "print('AUC for XGB: ', aucSVM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKNTgE26_WrW"
      },
      "source": [
        "Now for SVM's prediction, we have:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "2a4d8721-ab20-47d8-aeae-36a6e1ecaf39",
        "id": "E9gsOWuR_WrW"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for SVM: \n",
            " [[  0  64]\n",
            " [  0 107]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f15ae099e50>"
            ]
          },
          "metadata": {},
          "execution_count": 48
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#Compute the confusion matrix\n",
        "cmSVM = confusion_matrix(Y_test,SVM_pred)\n",
        "print('Confusion Matrix for SVM: \\n', cmSVM)\n",
        "\n",
        "#Plot the confusion matrix using seaborn\n",
        "import seaborn as sns\n",
        "sns.heatmap(cmSVM, annot=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute total test cases\n",
        "totalSVM=sum(sum(cmSVM))\n",
        "#####from confusion matrix calculate accuracy\n",
        "accuracySVM=(cmSVM[0,0]+cmSVM[1,1])/totalSVM\n",
        "print ('Accuracy for SVM: ', accuracySVM)\n",
        "\n",
        "sensitivitySVM = cmSVM[1,1]/(cmSVM[1,0]+cmSVM[1,1])\n",
        "print('Specificity for SVM: ', sensitivitySVM)\n",
        "\n",
        "specificitySVM = cmSVM[0,0]/(cmSVM[0,0]+cmSVM[0,1])\n",
        "print('Sensitivity for SVM: ', specificitySVM)"
      ],
      "metadata": {
        "id": "cDXSmoA0E6QI",
        "outputId": "5d1af7ba-b90b-4f6f-a682-f73844069928",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for SVM:  0.6257309941520468\n",
            "Specificity for SVM:  1.0\n",
            "Sensitivity for SVM:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMzeHoOb_WrW"
      },
      "source": [
        "Then, we compute the AUC for SVM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f8f1cf0-c181-4ee7-c160-42ef55a6f4c9",
        "id": "Q6N8mE2x_WrW"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC for SVM:  0.8879964953271028\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#We first compute the probability output from the SVM classifier\n",
        "SVM_prob = classifier_SVM_tuned_grid.predict_proba(X_test)\n",
        "\n",
        "#We compute the AUC score\n",
        "aucSVM = roc_auc_score(Y_test,SVM_prob[:,1])\n",
        "print('AUC for SVM: ', aucSVM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX7SnsiDWQ43"
      },
      "source": [
        "## Unsupervised Learning - Clustering (and Dimension Reduction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORhQRZbv7Cwc"
      },
      "source": [
        "#### Dataset Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5MeAadHWQ44"
      },
      "source": [
        "Lastly we want to consider an unsupervised learning problem, where we don't actually have an outcome at all, or our data is \"unlabeled.\" Instead of predicting something we just want to find patterns and structure in our data.\n",
        "\n",
        "Our data can be unlabeled for two reasons:\n",
        "\n",
        "• First, maybe our data does not have well-defined groupings. An example might be a company's customers: there are not clear and distinct groups that we can put people in. \n",
        "\n",
        "• Second, maybe the label of our data is missing. Suppose you are a wine vendor and you ordered three types of wine from your supplier. When you receive your wine shipment, however, you realize that the labels were not put on. You may want to learn about how the different wine bottles are related to one another to make an educated guess on which is what wine type.\n",
        "\n",
        "Our example below falls in this second case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL-PO7LrWQ45"
      },
      "outputs": [],
      "source": [
        "wine = datasets.load_wine(as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c_SCElBgWQ45"
      },
      "outputs": [],
      "source": [
        "wine.data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4l4wK5z5YUC6"
      },
      "outputs": [],
      "source": [
        "wine.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e5r4Un57I2-"
      },
      "source": [
        "#### Initialize the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzcQqq5r-QNs"
      },
      "source": [
        "Initialize the dataset as `X`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffGyVj1w-S7v"
      },
      "outputs": [],
      "source": [
        "X= wine.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fkCOINlx_Wre"
      },
      "outputs": [],
      "source": [
        "wine.target.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0yRsiFz-_K0"
      },
      "source": [
        "#### Clustering using K-Means algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gyXR2eUBcfO"
      },
      "source": [
        "##### Intialize the K-Means Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u22oqn0-IRO"
      },
      "source": [
        "The K-Mean algorithm is included in the Scikit-leanr library. Define the number of clusters by `n_clusters` and random initialization state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN01QBb4-Pdt"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "#Here we set n=3 in this workshop\n",
        "cluster_KMeans = KMeans(n_clusters=3, random_state=0)\n",
        "cluster_KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGumzwgl-1xt"
      },
      "source": [
        "##### Fit and predict using K-Mean algorithm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DJRbWuJ_cBG"
      },
      "source": [
        "Fit the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_ch__Ce-1Gx"
      },
      "outputs": [],
      "source": [
        "cluster_KMeans.fit(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icvv8h9z_Oh8"
      },
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "weBqEwxW_hoE"
      },
      "outputs": [],
      "source": [
        "cluster_labels = cluster_KMeans.predict(X)\n",
        "cluster_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEL2KmZH1e3y"
      },
      "source": [
        "Compute inner cluster distances (Euclidean distances) within all clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLcypDGJ1kSZ"
      },
      "outputs": [],
      "source": [
        "cluster_KMeans.inertia_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2VQS91NBUJN"
      },
      "source": [
        "##### Find the BEST k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcA2Ed-z1toI"
      },
      "source": [
        "Now, let's try different numbers of k to see how cluster centers change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVW1JGmP1s0P"
      },
      "outputs": [],
      "source": [
        "#Store the sum of inner cluster distances in a list and name is as dist\n",
        "dist=[]\n",
        "\n",
        "for i in range(2,11):\n",
        "  #Run k-mean clustering with i centers\n",
        "  cluster_KMeans = KMeans(n_clusters =i, random_state=0)\n",
        "  cluster_KMeans.fit(X)\n",
        "  #Store the summed inner cluster distances into the list namely 'dist'\n",
        "  dist.append(cluster_KMeans.inertia_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aRiilxo8bGJ"
      },
      "source": [
        "Display the inner cluster distances for all k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RPTDSExDBY0v"
      },
      "outputs": [],
      "source": [
        "dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNud2CgJ8hYy"
      },
      "source": [
        "Now, let's use `matplotlib` library to visualize the inner cluster distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyljMec38NjX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MexfgXCq8o1Y"
      },
      "source": [
        "We can plot the inner cluster distance curve and use Elbow's method to seek for optimal k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a8w02SxZ8P4j"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "elbowPlot = pd.DataFrame(dist)\n",
        "elbowPlot.rename(columns={0: \"Inner cluster distance\"}, inplace=True)\n",
        "elbowPlot[\"Number of Clusters\"] = np.arange(2, 11)\n",
        "\n",
        "plt.plot(elbowPlot[\"Number of Clusters\"], elbowPlot[\"Inner cluster distance\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x2eiPRk_Wrp"
      },
      "source": [
        "#### DBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laqjJdOi_Wrp"
      },
      "source": [
        "The DBSCAN algorithm is included in the cluster subdirectory of scikit-learn.\n",
        "\n",
        "To create the model, we need to decide our radius factor, `eps`, which tells us how large we think our clusters will be, and the minimum number of samples we want included in each cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vkx--XsM_Wrp"
      },
      "outputs": [],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "cluster_DBSCAN = DBSCAN(eps=40, min_samples=20)\n",
        "cluster_DBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELVwSwqD_Wrq"
      },
      "source": [
        "Fit the DBSCAN algorithm to our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dpsPBwt_Wrq"
      },
      "outputs": [],
      "source": [
        "cluster_DBSCAN.fit(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRQ92Oea_Wrr"
      },
      "source": [
        "Predict the clustering groups using our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tT2mHUUu_Wrs"
      },
      "outputs": [],
      "source": [
        "DBSCAN_predict = cluster_DBSCAN.fit_predict(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWWOdZq4_Wrs"
      },
      "source": [
        "Unlike k-means, DBSCAN tries to figure out the optimal number of clusters.\n",
        "\n",
        "How many clusters do we have in this fitted model? And what are they?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QIaegMdi_Wrt"
      },
      "outputs": [],
      "source": [
        "print(len(set(DBSCAN_predict)))\n",
        "print(np.unique(DBSCAN_predict, return_counts=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1YZ7cIH_Wrt"
      },
      "source": [
        "So here we have two groups (0 and 1) with some outliers (-1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRQlkn5s_Wrt"
      },
      "source": [
        "#### Why are we seeing different results using k-means and DBSCAN?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgCdXtmh_Wrt"
      },
      "source": [
        "We use TSNE, another dimension reduction algorithm besides Principal Component Analysis, to visualize our data in two dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9sfnx8fq_Wrt"
      },
      "outputs": [],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(X)\n",
        "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=wine.target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQTfykyp_Wru"
      },
      "source": [
        "It looks like two of the wines are hard to differentiate, and the third is still not that different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GCmgQR7_Wru"
      },
      "source": [
        "## Your turn!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kMRNScr_Wru"
      },
      "source": [
        "It's time for a competition. \n",
        "\n",
        "You should have gotten a dataset on forest fires in Portugal taken from `kaggle.com`. We are going to try and predict the amount of area burned using variables like wind, rain, day of the week, and month of the year.\n",
        "\n",
        "Try different algorithms for regression tasks and tune their hyperparameters if necessary. The people with the 5 lowest mean square errors will receive a prize!\n",
        "\n",
        "*Hint*: The outcome variable, area burned, is very right-skewed, or most values are small and just a few are larger. Fitting models using the log of the outcome may help. Then when you predict values, exponentiate them to get them on the original scale. Use the `np.log()` and `np.exp()` functions to take the natural log/raise to the power of e."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asFqMj9K_Wru"
      },
      "outputs": [],
      "source": [
        "fires = pd.read_csv(\"forestfires.csv\")\n",
        "fires.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nYMP-3L_Wru"
      },
      "source": [
        "A description of each variable is below:\n",
        "\n",
        "*   `X` is the x-coordinate of the fire on a map of the Portugal park (not very important)\n",
        "*   `Y` is the y-coordinate of the fire on a map of the Portugal park (not very important)\n",
        "*   `month` is the month the fire occured in\n",
        "*   `day` is the day of the week the fire occured on\n",
        "*   `FFMC` stands for \"Fine Fuel Moisture Code\" and indicates the moisture levels among the small leaves in the forest.\n",
        "*   `DMC` stands for \"Duff Moisture Code\" and indicates the moisture levels among decomposed organic material.\n",
        "*   `DC` stands for \"Drought Code\" and indicates how dry the deeper soil is.\n",
        "*   `ISI` stands for \"Initial Spread Index\" and takes into account the moisture of fuels for fire and windspeed to determine how likely things are to be spread around in the forest.\n",
        "*   `temp` is the temperature in Celsius during the fire.\n",
        "*   `RH` is the relative humidity in percentage terms.\n",
        "*   `wind` is the windspeed in $km/h$ during the fire.\n",
        "*   `rain` is the amount of rain in $mm/m^2$ during the fire.\n",
        "*   `area`, our outcome variable, is the amount of area burned by the fire in hectares.\n",
        "\n",
        "*Note*: a lot of these variables are correlated with one another. So it may be better to choose a subset of them when fitting models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QonX2cM1_Wrw"
      },
      "source": [
        "Then `scikit-learn` needs our outcome variable in a separate dataframe from our predictors. We create those two objects now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeLCaGTN_Wrw"
      },
      "outputs": [],
      "source": [
        "Y = fires[\"area\"]\n",
        "X = fires.drop(columns=\"area\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9vP5-yz_Wrx"
      },
      "source": [
        "Now we create our training and testing datasets. By making `random_state=0` we assure that everyone uses the same training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrhAYrTj_Wrx"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3,  random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5nkFstu_Wrx"
      },
      "source": [
        "OK take it away! Have fun creating your models!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "OHoqoS6zCuES",
        "iIQhfBLiK0Zn",
        "CjRNjZ5WK4pO",
        "KX7SnsiDWQ43",
        "6e5r4Un57I2-",
        "QTHEycO9LFI2"
      ],
      "name": "Python_Workshop_Session_3_Applied_Machine_Learning.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}