{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JPYaq5eWQ4n"
      },
      "source": [
        "# Introduction to Machine Learning\n",
        "### Workshop 3 of DASIL's series on \"Data Science with Python\"\n",
        "### Created by Yusen He & Martin Pollack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0FGuCgcWQ4p"
      },
      "source": [
        "In this Jupyter notebook we will give you a quick introduction on how to fit machine learning models in Python with the `scikit-learn` package. \n",
        "\n",
        "Next week we will go much more into depth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UiT01kfZWQ4q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEOwnQpUWQ4t"
      },
      "source": [
        "## Supervised Learning - Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NHTB5d26lQO"
      },
      "source": [
        "#### Dataset introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7L_N9Q6WQ4u"
      },
      "source": [
        "Remember that in a regression problem the outcome variable is numeric and continuous. However, the predictor variables can either be continuous or discrete.\n",
        "\n",
        "An example of a regression problem can be found in the diabetes dataset within sklearn. Our outcome is a quantitative measure of disease progression that takes on numbers between 25 and 346."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3ffUxHDLWQ4v"
      },
      "outputs": [],
      "source": [
        "diabetes = datasets.load_diabetes(as_frame=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`diabetes` is a special scikit-learn dataset. Its `target` field is a pandas Series with our continuous outcome variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      151.0\n",
              "1       75.0\n",
              "2      141.0\n",
              "3      206.0\n",
              "4      135.0\n",
              "       ...  \n",
              "437    178.0\n",
              "438    104.0\n",
              "439    132.0\n",
              "440    220.0\n",
              "441     57.0\n",
              "Name: target, Length: 442, dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diabetes.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d-7lrwcWQ4w",
        "outputId": "5b54aafc-2a73-4c96-bdf5-d337a6b9f5f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25.0\n",
            "346.0\n"
          ]
        }
      ],
      "source": [
        "print(min(diabetes.target))\n",
        "print(max(diabetes.target))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Re8w01hY86c"
      },
      "source": [
        "And its `data` field is a pandas Dataframe of all of our potential predictor variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "uZND0mNpYxjS",
        "outputId": "25c1b667-da38-44c5-8e13-bf5e77b9b2d6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>bp</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.038076</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.061696</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>-0.044223</td>\n",
              "      <td>-0.034821</td>\n",
              "      <td>-0.043401</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.019908</td>\n",
              "      <td>-0.017646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.001882</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.051474</td>\n",
              "      <td>-0.026328</td>\n",
              "      <td>-0.008449</td>\n",
              "      <td>-0.019163</td>\n",
              "      <td>0.074412</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.068330</td>\n",
              "      <td>-0.092204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.085299</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.044451</td>\n",
              "      <td>-0.005671</td>\n",
              "      <td>-0.045599</td>\n",
              "      <td>-0.034194</td>\n",
              "      <td>-0.032356</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>-0.025930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.089063</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.011595</td>\n",
              "      <td>-0.036656</td>\n",
              "      <td>0.012191</td>\n",
              "      <td>0.024991</td>\n",
              "      <td>-0.036038</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>0.022692</td>\n",
              "      <td>-0.009362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.005383</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.036385</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>0.003935</td>\n",
              "      <td>0.015596</td>\n",
              "      <td>0.008142</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>-0.031991</td>\n",
              "      <td>-0.046641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>0.041708</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.019662</td>\n",
              "      <td>0.059744</td>\n",
              "      <td>-0.005697</td>\n",
              "      <td>-0.002566</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.031193</td>\n",
              "      <td>0.007207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>-0.005515</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>-0.067642</td>\n",
              "      <td>0.049341</td>\n",
              "      <td>0.079165</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>-0.018118</td>\n",
              "      <td>0.044485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>0.041708</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>0.017282</td>\n",
              "      <td>-0.037344</td>\n",
              "      <td>-0.013840</td>\n",
              "      <td>-0.024993</td>\n",
              "      <td>-0.011080</td>\n",
              "      <td>-0.046879</td>\n",
              "      <td>0.015491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>-0.045472</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>0.001215</td>\n",
              "      <td>0.016318</td>\n",
              "      <td>0.015283</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>0.026560</td>\n",
              "      <td>0.044528</td>\n",
              "      <td>-0.025930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>-0.045472</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.073030</td>\n",
              "      <td>-0.081414</td>\n",
              "      <td>0.083740</td>\n",
              "      <td>0.027809</td>\n",
              "      <td>0.173816</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.004220</td>\n",
              "      <td>0.003064</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>442 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          age       sex       bmi        bp        s1        s2        s3  \\\n",
              "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
              "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
              "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
              "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
              "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
              "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
              "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
              "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
              "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
              "\n",
              "           s4        s5        s6  \n",
              "0   -0.002592  0.019908 -0.017646  \n",
              "1   -0.039493 -0.068330 -0.092204  \n",
              "2   -0.002592  0.002864 -0.025930  \n",
              "3    0.034309  0.022692 -0.009362  \n",
              "4   -0.002592 -0.031991 -0.046641  \n",
              "..        ...       ...       ...  \n",
              "437 -0.002592  0.031193  0.007207  \n",
              "438  0.034309 -0.018118  0.044485  \n",
              "439 -0.011080 -0.046879  0.015491  \n",
              "440  0.026560  0.044528 -0.025930  \n",
              "441 -0.039493 -0.004220  0.003064  \n",
              "\n",
              "[442 rows x 10 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diabetes.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIxkNetfZdKT"
      },
      "source": [
        "#### Define the predictor variable set and a target\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bnxdeb4bctZ"
      },
      "source": [
        "For the regression tasks, a feature set `X` and a target set `y` need to be defined first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3vEryq9hY7Ni",
        "outputId": "19005942-501b-499d-937c-7f686276330f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>bp</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.038076</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.061696</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>-0.044223</td>\n",
              "      <td>-0.034821</td>\n",
              "      <td>-0.043401</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.019908</td>\n",
              "      <td>-0.017646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.001882</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.051474</td>\n",
              "      <td>-0.026328</td>\n",
              "      <td>-0.008449</td>\n",
              "      <td>-0.019163</td>\n",
              "      <td>0.074412</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.068330</td>\n",
              "      <td>-0.092204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.085299</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.044451</td>\n",
              "      <td>-0.005671</td>\n",
              "      <td>-0.045599</td>\n",
              "      <td>-0.034194</td>\n",
              "      <td>-0.032356</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>-0.025930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.089063</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.011595</td>\n",
              "      <td>-0.036656</td>\n",
              "      <td>0.012191</td>\n",
              "      <td>0.024991</td>\n",
              "      <td>-0.036038</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>0.022692</td>\n",
              "      <td>-0.009362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.005383</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.036385</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>0.003935</td>\n",
              "      <td>0.015596</td>\n",
              "      <td>0.008142</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>-0.031991</td>\n",
              "      <td>-0.046641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>0.041708</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.019662</td>\n",
              "      <td>0.059744</td>\n",
              "      <td>-0.005697</td>\n",
              "      <td>-0.002566</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.031193</td>\n",
              "      <td>0.007207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>-0.005515</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>-0.067642</td>\n",
              "      <td>0.049341</td>\n",
              "      <td>0.079165</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>-0.018118</td>\n",
              "      <td>0.044485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>0.041708</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>0.017282</td>\n",
              "      <td>-0.037344</td>\n",
              "      <td>-0.013840</td>\n",
              "      <td>-0.024993</td>\n",
              "      <td>-0.011080</td>\n",
              "      <td>-0.046879</td>\n",
              "      <td>0.015491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>-0.045472</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>0.001215</td>\n",
              "      <td>0.016318</td>\n",
              "      <td>0.015283</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>0.026560</td>\n",
              "      <td>0.044528</td>\n",
              "      <td>-0.025930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>-0.045472</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.073030</td>\n",
              "      <td>-0.081414</td>\n",
              "      <td>0.083740</td>\n",
              "      <td>0.027809</td>\n",
              "      <td>0.173816</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.004220</td>\n",
              "      <td>0.003064</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>442 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          age       sex       bmi        bp        s1        s2        s3  \\\n",
              "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
              "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
              "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
              "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
              "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
              "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
              "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
              "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
              "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
              "\n",
              "           s4        s5        s6  \n",
              "0   -0.002592  0.019908 -0.017646  \n",
              "1   -0.039493 -0.068330 -0.092204  \n",
              "2   -0.002592  0.002864 -0.025930  \n",
              "3    0.034309  0.022692 -0.009362  \n",
              "4   -0.002592 -0.031991 -0.046641  \n",
              "..        ...       ...       ...  \n",
              "437 -0.002592  0.031193  0.007207  \n",
              "438  0.034309 -0.018118  0.044485  \n",
              "439 -0.011080 -0.046879  0.015491  \n",
              "440  0.026560  0.044528 -0.025930  \n",
              "441 -0.039493 -0.004220  0.003064  \n",
              "\n",
              "[442 rows x 10 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = diabetes.data\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "zY4SVr_VbSqC",
        "outputId": "bedf0577-e871-425f-dc9c-f8899457a29f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      151.0\n",
              "1       75.0\n",
              "2      141.0\n",
              "3      206.0\n",
              "4      135.0\n",
              "       ...  \n",
              "437    178.0\n",
              "438    104.0\n",
              "439    132.0\n",
              "440    220.0\n",
              "441     57.0\n",
              "Name: target, Length: 442, dtype: float64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y = diabetes.target\n",
        "Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amRvAyBZaNez"
      },
      "source": [
        "#### Splitting the dataset into Training and Test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ro8jKDFpwSh"
      },
      "source": [
        "To evaluate the performance of our models, we need to randomly split our features dataset `X` and outcomes `Y` into a training set `X_train`/`y_train` and testing set `X_test`/`Y_test`. Randomly, we will use some observations to train our models and others see how our model generalizes to new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40iJCmxjcLVC"
      },
      "source": [
        "The `sklearn.model_selection.train_test_split()` does the random split for the training and testing dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VADJGmpq-96"
      },
      "source": [
        "The `test_size` option controls the size of the test set. The `random_state` parameter controls the shuffling applied which can be ignored in this work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NZBrjZyeaTxa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "WQ3sh-bKq0ko",
        "outputId": "991c2d8d-fe61-40f0-8257-303c0601b93b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(442, 10)\n",
            "(331, 10)\n",
            "(111, 10)\n",
            "(442,)\n",
            "(331,)\n",
            "(111,)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "print(Y.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19ntU4ger8wA"
      },
      "source": [
        "#### Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjXs3btQvjH_"
      },
      "source": [
        "Let's fit our first machine learning model!\n",
        "\n",
        "At a minimum this process takes two steps.\n",
        "\n",
        "First we create the model object, specifying any hyperparameters. In this case we want to use the `LinearRegression` object from `sklearn.linear_model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0ArrMz1IthGn"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor_LinReg = LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF0zkZimvm2Q"
      },
      "source": [
        "Second we have to actually fit the linear regression model using our training data. This is done by calling the `fit()` method on our model object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKYPHVBJvsnB",
        "outputId": "a01f2f63-8b31-4037-9258-29a30220fa54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "regressor_LinReg.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQlOWLImv3tr"
      },
      "source": [
        "Make predictions on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJt3Ymrsv6iI"
      },
      "outputs": [],
      "source": [
        "GLM_pred = regressor_LinReg.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1_xHJYlKcK-"
      },
      "source": [
        "#### Artificial Neural Network for regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhMzhu83KcK_"
      },
      "source": [
        "Set up the artifical neural network model. Name it as `regressor`. Define the number of hidden layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u1IhG5bQKcK_"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "regressor_ANN_default = MLPRegressor(solver='lbfgs', max_iter=2000, learning_rate_init=0.000001,hidden_layer_sizes=(40,1), random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.34888647829370967"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "regressor_ANN_default.fit(X_train, Y_train)\n",
        "regressor_ANN_default.score(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r27sd4IPZsW"
      },
      "source": [
        "Tuning the Parameters in our NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R-sVlyILri3",
        "outputId": "dde81c53-15b8-4282-8831-b95055043d85"
      },
      "outputs": [],
      "source": [
        "parameters = {'solver':['lbfgs'], 'learning_rate_init':[0.001], 'hidden_layer_sizes':[(200,1)]}\n",
        "regressor_ANN_tuned_grid = GridSearchCV(regressor_ANN_default, parameters)\n",
        "\n",
        "#regressor_ANN_tuned_grid.fit(X_train,Y_train)\n",
        "#This is a lot of results\n",
        "#print(regressor_ANN_tuned_grid.cv_results_)\n",
        "#This is less (but more important)\n",
        "#ANN_pred = regressor_ANN_tuned_grid.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=MLPRegressor(hidden_layer_sizes=(40, 1),\n",
              "                                    learning_rate_init=1e-06, max_iter=2000,\n",
              "                                    random_state=1, solver='lbfgs'),\n",
              "             param_grid={'hidden_layer_sizes': [(200, 1)],\n",
              "                         'learning_rate_init': [0.001], 'solver': ['lbfgs']})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "regressor_ANN_tuned_grid.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLPRegressor(hidden_layer_sizes=(200, 1), max_iter=2000, random_state=1,\n",
              "             solver='lbfgs')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "regressor_ANN_tuned_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKeB6KumRoQ0",
        "outputId": "6d8cfc95-6088-46f2-a761-0ae13a9cb017"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([281., 220., 178.,  72., 200., 281.,  72., 202., 200., 200., 200.,\n",
              "       220.,  71.,  72., 220.,  71., 200.,  72.,  72., 220.,  71., 200.,\n",
              "       202., 200., 220., 109.,  48.,  72., 200.,  91., 202.,  72., 200.,\n",
              "       200.,  84., 200.,  91.,  91., 200., 220.,  72., 220., 109., 200.,\n",
              "       220.,  72.,  72., 200.,  91., 220.,  71.,  71., 200.,  91., 258.,\n",
              "       220., 220.,  72.,  84., 220., 200., 200.,  91.,  91., 281., 200.,\n",
              "        72., 220., 220.,  72.,  72.,  91.,  71.,  72.,  71., 220.,  91.,\n",
              "       220., 220., 109., 109., 220.,  72., 220.,  71.,  72.,  72., 220.,\n",
              "        72., 202.,  72.,  71.,  72.,  91.,  72.,  72., 281., 109.,  71.,\n",
              "       202., 200.,  72., 220.,  84., 220.,  91., 220., 220.,  72.,  71.,\n",
              "       202.])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ANN_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwgYE5sUKcK_"
      },
      "source": [
        "Fit the ANN model using the input `X_train` and output `y_train`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPoEd2jWKcK_",
        "outputId": "e872d5bf-0555-43c8-b365-e9b69e76fb7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(250, 1), random_state=1)"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "regressor_ANN.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lMXwRzRKcLA"
      },
      "source": [
        "Making predictions on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_mOK2wVKcLA"
      },
      "outputs": [],
      "source": [
        "ANN_pred = regressor_ANN.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8ALjumfss_Y"
      },
      "source": [
        "#### Support Vector Machine Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxPNfrcit2i_"
      },
      "source": [
        "Set up the support vector machine for regression. Name it as `regressor_SVR`. Use `rbf` as the kernel function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-m2IZ8etF24"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZD23upduB_5"
      },
      "source": [
        "Fit the SVR model using the input `X_train` and output `y_train`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XXL8l4nuMiv",
        "outputId": "303b7b5a-c8c7-4e23-9b1b-4358faa0dbb5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SVR()"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqAofH3wuRhJ"
      },
      "source": [
        "Make predictions on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3t33mmOuQ0a"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbtu3t5bwXWf"
      },
      "source": [
        "#### Performance Assessment\n",
        "\n",
        "*   Mean Absolute Error\n",
        "*   Mean Absolute Percentage Error\n",
        "*   Mean Square Error\n",
        "*   Root-Mean-Square Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN5qPEBsJ4kr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEexDKqYx3cA"
      },
      "source": [
        "First, let's compute Mean Absolute Error (MAE) for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr21dcF-wqao",
        "outputId": "54afc4b8-cfe8-423d-930b-3448a8183ab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The MAE of predictions provided by GLM is :\n",
            "45.120987683251\n",
            "The MAE of predictions provided by SVR is :\n",
            "52.45903046955925\n",
            "The MAE of predictions provided by ANN is :\n",
            "53.306306306306304\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "MAE_GLM = mean_absolute_error(y_test, GLM_pred)\n",
        "MAE_SVR = mean_absolute_error(y_test, SVR_pred)\n",
        "MAE_ANN = mean_absolute_error(y_test, ANN_pred)\n",
        "\n",
        "print(\"The MAE of predictions provided by GLM is :\")\n",
        "print(MAE_GLM)\n",
        "\n",
        "print(\"The MAE of predictions provided by SVR is :\")\n",
        "print(MAE_SVR)\n",
        "\n",
        "print(\"The MAE of predictions provided by ANN is :\")\n",
        "print(MAE_ANN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZCsUF1EyATg"
      },
      "source": [
        "Second, let's compute Mean Absolute Percentage Error (MAPE) for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpCMtL9S3U0h",
        "outputId": "2137e069-3202-43ce-f46e-bace10bc679b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The MAPE of predictions provided by GLM is :\n",
            "0.37961401187552524\n",
            "The MAPE of predictions provided by SVR is :\n",
            "0.4218772291282973\n",
            "The MAPE of predictions provided by ANN is :\n",
            "0.3592407768614211\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "MAPE_GLM = mean_absolute_percentage_error(y_test, GLM_pred)\n",
        "MAPE_SVR = mean_absolute_percentage_error(y_test, SVR_pred)\n",
        "MAPE_ANN = mean_absolute_percentage_error(y_test, ANN_pred)\n",
        "\n",
        "print(\"The MAPE of predictions provided by GLM is :\")\n",
        "print(MAPE_GLM)\n",
        "\n",
        "print(\"The MAPE of predictions provided by SVR is :\")\n",
        "print(MAPE_SVR)\n",
        "\n",
        "print(\"The MAPE of predictions provided by ANN is :\")\n",
        "print(MAPE_ANN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2neFZEkyIJh"
      },
      "source": [
        "Third, let's compute Mean Square Error (MSE) for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v44igycf39JO",
        "outputId": "2984a3ab-a843-45c7-9b65-aa1c1af2ed96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The MSE of predictions provided by GLM is :\n",
            "3180.1988368427265\n",
            "The MSE of predictions provided by SVR is :\n",
            "4277.196345895227\n",
            "The MSE of predictions provided by ANN is :\n",
            "5218.369369369369\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "MSE_GLM = mean_squared_error(y_test, GLM_pred)\n",
        "MSE_SVR = mean_squared_error(y_test, SVR_pred)\n",
        "MSE_ANN = mean_squared_error(y_test, ANN_pred)\n",
        "\n",
        "print(\"The MSE of predictions provided by GLM is :\")\n",
        "print(MSE_GLM)\n",
        "\n",
        "print(\"The MSE of predictions provided by SVR is :\")\n",
        "print(MSE_SVR)\n",
        "\n",
        "print(\"The MSE of predictions provided by ANN is :\")\n",
        "print(MSE_ANN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKo8f8k5yOEh"
      },
      "source": [
        "Last, let's compute Root-Mean-Suqare-Error (RMSE) for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aBlPKXL5oAh",
        "outputId": "ff1d9716-605d-446c-9203-179093d3e60c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The RMSE of predictions provided by GLM is :\n",
            "56.39325169594964\n",
            "The RMSE of predictions provided by SVR is :\n",
            "65.4002778732264\n",
            "The RMSE of predictions provided by ANN is :\n",
            "72.23828188273424\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "RMSE_GLM = mean_squared_error(y_test, GLM_pred, squared=False)\n",
        "RMSE_SVR = mean_squared_error(y_test, SVR_pred, squared=False)\n",
        "RMSE_ANN = mean_squared_error(y_test, ANN_pred, squared=False)\n",
        "\n",
        "print(\"The RMSE of predictions provided by GLM is :\")\n",
        "print(RMSE_GLM)\n",
        "\n",
        "print(\"The RMSE of predictions provided by SVR is :\")\n",
        "print(RMSE_SVR)\n",
        "\n",
        "print(\"The RMSE of predictions provided by ANN is :\")\n",
        "print(RMSE_ANN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SarBlYm2WQ4x"
      },
      "source": [
        "## Supervised Learning - Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULypkTWU9hEp"
      },
      "source": [
        "#### Dataset Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29YqLUpTWQ4z"
      },
      "source": [
        "Now let's look at a classification problem, where the outcome can only take on 2 or more discrete values. But of course our predictors can be either continuous or discrete.\n",
        "\n",
        "Now we use `scikit-learn`'s breast cancer dataset. Here the outcome can take on a 0, for no breast cancer, or 1, for breast cancer. \n",
        "\n",
        "So in this case we actually have a *binary classification* problem, meaning our category can only take on 2 discrete values. In most binary classification problems, like in this case, the categories are 0 and 1 indiciating the presence or absence of some trait."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Jmrv4VMWQ41"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "breast_cancer = load_breast_cancer(as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZau-rgMWQ41",
        "outputId": "b2086757-82cd-4c3a-b6ee-f7b4113dc8d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    357\n",
              "0    212\n",
              "Name: target, dtype: int64"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "breast_cancer.target.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "NU-R05ZjXEbr",
        "outputId": "2142159d-2011-4fb6-ea88-3df509bd5c1a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3d591af0-f0b4-464a-a007-65a751db1320\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d591af0-f0b4-464a-a007-65a751db1320')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d591af0-f0b4-464a-a007-65a751db1320 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d591af0-f0b4-464a-a007-65a751db1320');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "0                   0.07871  ...        25.380          17.33   \n",
              "1                   0.05667  ...        24.990          23.41   \n",
              "2                   0.05999  ...        23.570          25.53   \n",
              "3                   0.09744  ...        14.910          26.50   \n",
              "4                   0.05883  ...        22.540          16.67   \n",
              "..                      ...  ...           ...            ...   \n",
              "564                 0.05623  ...        25.450          26.40   \n",
              "565                 0.05533  ...        23.690          38.25   \n",
              "566                 0.05648  ...        18.980          34.12   \n",
              "567                 0.07016  ...        25.740          39.42   \n",
              "568                 0.05884  ...         9.456          30.37   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "0             184.60      2019.0           0.16220            0.66560   \n",
              "1             158.80      1956.0           0.12380            0.18660   \n",
              "2             152.50      1709.0           0.14440            0.42450   \n",
              "3              98.87       567.7           0.20980            0.86630   \n",
              "4             152.20      1575.0           0.13740            0.20500   \n",
              "..               ...         ...               ...                ...   \n",
              "564           166.10      2027.0           0.14100            0.21130   \n",
              "565           155.00      1731.0           0.11660            0.19220   \n",
              "566           126.70      1124.0           0.11390            0.30940   \n",
              "567           184.60      1821.0           0.16500            0.86810   \n",
              "568            59.16       268.6           0.08996            0.06444   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "0             0.7119                0.2654          0.4601   \n",
              "1             0.2416                0.1860          0.2750   \n",
              "2             0.4504                0.2430          0.3613   \n",
              "3             0.6869                0.2575          0.6638   \n",
              "4             0.4000                0.1625          0.2364   \n",
              "..               ...                   ...             ...   \n",
              "564           0.4107                0.2216          0.2060   \n",
              "565           0.3215                0.1628          0.2572   \n",
              "566           0.3403                0.1418          0.2218   \n",
              "567           0.9387                0.2650          0.4087   \n",
              "568           0.0000                0.0000          0.2871   \n",
              "\n",
              "     worst fractal dimension  \n",
              "0                    0.11890  \n",
              "1                    0.08902  \n",
              "2                    0.08758  \n",
              "3                    0.17300  \n",
              "4                    0.07678  \n",
              "..                       ...  \n",
              "564                  0.07115  \n",
              "565                  0.06637  \n",
              "566                  0.07820  \n",
              "567                  0.12400  \n",
              "568                  0.07039  \n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "breast_cancer.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnasUbL_9xOg"
      },
      "source": [
        "#### Define the predictor variable set and a target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQALRlB997O7"
      },
      "source": [
        "For the regression tasks, a feature set `X` and a target set `y` need to be defined first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "eWj12b_r98X8",
        "outputId": "edbc548a-c8e4-4437-98ed-638008618ae1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-88d269db-3ef0-4d14-a2f7-3a7c51c84c3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88d269db-3ef0-4d14-a2f7-3a7c51c84c3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88d269db-3ef0-4d14-a2f7-3a7c51c84c3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88d269db-3ef0-4d14-a2f7-3a7c51c84c3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "0                   0.07871  ...        25.380          17.33   \n",
              "1                   0.05667  ...        24.990          23.41   \n",
              "2                   0.05999  ...        23.570          25.53   \n",
              "3                   0.09744  ...        14.910          26.50   \n",
              "4                   0.05883  ...        22.540          16.67   \n",
              "..                      ...  ...           ...            ...   \n",
              "564                 0.05623  ...        25.450          26.40   \n",
              "565                 0.05533  ...        23.690          38.25   \n",
              "566                 0.05648  ...        18.980          34.12   \n",
              "567                 0.07016  ...        25.740          39.42   \n",
              "568                 0.05884  ...         9.456          30.37   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "0             184.60      2019.0           0.16220            0.66560   \n",
              "1             158.80      1956.0           0.12380            0.18660   \n",
              "2             152.50      1709.0           0.14440            0.42450   \n",
              "3              98.87       567.7           0.20980            0.86630   \n",
              "4             152.20      1575.0           0.13740            0.20500   \n",
              "..               ...         ...               ...                ...   \n",
              "564           166.10      2027.0           0.14100            0.21130   \n",
              "565           155.00      1731.0           0.11660            0.19220   \n",
              "566           126.70      1124.0           0.11390            0.30940   \n",
              "567           184.60      1821.0           0.16500            0.86810   \n",
              "568            59.16       268.6           0.08996            0.06444   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "0             0.7119                0.2654          0.4601   \n",
              "1             0.2416                0.1860          0.2750   \n",
              "2             0.4504                0.2430          0.3613   \n",
              "3             0.6869                0.2575          0.6638   \n",
              "4             0.4000                0.1625          0.2364   \n",
              "..               ...                   ...             ...   \n",
              "564           0.4107                0.2216          0.2060   \n",
              "565           0.3215                0.1628          0.2572   \n",
              "566           0.3403                0.1418          0.2218   \n",
              "567           0.9387                0.2650          0.4087   \n",
              "568           0.0000                0.0000          0.2871   \n",
              "\n",
              "     worst fractal dimension  \n",
              "0                    0.11890  \n",
              "1                    0.08902  \n",
              "2                    0.08758  \n",
              "3                    0.17300  \n",
              "4                    0.07678  \n",
              "..                       ...  \n",
              "564                  0.07115  \n",
              "565                  0.06637  \n",
              "566                  0.07820  \n",
              "567                  0.12400  \n",
              "568                  0.07039  \n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = pd.DataFrame(breast_cancer['data'])\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "TkzBmuh6-B6J",
        "outputId": "4d4fef68-0bc3-4f84-8222-ac04c84270f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3776d117-f015-4d20-98d6-73495d75935d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3776d117-f015-4d20-98d6-73495d75935d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3776d117-f015-4d20-98d6-73495d75935d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3776d117-f015-4d20-98d6-73495d75935d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     target\n",
              "0         0\n",
              "1         0\n",
              "2         0\n",
              "3         0\n",
              "4         0\n",
              "..      ...\n",
              "564       0\n",
              "565       0\n",
              "566       0\n",
              "567       0\n",
              "568       1\n",
              "\n",
              "[569 rows x 1 columns]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = pd.DataFrame(breast_cancer['target'])\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56eOA-Y_9lcz"
      },
      "source": [
        "#### Split the dataset into training and test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89bteG4dHsXY"
      },
      "source": [
        "The `sklearn.model_selection.train_test_split` does the random split for the training and testing dataset.\n",
        "\n",
        "Note: Here, `stratify` means the test set has equal numbers of 0 & 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HU4MmjqLHtaQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, stratify=y,  random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB6c_jrmIdF4"
      },
      "source": [
        "To evaluate the model performance, we need to randomly split the feature set `X` and the target set `y` into the training set `X_train` & `y_train` and test set `X_test` & `y_test`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qayqpBTIdp3"
      },
      "source": [
        "The `test_size` option controls the size of the test set. The `random_state` parameter controls the shuffling applied which can be ignored in this work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "5eLqQ1M6Ih1k",
        "outputId": "4dd50ede-6800-4669-b3c2-db5d850ae238"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-82179fa9-a53a-42ee-9a62-35e850f3a354\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>13.20</td>\n",
              "      <td>17.43</td>\n",
              "      <td>84.13</td>\n",
              "      <td>541.6</td>\n",
              "      <td>0.07215</td>\n",
              "      <td>0.04524</td>\n",
              "      <td>0.043360</td>\n",
              "      <td>0.011050</td>\n",
              "      <td>0.1487</td>\n",
              "      <td>0.05635</td>\n",
              "      <td>...</td>\n",
              "      <td>13.94</td>\n",
              "      <td>27.82</td>\n",
              "      <td>88.28</td>\n",
              "      <td>602.0</td>\n",
              "      <td>0.11010</td>\n",
              "      <td>0.15080</td>\n",
              "      <td>0.22980</td>\n",
              "      <td>0.04970</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.07198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>11.22</td>\n",
              "      <td>33.81</td>\n",
              "      <td>70.79</td>\n",
              "      <td>386.8</td>\n",
              "      <td>0.07780</td>\n",
              "      <td>0.03574</td>\n",
              "      <td>0.004967</td>\n",
              "      <td>0.006434</td>\n",
              "      <td>0.1845</td>\n",
              "      <td>0.05828</td>\n",
              "      <td>...</td>\n",
              "      <td>12.36</td>\n",
              "      <td>41.78</td>\n",
              "      <td>78.44</td>\n",
              "      <td>470.9</td>\n",
              "      <td>0.09994</td>\n",
              "      <td>0.06885</td>\n",
              "      <td>0.02318</td>\n",
              "      <td>0.03002</td>\n",
              "      <td>0.2911</td>\n",
              "      <td>0.07307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>14.54</td>\n",
              "      <td>27.54</td>\n",
              "      <td>96.73</td>\n",
              "      <td>658.8</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.15950</td>\n",
              "      <td>0.163900</td>\n",
              "      <td>0.073640</td>\n",
              "      <td>0.2303</td>\n",
              "      <td>0.07077</td>\n",
              "      <td>...</td>\n",
              "      <td>17.46</td>\n",
              "      <td>37.13</td>\n",
              "      <td>124.10</td>\n",
              "      <td>943.2</td>\n",
              "      <td>0.16780</td>\n",
              "      <td>0.65770</td>\n",
              "      <td>0.70260</td>\n",
              "      <td>0.17120</td>\n",
              "      <td>0.4218</td>\n",
              "      <td>0.13410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>15.10</td>\n",
              "      <td>16.39</td>\n",
              "      <td>99.58</td>\n",
              "      <td>674.5</td>\n",
              "      <td>0.11500</td>\n",
              "      <td>0.18070</td>\n",
              "      <td>0.113800</td>\n",
              "      <td>0.085340</td>\n",
              "      <td>0.2001</td>\n",
              "      <td>0.06467</td>\n",
              "      <td>...</td>\n",
              "      <td>16.11</td>\n",
              "      <td>18.33</td>\n",
              "      <td>105.90</td>\n",
              "      <td>762.6</td>\n",
              "      <td>0.13860</td>\n",
              "      <td>0.28830</td>\n",
              "      <td>0.19600</td>\n",
              "      <td>0.14230</td>\n",
              "      <td>0.2590</td>\n",
              "      <td>0.07779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>17.29</td>\n",
              "      <td>22.13</td>\n",
              "      <td>114.40</td>\n",
              "      <td>947.8</td>\n",
              "      <td>0.08999</td>\n",
              "      <td>0.12730</td>\n",
              "      <td>0.096970</td>\n",
              "      <td>0.075070</td>\n",
              "      <td>0.2108</td>\n",
              "      <td>0.05464</td>\n",
              "      <td>...</td>\n",
              "      <td>20.39</td>\n",
              "      <td>27.24</td>\n",
              "      <td>137.90</td>\n",
              "      <td>1295.0</td>\n",
              "      <td>0.11340</td>\n",
              "      <td>0.28670</td>\n",
              "      <td>0.22980</td>\n",
              "      <td>0.15280</td>\n",
              "      <td>0.3067</td>\n",
              "      <td>0.07484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>25.22</td>\n",
              "      <td>24.91</td>\n",
              "      <td>171.50</td>\n",
              "      <td>1878.0</td>\n",
              "      <td>0.10630</td>\n",
              "      <td>0.26650</td>\n",
              "      <td>0.333900</td>\n",
              "      <td>0.184500</td>\n",
              "      <td>0.1829</td>\n",
              "      <td>0.06782</td>\n",
              "      <td>...</td>\n",
              "      <td>30.00</td>\n",
              "      <td>33.62</td>\n",
              "      <td>211.70</td>\n",
              "      <td>2562.0</td>\n",
              "      <td>0.15730</td>\n",
              "      <td>0.60760</td>\n",
              "      <td>0.64760</td>\n",
              "      <td>0.28670</td>\n",
              "      <td>0.2355</td>\n",
              "      <td>0.10510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>10.80</td>\n",
              "      <td>9.71</td>\n",
              "      <td>68.77</td>\n",
              "      <td>357.6</td>\n",
              "      <td>0.09594</td>\n",
              "      <td>0.05736</td>\n",
              "      <td>0.025310</td>\n",
              "      <td>0.016980</td>\n",
              "      <td>0.1381</td>\n",
              "      <td>0.06400</td>\n",
              "      <td>...</td>\n",
              "      <td>11.60</td>\n",
              "      <td>12.02</td>\n",
              "      <td>73.66</td>\n",
              "      <td>414.0</td>\n",
              "      <td>0.14360</td>\n",
              "      <td>0.12570</td>\n",
              "      <td>0.10470</td>\n",
              "      <td>0.04603</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.07699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>11.06</td>\n",
              "      <td>14.96</td>\n",
              "      <td>71.49</td>\n",
              "      <td>373.9</td>\n",
              "      <td>0.10330</td>\n",
              "      <td>0.09097</td>\n",
              "      <td>0.053970</td>\n",
              "      <td>0.033410</td>\n",
              "      <td>0.1776</td>\n",
              "      <td>0.06907</td>\n",
              "      <td>...</td>\n",
              "      <td>11.92</td>\n",
              "      <td>19.90</td>\n",
              "      <td>79.76</td>\n",
              "      <td>440.0</td>\n",
              "      <td>0.14180</td>\n",
              "      <td>0.22100</td>\n",
              "      <td>0.22990</td>\n",
              "      <td>0.10750</td>\n",
              "      <td>0.3301</td>\n",
              "      <td>0.09080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>11.99</td>\n",
              "      <td>24.89</td>\n",
              "      <td>77.61</td>\n",
              "      <td>441.3</td>\n",
              "      <td>0.10300</td>\n",
              "      <td>0.09218</td>\n",
              "      <td>0.054410</td>\n",
              "      <td>0.042740</td>\n",
              "      <td>0.1820</td>\n",
              "      <td>0.06850</td>\n",
              "      <td>...</td>\n",
              "      <td>12.98</td>\n",
              "      <td>30.36</td>\n",
              "      <td>84.48</td>\n",
              "      <td>513.9</td>\n",
              "      <td>0.13110</td>\n",
              "      <td>0.18220</td>\n",
              "      <td>0.16090</td>\n",
              "      <td>0.12020</td>\n",
              "      <td>0.2599</td>\n",
              "      <td>0.08251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>12.39</td>\n",
              "      <td>17.48</td>\n",
              "      <td>80.64</td>\n",
              "      <td>462.9</td>\n",
              "      <td>0.10420</td>\n",
              "      <td>0.12970</td>\n",
              "      <td>0.058920</td>\n",
              "      <td>0.028800</td>\n",
              "      <td>0.1779</td>\n",
              "      <td>0.06588</td>\n",
              "      <td>...</td>\n",
              "      <td>14.18</td>\n",
              "      <td>23.13</td>\n",
              "      <td>95.23</td>\n",
              "      <td>600.5</td>\n",
              "      <td>0.14270</td>\n",
              "      <td>0.35930</td>\n",
              "      <td>0.32060</td>\n",
              "      <td>0.09804</td>\n",
              "      <td>0.2819</td>\n",
              "      <td>0.11180</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>398 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82179fa9-a53a-42ee-9a62-35e850f3a354')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82179fa9-a53a-42ee-9a62-35e850f3a354 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82179fa9-a53a-42ee-9a62-35e850f3a354');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "246        13.20         17.43           84.13      541.6          0.07215   \n",
              "232        11.22         33.81           70.79      386.8          0.07780   \n",
              "15         14.54         27.54           96.73      658.8          0.11390   \n",
              "128        15.10         16.39           99.58      674.5          0.11500   \n",
              "262        17.29         22.13          114.40      947.8          0.08999   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "82         25.22         24.91          171.50     1878.0          0.10630   \n",
              "166        10.80          9.71           68.77      357.6          0.09594   \n",
              "342        11.06         14.96           71.49      373.9          0.10330   \n",
              "445        11.99         24.89           77.61      441.3          0.10300   \n",
              "383        12.39         17.48           80.64      462.9          0.10420   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "246           0.04524        0.043360             0.011050         0.1487   \n",
              "232           0.03574        0.004967             0.006434         0.1845   \n",
              "15            0.15950        0.163900             0.073640         0.2303   \n",
              "128           0.18070        0.113800             0.085340         0.2001   \n",
              "262           0.12730        0.096970             0.075070         0.2108   \n",
              "..                ...             ...                  ...            ...   \n",
              "82            0.26650        0.333900             0.184500         0.1829   \n",
              "166           0.05736        0.025310             0.016980         0.1381   \n",
              "342           0.09097        0.053970             0.033410         0.1776   \n",
              "445           0.09218        0.054410             0.042740         0.1820   \n",
              "383           0.12970        0.058920             0.028800         0.1779   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "246                 0.05635  ...         13.94          27.82   \n",
              "232                 0.05828  ...         12.36          41.78   \n",
              "15                  0.07077  ...         17.46          37.13   \n",
              "128                 0.06467  ...         16.11          18.33   \n",
              "262                 0.05464  ...         20.39          27.24   \n",
              "..                      ...  ...           ...            ...   \n",
              "82                  0.06782  ...         30.00          33.62   \n",
              "166                 0.06400  ...         11.60          12.02   \n",
              "342                 0.06907  ...         11.92          19.90   \n",
              "445                 0.06850  ...         12.98          30.36   \n",
              "383                 0.06588  ...         14.18          23.13   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "246            88.28       602.0           0.11010            0.15080   \n",
              "232            78.44       470.9           0.09994            0.06885   \n",
              "15            124.10       943.2           0.16780            0.65770   \n",
              "128           105.90       762.6           0.13860            0.28830   \n",
              "262           137.90      1295.0           0.11340            0.28670   \n",
              "..               ...         ...               ...                ...   \n",
              "82            211.70      2562.0           0.15730            0.60760   \n",
              "166            73.66       414.0           0.14360            0.12570   \n",
              "342            79.76       440.0           0.14180            0.22100   \n",
              "445            84.48       513.9           0.13110            0.18220   \n",
              "383            95.23       600.5           0.14270            0.35930   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "246          0.22980               0.04970          0.2767   \n",
              "232          0.02318               0.03002          0.2911   \n",
              "15           0.70260               0.17120          0.4218   \n",
              "128          0.19600               0.14230          0.2590   \n",
              "262          0.22980               0.15280          0.3067   \n",
              "..               ...                   ...             ...   \n",
              "82           0.64760               0.28670          0.2355   \n",
              "166          0.10470               0.04603          0.2090   \n",
              "342          0.22990               0.10750          0.3301   \n",
              "445          0.16090               0.12020          0.2599   \n",
              "383          0.32060               0.09804          0.2819   \n",
              "\n",
              "     worst fractal dimension  \n",
              "246                  0.07198  \n",
              "232                  0.07307  \n",
              "15                   0.13410  \n",
              "128                  0.07779  \n",
              "262                  0.07484  \n",
              "..                       ...  \n",
              "82                   0.10510  \n",
              "166                  0.07699  \n",
              "342                  0.09080  \n",
              "445                  0.08251  \n",
              "383                  0.11180  \n",
              "\n",
              "[398 rows x 30 columns]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "e5pjq0pjIlWx",
        "outputId": "53f4d988-cb12-4b75-9ff6-07e293667127"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2c9d847f-d6e3-4a58-80ef-20b60cc05fea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>398 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c9d847f-d6e3-4a58-80ef-20b60cc05fea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c9d847f-d6e3-4a58-80ef-20b60cc05fea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c9d847f-d6e3-4a58-80ef-20b60cc05fea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     target\n",
              "246       1\n",
              "232       1\n",
              "15        0\n",
              "128       1\n",
              "262       0\n",
              "..      ...\n",
              "82        0\n",
              "166       1\n",
              "342       1\n",
              "445       1\n",
              "383       1\n",
              "\n",
              "[398 rows x 1 columns]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "k0vJoDw7IlcD",
        "outputId": "24f345c0-556b-48eb-fecb-111629f6172c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bf9ec9f9-ac01-46d2-acd7-059905bac69e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>17.08</td>\n",
              "      <td>27.15</td>\n",
              "      <td>111.20</td>\n",
              "      <td>930.9</td>\n",
              "      <td>0.09898</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.10070</td>\n",
              "      <td>0.06431</td>\n",
              "      <td>0.1793</td>\n",
              "      <td>0.06281</td>\n",
              "      <td>...</td>\n",
              "      <td>22.960</td>\n",
              "      <td>34.49</td>\n",
              "      <td>152.10</td>\n",
              "      <td>1648.0</td>\n",
              "      <td>0.16000</td>\n",
              "      <td>0.24440</td>\n",
              "      <td>0.26390</td>\n",
              "      <td>0.15550</td>\n",
              "      <td>0.3010</td>\n",
              "      <td>0.09060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>12.77</td>\n",
              "      <td>22.47</td>\n",
              "      <td>81.72</td>\n",
              "      <td>506.3</td>\n",
              "      <td>0.09055</td>\n",
              "      <td>0.05761</td>\n",
              "      <td>0.04711</td>\n",
              "      <td>0.02704</td>\n",
              "      <td>0.1585</td>\n",
              "      <td>0.06065</td>\n",
              "      <td>...</td>\n",
              "      <td>14.490</td>\n",
              "      <td>33.37</td>\n",
              "      <td>92.04</td>\n",
              "      <td>653.6</td>\n",
              "      <td>0.14190</td>\n",
              "      <td>0.15230</td>\n",
              "      <td>0.21770</td>\n",
              "      <td>0.09331</td>\n",
              "      <td>0.2829</td>\n",
              "      <td>0.08067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>14.25</td>\n",
              "      <td>22.15</td>\n",
              "      <td>96.42</td>\n",
              "      <td>645.7</td>\n",
              "      <td>0.10490</td>\n",
              "      <td>0.20080</td>\n",
              "      <td>0.21350</td>\n",
              "      <td>0.08653</td>\n",
              "      <td>0.1949</td>\n",
              "      <td>0.07292</td>\n",
              "      <td>...</td>\n",
              "      <td>17.670</td>\n",
              "      <td>29.51</td>\n",
              "      <td>119.10</td>\n",
              "      <td>959.5</td>\n",
              "      <td>0.16400</td>\n",
              "      <td>0.62470</td>\n",
              "      <td>0.69220</td>\n",
              "      <td>0.17850</td>\n",
              "      <td>0.2844</td>\n",
              "      <td>0.11320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>12.45</td>\n",
              "      <td>16.41</td>\n",
              "      <td>82.85</td>\n",
              "      <td>476.7</td>\n",
              "      <td>0.09514</td>\n",
              "      <td>0.15110</td>\n",
              "      <td>0.15440</td>\n",
              "      <td>0.04846</td>\n",
              "      <td>0.2082</td>\n",
              "      <td>0.07325</td>\n",
              "      <td>...</td>\n",
              "      <td>13.780</td>\n",
              "      <td>21.03</td>\n",
              "      <td>97.82</td>\n",
              "      <td>580.6</td>\n",
              "      <td>0.11750</td>\n",
              "      <td>0.40610</td>\n",
              "      <td>0.48960</td>\n",
              "      <td>0.13420</td>\n",
              "      <td>0.3231</td>\n",
              "      <td>0.10340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>16.35</td>\n",
              "      <td>23.29</td>\n",
              "      <td>109.00</td>\n",
              "      <td>840.4</td>\n",
              "      <td>0.09742</td>\n",
              "      <td>0.14970</td>\n",
              "      <td>0.18110</td>\n",
              "      <td>0.08773</td>\n",
              "      <td>0.2175</td>\n",
              "      <td>0.06218</td>\n",
              "      <td>...</td>\n",
              "      <td>19.380</td>\n",
              "      <td>31.03</td>\n",
              "      <td>129.30</td>\n",
              "      <td>1165.0</td>\n",
              "      <td>0.14150</td>\n",
              "      <td>0.46650</td>\n",
              "      <td>0.70870</td>\n",
              "      <td>0.22480</td>\n",
              "      <td>0.4824</td>\n",
              "      <td>0.09614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>14.86</td>\n",
              "      <td>16.94</td>\n",
              "      <td>94.89</td>\n",
              "      <td>673.7</td>\n",
              "      <td>0.08924</td>\n",
              "      <td>0.07074</td>\n",
              "      <td>0.03346</td>\n",
              "      <td>0.02877</td>\n",
              "      <td>0.1573</td>\n",
              "      <td>0.05703</td>\n",
              "      <td>...</td>\n",
              "      <td>16.310</td>\n",
              "      <td>20.54</td>\n",
              "      <td>102.30</td>\n",
              "      <td>777.5</td>\n",
              "      <td>0.12180</td>\n",
              "      <td>0.15500</td>\n",
              "      <td>0.12200</td>\n",
              "      <td>0.07971</td>\n",
              "      <td>0.2525</td>\n",
              "      <td>0.06827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>13.61</td>\n",
              "      <td>24.98</td>\n",
              "      <td>88.05</td>\n",
              "      <td>582.7</td>\n",
              "      <td>0.09488</td>\n",
              "      <td>0.08511</td>\n",
              "      <td>0.08625</td>\n",
              "      <td>0.04489</td>\n",
              "      <td>0.1609</td>\n",
              "      <td>0.05871</td>\n",
              "      <td>...</td>\n",
              "      <td>16.990</td>\n",
              "      <td>35.27</td>\n",
              "      <td>108.60</td>\n",
              "      <td>906.5</td>\n",
              "      <td>0.12650</td>\n",
              "      <td>0.19430</td>\n",
              "      <td>0.31690</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.2651</td>\n",
              "      <td>0.07397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>13.00</td>\n",
              "      <td>20.78</td>\n",
              "      <td>83.51</td>\n",
              "      <td>519.4</td>\n",
              "      <td>0.11350</td>\n",
              "      <td>0.07589</td>\n",
              "      <td>0.03136</td>\n",
              "      <td>0.02645</td>\n",
              "      <td>0.2540</td>\n",
              "      <td>0.06087</td>\n",
              "      <td>...</td>\n",
              "      <td>14.160</td>\n",
              "      <td>24.11</td>\n",
              "      <td>90.82</td>\n",
              "      <td>616.7</td>\n",
              "      <td>0.12970</td>\n",
              "      <td>0.11050</td>\n",
              "      <td>0.08112</td>\n",
              "      <td>0.06296</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>0.06435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>511</th>\n",
              "      <td>14.81</td>\n",
              "      <td>14.70</td>\n",
              "      <td>94.66</td>\n",
              "      <td>680.7</td>\n",
              "      <td>0.08472</td>\n",
              "      <td>0.05016</td>\n",
              "      <td>0.03416</td>\n",
              "      <td>0.02541</td>\n",
              "      <td>0.1659</td>\n",
              "      <td>0.05348</td>\n",
              "      <td>...</td>\n",
              "      <td>15.610</td>\n",
              "      <td>17.58</td>\n",
              "      <td>101.70</td>\n",
              "      <td>760.2</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.10110</td>\n",
              "      <td>0.11010</td>\n",
              "      <td>0.07955</td>\n",
              "      <td>0.2334</td>\n",
              "      <td>0.06142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>9.72</td>\n",
              "      <td>18.22</td>\n",
              "      <td>60.73</td>\n",
              "      <td>288.1</td>\n",
              "      <td>0.06950</td>\n",
              "      <td>0.02344</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1653</td>\n",
              "      <td>0.06447</td>\n",
              "      <td>...</td>\n",
              "      <td>9.968</td>\n",
              "      <td>20.83</td>\n",
              "      <td>62.25</td>\n",
              "      <td>303.8</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1909</td>\n",
              "      <td>0.06559</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>171 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf9ec9f9-ac01-46d2-acd7-059905bac69e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf9ec9f9-ac01-46d2-acd7-059905bac69e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf9ec9f9-ac01-46d2-acd7-059905bac69e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "460        17.08         27.15          111.20      930.9          0.09898   \n",
              "135        12.77         22.47           81.72      506.3          0.09055   \n",
              "62         14.25         22.15           96.42      645.7          0.10490   \n",
              "485        12.45         16.41           82.85      476.7          0.09514   \n",
              "370        16.35         23.29          109.00      840.4          0.09742   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "434        14.86         16.94           94.89      673.7          0.08924   \n",
              "100        13.61         24.98           88.05      582.7          0.09488   \n",
              "150        13.00         20.78           83.51      519.4          0.11350   \n",
              "511        14.81         14.70           94.66      680.7          0.08472   \n",
              "192         9.72         18.22           60.73      288.1          0.06950   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "460           0.11100         0.10070              0.06431         0.1793   \n",
              "135           0.05761         0.04711              0.02704         0.1585   \n",
              "62            0.20080         0.21350              0.08653         0.1949   \n",
              "485           0.15110         0.15440              0.04846         0.2082   \n",
              "370           0.14970         0.18110              0.08773         0.2175   \n",
              "..                ...             ...                  ...            ...   \n",
              "434           0.07074         0.03346              0.02877         0.1573   \n",
              "100           0.08511         0.08625              0.04489         0.1609   \n",
              "150           0.07589         0.03136              0.02645         0.2540   \n",
              "511           0.05016         0.03416              0.02541         0.1659   \n",
              "192           0.02344         0.00000              0.00000         0.1653   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "460                 0.06281  ...        22.960          34.49   \n",
              "135                 0.06065  ...        14.490          33.37   \n",
              "62                  0.07292  ...        17.670          29.51   \n",
              "485                 0.07325  ...        13.780          21.03   \n",
              "370                 0.06218  ...        19.380          31.03   \n",
              "..                      ...  ...           ...            ...   \n",
              "434                 0.05703  ...        16.310          20.54   \n",
              "100                 0.05871  ...        16.990          35.27   \n",
              "150                 0.06087  ...        14.160          24.11   \n",
              "511                 0.05348  ...        15.610          17.58   \n",
              "192                 0.06447  ...         9.968          20.83   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "460           152.10      1648.0           0.16000            0.24440   \n",
              "135            92.04       653.6           0.14190            0.15230   \n",
              "62            119.10       959.5           0.16400            0.62470   \n",
              "485            97.82       580.6           0.11750            0.40610   \n",
              "370           129.30      1165.0           0.14150            0.46650   \n",
              "..               ...         ...               ...                ...   \n",
              "434           102.30       777.5           0.12180            0.15500   \n",
              "100           108.60       906.5           0.12650            0.19430   \n",
              "150            90.82       616.7           0.12970            0.11050   \n",
              "511           101.70       760.2           0.11390            0.10110   \n",
              "192            62.25       303.8           0.07117            0.02729   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "460          0.26390               0.15550          0.3010   \n",
              "135          0.21770               0.09331          0.2829   \n",
              "62           0.69220               0.17850          0.2844   \n",
              "485          0.48960               0.13420          0.3231   \n",
              "370          0.70870               0.22480          0.4824   \n",
              "..               ...                   ...             ...   \n",
              "434          0.12200               0.07971          0.2525   \n",
              "100          0.31690               0.11840          0.2651   \n",
              "150          0.08112               0.06296          0.3196   \n",
              "511          0.11010               0.07955          0.2334   \n",
              "192          0.00000               0.00000          0.1909   \n",
              "\n",
              "     worst fractal dimension  \n",
              "460                  0.09060  \n",
              "135                  0.08067  \n",
              "62                   0.11320  \n",
              "485                  0.10340  \n",
              "370                  0.09614  \n",
              "..                       ...  \n",
              "434                  0.06827  \n",
              "100                  0.07397  \n",
              "150                  0.06435  \n",
              "511                  0.06142  \n",
              "192                  0.06559  \n",
              "\n",
              "[171 rows x 30 columns]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "joZSDcGzIlo4",
        "outputId": "004ca059-526b-4d73-c50b-5380f6019558"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7c1bed8f-c098-42f4-b7c5-50cd90c8e851\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>511</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>171 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c1bed8f-c098-42f4-b7c5-50cd90c8e851')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c1bed8f-c098-42f4-b7c5-50cd90c8e851 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c1bed8f-c098-42f4-b7c5-50cd90c8e851');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     target\n",
              "460       0\n",
              "135       0\n",
              "62        0\n",
              "485       1\n",
              "370       0\n",
              "..      ...\n",
              "434       1\n",
              "100       0\n",
              "150       1\n",
              "511       1\n",
              "192       1\n",
              "\n",
              "[171 rows x 1 columns]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elJ87AHnKp0t"
      },
      "source": [
        "#### XGBoost for Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX6uFoxntutW"
      },
      "source": [
        "Set up the XGBoost model. Name it as `classifier_XGB`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apugvOWmtt8G",
        "outputId": "c114e71c-060d-4b81-d856-f4e16f5638df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=0)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "classifier_XGB = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
        "classifier_XGB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV3-d1_6t3cf"
      },
      "source": [
        "Fit the XGBoost model using the input `X_train` and output `y_train`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZi_gQXvt9zz",
        "outputId": "e7b37997-281c-4412-c26b-0624a22269d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=0)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_XGB.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBdQJKdot7A_"
      },
      "source": [
        "Make predictions on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LVRfYuUt-Nv",
        "outputId": "b1d744b7-0925-445d-d464-6f7aada70222"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
              "       0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "XGB_pred = classifier_XGB.predict(X_test)\n",
        "XGB_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIQhfBLiK0Zn"
      },
      "source": [
        "#### Support Vector Machine for Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp-UWCS8uBY0"
      },
      "source": [
        "Set up the SVM model. Name it as `classifier_SVM`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-RYcxNYuQRJ",
        "outputId": "af150a16-6fc7-438f-d4f2-3ebddff71109"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SVC(gamma='auto')"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier_SVM = SVC(gamma='auto')\n",
        "classifier_SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWx1-qp-uBjO"
      },
      "source": [
        "Fit the SVM model using the input `X_train` and output `y_train`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAIa6UZsuQx5",
        "outputId": "9cd47209-f6f8-4453-88e2-f160f43cdccd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SVC(gamma='auto')"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_SVM.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIcdWkkyuBue"
      },
      "source": [
        "Make predictions on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e-BwZvnuROf",
        "outputId": "607a7f32-0c06-435b-ed9d-90942c093121"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SVM_pred = classifier_SVM.predict(X_test)\n",
        "SVM_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1fxh88pvQzj"
      },
      "source": [
        "#### Performance Assessment\n",
        "\n",
        "*   Accuracy\n",
        "*   Sensitivity\n",
        "*   Specificity\n",
        "*   AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlOUmIEUz2z0"
      },
      "source": [
        "First, let's compute the confusion matrix for predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDaIRwwW4BZi"
      },
      "source": [
        "For example: for Naive Bayes's prediction, we have:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqsmOh8fz9Gn",
        "outputId": "2ab94478-5e06-4ceb-d426-5e84736da852"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix for Naive Bayes: \n",
            " [[ 57   7]\n",
            " [  6 101]]\n",
            "Accuracy for Naive Bayes:  0.9239766081871345\n",
            "Sensitivity for Naive Bayes:  0.890625\n",
            "Specificity for Naive Bayes:  0.9439252336448598\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#Compute the confusion matrix\n",
        "cmNB = confusion_matrix(y_test,NB_pred)\n",
        "print('Confusion Matrix for Naive Bayes: \\n', cmNB)\n",
        "#Compute total test cases\n",
        "totalNB=sum(sum(cmNB))\n",
        "#####from confusion matrix calculate accuracy\n",
        "accuracyNB=(cmNB[0,0]+cmNB[1,1])/totalNB\n",
        "print ('Accuracy for Naive Bayes: ', accuracyNB)\n",
        "\n",
        "sensitivityNB = cmNB[0,0]/(cmNB[0,0]+cmNB[0,1])\n",
        "print('Sensitivity for Naive Bayes: ', sensitivityNB)\n",
        "\n",
        "specificityNB = cmNB[1,1]/(cmNB[1,0]+cmNB[1,1])\n",
        "print('Specificity for Naive Bayes: ', specificityNB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ekaseon1kDu"
      },
      "source": [
        "Then, we compute the AUC. We use the `roc_auc_score` from `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8eqsAS210uf",
        "outputId": "971a77a0-ccbe-4023-dadd-c481cc0fba2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC for Naive Bayes:  0.9767815420560748\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#We first compute the probability output from the Naive Bayes classifier\n",
        "NB_prob = classifier_NB.predict_proba(X_test)\n",
        "\n",
        "#We compute the AUC score\n",
        "aucNB = roc_auc_score(y_test,NB_prob[:,1])\n",
        "print('AUC for Naive Bayes: ', aucNB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX7SnsiDWQ43"
      },
      "source": [
        "## Unsupervised Learning - Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORhQRZbv7Cwc"
      },
      "source": [
        "#### Dataset Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5MeAadHWQ44"
      },
      "source": [
        "Lastly we want to consider an unsupervised learning problem, where we don't actually have an outcome at all, or our data is \"unlabeled.\" Instead of predicting something we just want to find patterns and structure in our data.\n",
        "\n",
        "Our data can be unlabeled for two reasons:\n",
        "\n",
        "• First, maybe our data does not have well-defined groupings. An example might be a company's customers: there are not clear and distinct groups that we can put people in. \n",
        "\n",
        "• Second, maybe the label of our data is missing. Suppose you are a wine vendor and you ordered three types of wine from your supplier. When you receive your wine shipment, however, you realize that the labels were not put on. You may want to learn about how the different wine bottles are related to one another to make an educated guess on which is what wine type.\n",
        "\n",
        "Our example below falls in this second case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "SL-PO7LrWQ45"
      },
      "outputs": [],
      "source": [
        "wine = datasets.load_wine(as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_SCElBgWQ45",
        "outputId": "2da23c14-9dc9-4f02-c95e-1c6a13c61be5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n",
              "       'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n",
              "       'proanthocyanins', 'color_intensity', 'hue',\n",
              "       'od280/od315_of_diluted_wines', 'proline'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wine.data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "4l4wK5z5YUC6",
        "outputId": "ac30d0dd-42ee-4cee-b958-aaf136904852"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c6e1e5b2-5f35-4ca5-9d88-01d41f37c0fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6e1e5b2-5f35-4ca5-9d88-01d41f37c0fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6e1e5b2-5f35-4ca5-9d88-01d41f37c0fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6e1e5b2-5f35-4ca5-9d88-01d41f37c0fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "..       ...         ...   ...                ...        ...            ...   \n",
              "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
              "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
              "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
              "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
              "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
              "\n",
              "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0          3.06                  0.28             2.29             5.64  1.04   \n",
              "1          2.76                  0.26             1.28             4.38  1.05   \n",
              "2          3.24                  0.30             2.81             5.68  1.03   \n",
              "3          3.49                  0.24             2.18             7.80  0.86   \n",
              "4          2.69                  0.39             1.82             4.32  1.04   \n",
              "..          ...                   ...              ...              ...   ...   \n",
              "173        0.61                  0.52             1.06             7.70  0.64   \n",
              "174        0.75                  0.43             1.41             7.30  0.70   \n",
              "175        0.69                  0.43             1.35            10.20  0.59   \n",
              "176        0.68                  0.53             1.46             9.30  0.60   \n",
              "177        0.76                  0.56             1.35             9.20  0.61   \n",
              "\n",
              "     od280/od315_of_diluted_wines  proline  \n",
              "0                            3.92   1065.0  \n",
              "1                            3.40   1050.0  \n",
              "2                            3.17   1185.0  \n",
              "3                            3.45   1480.0  \n",
              "4                            2.93    735.0  \n",
              "..                            ...      ...  \n",
              "173                          1.74    740.0  \n",
              "174                          1.56    750.0  \n",
              "175                          1.56    835.0  \n",
              "176                          1.62    840.0  \n",
              "177                          1.60    560.0  \n",
              "\n",
              "[178 rows x 13 columns]"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wine.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e5r4Un57I2-"
      },
      "source": [
        "#### Initialize the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzcQqq5r-QNs"
      },
      "source": [
        "Initialize the dataset as `X`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ffGyVj1w-S7v"
      },
      "outputs": [],
      "source": [
        "X= wine.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    71\n",
              "0    59\n",
              "2    48\n",
              "Name: target, dtype: int64"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wine.target.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0yRsiFz-_K0"
      },
      "source": [
        "#### Clustering using K-Means algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gyXR2eUBcfO"
      },
      "source": [
        "##### Intialize the K-Means Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u22oqn0-IRO"
      },
      "source": [
        "The K-Mean algorithm is included in the Scikit-leanr library. Define the number of clusters by `n_clusters` and random initialization state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN01QBb4-Pdt",
        "outputId": "bee71b5a-38c7-4edd-d72c-045d5c1333ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KMeans(n_clusters=3, random_state=0)"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "#Here we set n=3 in this workshop\n",
        "cluster_KMeans = KMeans(n_clusters =3, random_state=0)\n",
        "cluster_KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGumzwgl-1xt"
      },
      "source": [
        "##### Fit and predict using K-Mean algorithm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DJRbWuJ_cBG"
      },
      "source": [
        "Fit the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_ch__Ce-1Gx",
        "outputId": "63a9b541-9617-4f37-d5d1-7bde072c6da5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KMeans(n_clusters=3, random_state=0)"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cluster_KMeans.fit(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icvv8h9z_Oh8"
      },
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weBqEwxW_hoE",
        "outputId": "54343e0c-2609-4edb-8a6a-28e6810c4575"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 2, 0, 2, 2, 0,\n",
              "       2, 2, 0, 0, 0, 2, 2, 1, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2,\n",
              "       0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0,\n",
              "       2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2,\n",
              "       2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 2, 0,\n",
              "       0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0,\n",
              "       0, 2], dtype=int32)"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cluster_labels = cluster_KMeans.predict(X)\n",
        "cluster_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEL2KmZH1e3y"
      },
      "source": [
        "Compute inner cluster distances (Euclidean distances) within all clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLcypDGJ1kSZ",
        "outputId": "502808f9-3700-4382-ca85-d6dc43cd558c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2370689.686782969"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cluster_KMeans.inertia_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2VQS91NBUJN"
      },
      "source": [
        "##### Find the BEST k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcA2Ed-z1toI"
      },
      "source": [
        "Now, let's try different numbers of k to see how cluster centers change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "yVW1JGmP1s0P"
      },
      "outputs": [],
      "source": [
        "#Store the sum of inner cluster distances in a list and name is as dist\n",
        "dist=[]\n",
        "\n",
        "for i in range(2,11):\n",
        "  #Run k-mean clustering with i centers\n",
        "  cluster_KMeans = KMeans(n_clusters =i, random_state=0)\n",
        "  cluster_KMeans.fit(X)\n",
        "  #Store the summed inner cluster distances into the list namely 'dist'\n",
        "  dist.append(cluster_KMeans.inertia_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aRiilxo8bGJ"
      },
      "source": [
        "Display the inner cluster distances for all k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPTDSExDBY0v",
        "outputId": "38f29446-7c42-426e-868c-1b09a61bfca8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[4543877.621627203,\n",
              " 2370689.686782969,\n",
              " 1331920.430684771,\n",
              " 916415.1871539169,\n",
              " 647362.0020260848,\n",
              " 412137.5091004584,\n",
              " 324553.044355034,\n",
              " 270954.9292415376,\n",
              " 217887.37856033302]"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNud2CgJ8hYy"
      },
      "source": [
        "Now, let's use `matplotlib` library to visualize the inner cluster distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "dyljMec38NjX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MexfgXCq8o1Y"
      },
      "source": [
        "We can plot the inner cluster distance curve and use Elbow's method to seek for optimal k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "a8w02SxZ8P4j",
        "outputId": "94fb1a0f-6b8d-4085-9799-06c4695687e2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEDCAYAAAAcI05xAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAcbElEQVR4nO3deXDc5Z3n8fe3D52W5EOnJWFj4wPfRgoBEx8YiA1hgYRYIbOB7FY2QIVNQjazqcnM1GTZzFRtdiaZTMJuajxJJgdH1uaGBAcCxiQQDJIPLNv4vmRbl22d1q1n/+i2ET4lW63fr7s/ryqVW92t1qcE+ujp5/n9np855xAREf8KeB1AREQuTEUtIuJzKmoREZ9TUYuI+JyKWkTE51TUIiI+F7OiNrOfm1m9mVUP8vkVZrbNzLaa2ROxyiUiEm8sVsdRm9kioA34lXNu1kWeOwVYBSx1zp0ws3znXH1MgomIxJmYjaidc28CxwfeZ2aTzWyNmVWZ2R/NbHr0oS8D/8c5dyL6tSppEZGokZ6jXgl81TlXBvwl8H+j908FpprZW2b2jpktH+FcIiK+FRqpb2Rmo4AFwGozO3V36oAcU4AlQAnwppnNds41jVQ+ERG/GrGiJjJ6b3LOzTvHYzXAeudcD7DPzHYSKe73RjCfiIgvjdjUh3OuhUgJrwCwiLnRh58jMprGzHKJTIXsHalsIiJ+FsvD854E/gxMM7MaM/sS8B+BL5nZZmArcGf06b8HjpnZNmAt8N+dc8dilU1EJJ7E7PA8EREZHjozUUTE52KymJibm+smTpwYi5cWEUlIVVVVjc65vHM9FpOinjhxIpWVlbF4aRGRhGRmB873mKY+RER8TkUtIuJzKmoREZ9TUYuI+JyKWkTE51TUIiI+p6IWEfE53xR1Z08f//bmXt7e3eh1FBERX/FNUYcCxso/7uXnb+3zOoqIiK/4p6iDAe6+poS1Oxqob+n0Oo6IiG/4pqgBVpSX0NfveGbjYa+jiIj4hq+KenLeKMonjGFV5SG0/aqISISvihqgoryUvQ3tbDh4wusoIiK+4Luivm1OERkpQVa9V+N1FBERX/BdUY9KDfGp2UW89P4R2rt6vY4jIuI53xU1QMXHSmnv7uN3W456HUVExHO+LOryCWOYlJvJ6kpNf4iI+LKozYwV5aW8u/84exvavI4jIuIpXxY1wN3XFBMMGKurNKoWkeTm26LOz05jydQ8nq6qobev3+s4IiKe8W1RA6woL6W+tYs3dzV4HUVExDO+Luql0/MZl5miY6pFJKn5uqhTQgE+Pb+YP2yv41hbl9dxREQ84euihsj0R2+/41lt1CQiScr3RT2tMIu5paO1UZOIJC3fFzVARXkJO+vaeL+m2esoIiIjLi6K+j/MHU9qKMCqykNeRxERGXFxUdTZaWFum13EC5uO0NHd53UcEZERFRdFDZGrv7R29fL7rbVeRxERGVFxU9TXXTmOK8ZmaPpDRJLOoIvazIJmttHMXoploPMJBIwVZSW8vecYB4+d9CKCiIgnhjKi/jqwPVZBBuPushLM4KkqjapFJHkMqqjNrAT4FPDT2Ma5sPGj01k4JY+nqmro69cx1SKSHAY7ov4h8C3gvNvYmdn9ZlZpZpUNDbHbRKmivIQjzZ28tbsxZt9DRMRPLlrUZnY7UO+cq7rQ85xzK51z5c658ry8vGELeKZbZhQwOiOsRUURSRqDGVHfANxhZvuB3wBLzeyxmKa6gNRQkLvmFfPK1jqaTnZ7FUNEZMRctKidc992zpU45yYC9wCvO+e+EPNkF7CivITuvn6e33TEyxgiIiMibo6jHmjm+Bxmjs/W9IeIJIUhFbVz7g3n3O2xCjMUFeWlbD3SQvVhbdQkIoktLkfUAHfOG09KMMBTuvitiCS4uC3q0RkpfHJmAc9uPExnjzZqEpHEFbdFDfC5j5XS3NHDH7bXeR1FRCRm4rqoF0zOpXh0OqsqNf0hIokrros6GDDuLivhj7saONzU4XUcEZGYiOuiBlhRVoJz8LQWFUUkQcV9UZeOzWDB5HGsrjpEvzZqEpEEFPdFDZFjqg8d7+Cdfce8jiIiMuwSoqiXzyokKy3Eai0qikgCSoiiTgsHuWPueH635SgtnT1exxERGVYJUdQQmf7o6u3nxc3aqElEEkvCFPWckhymFWTpmGoRSTgJU9RmxoryEjYfamJHbavXcUREhk3CFDXAp+cXEwoYq7X9qYgkkIQq6nGjUrn56shGTd295728o4hIXEmooobIRk3H2rt5/YN6r6OIiAyLhCvqhVNyKchO1fSHiCSMhCvqUDDA3deUsHZHPXUtnV7HERG5bAlX1AArykvpd/D0Bh2qJyLxLyGL+srcTK6dOJbVlTU4p42aRCS+JWRRA6woL2FfYzuVB054HUVE5LIkbFHfNruIzJQgq97ToqKIxLeELerM1BC3zxnPb7ccpa2r1+s4IiKXLGGLGqDiYyWc7O7jd+8f9TqKiMglS+iivuaKMUzKy2SVjqkWkTiW0EVtZlSUl1J54AR7Gtq8jiMickkSuqgBPnNNMcGA6eovIhK3Er6o87PSuHFaPk9vqKG3Txs1iUj8SfiiBqgoL6GhtYt1Oxu8jiIiMmRJUdQ3Ts8nd1SKFhVFJC4lRVGHgwE+c00Jr22vp6G1y+s4IiJDkhRFDbCirITefsdzGw97HUVEZEiSpqinFGQx/4rRrKo8pI2aRCSuJE1RA1SUl7Krvo1Nh5q8jiIiMmhJVdS3zykiLRxglY6pFpE4klRFnZUW5rbZRby4+Qgd3X1exxERGZSkKmqITH+0dfXycrU2ahKR+HDRojazNDN718w2m9lWM3tkJILFysevHMuEcRk6plpE4sZgRtRdwFLn3FxgHrDczK6LaaoYMjNWlJXwzt7jHDjW7nUcEZGLumhRu4hTW8+Fox9xfXzb3WUlBAyeqtKiooj436DmqM0saGabgHrgVefc+nM8534zqzSzyoYGf++pUZSTzqKpeTxVVUNff1z/zRGRJDCoonbO9Tnn5gElwLVmNuscz1npnCt3zpXn5eUNc8zhV1FeytHmTv60u9HrKCIiFzSkoz6cc03AWmB5TNKMoJuuzmdMRliLiiLie4M56iPPzEZHb6cDtwAfxDhXzKWGgtw1v5hXt9Zxor3b6zgiIuc1mBF1EbDWzN4H3iMyR/1SbGONjBVlpXT39fPcJm3UJCL+FbrYE5xz7wPzRyDLiJsxPpvZxTn8v/cO8Z8WTMTMvI4kInKWpDsz8UwV5SV8UNvK1iMtXkcRETmnpC/qO+YWkxIKaFFRRHwr6Ys6JyPM8pmFPLfxMJ092qhJRPwn6YsaIsdUt3T28sq2Oq+jiIicRUUNLJg8juLR6azW9IeI+JCKGggEjM+WlfCn3Y3UnDjpdRwRkY9QUUetKC8B4OkqHVMtIv6ioo4qGZPBDZNzWV11iH5t1CQiPqKiHmBFeQk1Jzp4Z+8xr6OIiJymoh5g2cxCstNCOqZaRHxFRT1AWjjInfOKebm6luaOHq/jiIgAKuqzVJSX0tXbzwubj3gdRUQEUFGfZVZxNtMLs3RMtYj4hor6DGZGRXkp79c0s/2oNmoSEe+pqM/hrvnFhIPG6kpd/FZEvKeiPoexmSncMqOAZzfW0N3b73UcEUlyKurzWFFeyomTPby2XRs1iYi3VNTnsWhKHoXZaTqmWkQ8p6I+j2DAuLusmHU7G6ht7vQ6jogkMRX1BawoK6XfwdMbtKgoIt5RUV/AxNxMPn7lWFZXHsI5bdQkIt5QUV9ERXkp+4+d5L39J7yOIiJJSkV9EbfOLiQrNcQ/vbKDnj4dqiciI09FfREZKSH+510zeXffcf7ht9u9jiMiSSjkdYB48On5JWypaeHnb+1jdnEOd5eVeB1JRJKIRtSD9Ne3TWfB5HF8+9ktvF/T5HUcEUkiKupBCgUDPPoX15A3KpUHfl1FQ2uX15FEJEmoqIdgbGYK/3pvGSdOdvPQExu0uCgiI0JFPUSzinP43t1zeHffcf7+pW1exxGRJKDFxEtw57xittQ089M/7WNWcQ4ryku9jiQiCUwj6kv0V7dO54arxvE3z1Wz6VCT13FEJIGpqC9RKBjg0c9fQ35WKg/+uor6Vm3cJCKxoaK+DGMyU1h5bzlNHd089PgGXWRARGJCRX2ZZozP5n9/di7v7T/Bd7W4KCIxoMXEYXDH3PFUH25m5Zt7mV2cQ8XHtLgoIsNHI+ph8q1l01g4JZe/fa6ajQe1056IDJ+LFrWZlZrZWjPbZmZbzezrIxEs3oSCAX78+fkU5KTy4GNaXBSR4TOYEXUv8E3n3AzgOuAhM5sR21jxaXRGZHGxpaOXrzymxUURGR4XLWrn3FHn3Ibo7VZgO1Ac62Dx6uqibP5xxRwqD5zgkRe3eh1HRBLAkOaozWwiMB9Yf47H7jezSjOrbGhoGKZ48en2OeN5YPEkHl9/kN+8e9DrOCIS5wZd1GY2CngaeNg513Lm4865lc65cudceV5e3nBmjEvfWjadhVNy+bvnt7JBi4sichkGVdRmFiZS0o87556JbaTEEAwYP/78fApz0iJnLrZocVFELs1gjvow4GfAdufcD2IfKXGMzkhh5X1ltHX18uBjVXT19nkdSUTi0GBG1DcA9wJLzWxT9OO2GOdKGNMLs/nHz85lw8Em/scLOnNRRIbuomcmOuf+BNgIZElYn5pTRPWRyfzkjT3MLs7hLz5+hdeRRCSO6MzEEfKXn5zG4ql5fOeFaqoOHPc6jojEERX1CAkGjB/dM5/xo9N58LEN1GlxUUQGSUU9gnIywqy8t5x2LS6KyBCoqEfYtMIsvr9iLhsPNvGd57finPM6koj4nIraA7fOLuKhGyfzm/cO8fh6nbkoIhemovbIf7tlGkum5fHIi1up3K/FRRE5PxW1R4IB41/umU/JmAwefGwDtc1aXBSRc1NReygnPczKe8vo6O7lgceq6OzR4qKInE1F7bEpBVl8v2Iemw818XfPV2txUUTOoqL2geWzCvnq0qtYVVnDY+8c8DqOiPiMitonvnHzVJZOz+eRF7fx7j4tLorIh1TUPhEIGP/8uXmUjs3gK49XcbS5w+tIIuITKmofyUkP82/3ldHZ08+Dv9bioohEqKh95qr8LH5QMZfNNc387XNaXBQRFbUvfXJmIV+7aQpPVdXwqz9rcVEk2amoferhm6Zw89X5fPelbazfe8zrOCLiIRW1TwUCxg8+N48rxmXwlcc3cKRJi4siyUpF7WPZaZFtUbt6+3lQZy6KJC0Vtc9dlT+Kf/7cPN6vaeZvntXiokgyUlHHgVtmFPDwzVN4ekMNv3h7v9dxRGSEqajjxNeWTuGWGQX8/W+38+c9WlwUSSYq6jgRCBg/qJjLxHEZPPTEBg5rcVEkaaio40hWWpiV95XT09vPA7+u1OKiSJJQUceZyXmj+OE989h6pIVvP7NFi4siSUBFHYduurqAb9w8lWc3HuaRF7dxor3b60giEkMhrwPIpfmvN15FbUsnv/zzflZXHuKLCybyXxZOYmxmitfRRGSYWSzeOpeXl7vKysphf1052866Vn702i5+u+UoGeGgClskTplZlXOu/JyPqagTw666Vn70+m5eev8I6dHC/rIKWyRuqKiTiApbJD6pqJPQrrpWfvz6bl6MFvZ910/kywuvZNyoVK+jicg5qKiT2O76Vn70mgpbxO9U1MLu+sgI+4XNkcK+9/oJ3L9wkgpbxCdU1HLawMJOCwW5b4EKW8QPVNRylt31bTz6+i5e2HyE1FCQ+66fwJcXTSJXhS3iCRW1nJcKW8QfVNRyUXsa2nj09d08v+kwqaHoHLYKW2TEqKhl0FTYIt64rKI2s58DtwP1zrlZg/mGKur4tzda2M9tOkxKKMC9103g/kWTyctSYYvEwuUW9SKgDfiVijr5qLBFRsZlT32Y2UTgJRV18trb0Maja3fz3MZIYX/h4xO4f/Ek8rPSvI4mkhBGpKjN7H7gfoArrrii7MCBA5eWVnxtX2M7P359lwpbZJhpRC3Dbl9jO4++vptnN9YQDgb4wnUTeECFLXLJLlTUusKLXJIrczP5fsVcXvvmEm6fM55fvL2fhd9by3df2kZ9a6fX8UQSikbUMiz2N7bz6NrdPLvxMKGAcee88dw6u4gbJueSEtJ4QORiLveojyeBJUAuUAd8xzn3swt9jYo6ee1vbOcnb+zht1uO0tbVS1ZqiJuuzmf5rCIWT80jPSXodUQRX9IJLzLiunr7eGt3Iy9vqeXV7XU0newhPRxkybQ8ls8qZOn0fLLSwl7HFPGNCxW1Lm4rMZEaCrJ0egFLpxfQ29fP+n3Hebn6KL/fWsfL1bWkBAN8Ykouy2cVcsvVBYzRFWhEzksjahlR/f2ODQdP8HJ1LWuqaznc1EEwYFw/aRzLZhWybGaBjhyRpKSpD/El5xxbDjezJlraexvbMYPyCWNYPquIZTMLKBmT4XVMkRGhohbfc86xs66Nl6uPsqa6lg9qWwGYU5LD8lmF3DqriCtzMz1OKRI7KmqJO/sa26Mj7aNsrmkGYFpBVqS0ZxcyrSALM/M4pcjwUVFLXDvc1MHvo9Mj7x04jnORE26WzSzk1lmFzCnJUWlL3FNRS8Kob+3k1W11rKmu5e09x+jrdxSPTmfZzEKWzyqkbMIYggGVtsQfFbUkpKaT3by6rY7fb63lzV2NdPf2kzsqlWUzC1g+q5DrJo0jHNRZkRIfVNSS8Nq6enn9g3rWVB9l7QcNdPT0MTojzM1XF7B8ZiGfmJJLWlhnRYp/qaglqXT29LFuZwNrqmv5w/Y6Wjt7GZUa4sbp+dwyo4BFU3IZnaETbMRfdGaiJJW0cJBlMwtZNrOQ7t5+3t7TyJrqWl7ZVseLm48QMJhXOprFU/NZPC2P2cU5mtcWX9OIWpJGX79jc00Tb+xoYN3OBt6vacI5GJMRZtHUPBZPzWPhlDxdZkw8oakPkXM43t7NH3c1sG5HA2/uaqCxrRuA2cU5LJ6ax+JpecwvHU1IC5IyAlTUIhfR3+/YeqSFdTvrWbezgQ0Hm+jrd2SlhVg4JTdS3FPzKczRPiQSGypqkSFq7ujhrd2NrItOk9S2RK5aM70wK1raeZRPHKuLIsiwUVGLXAbnHDvqWk+X9nv7j9PT58hICbJgci6Lp+WxZGoepWO1gZRcOhW1yDBq6+rlz3uOsW5nPW/saKDmRAcAk/IyWTw1jyXT8vn4lWN13LYMiYpaJEacc+xtbGfdjgbe2NnAO3uP0d3bT2oowHWTxrFkWmSa5MrcTO1HIhekohYZIR3dfazfd4w3djTw5s4G9ja2A1A6Np0lU/NZPDWP6yePIzNVpzDIR6moRTxy8NhJ1u1qYN2Oet7ec4yT3X2Eg8bHJo6NjrbzmVowSqNtUVGL+EFXbx9V+0/wxs7Isds76iIXRyjKSWP+FaMpyE6jMDuNwpy0j9zWXHdyUFGL+NDR5o7TR5LsqGulrrmT9u6+s56Xkx6mMDuNgpw0CrNTT98uyPqw1MdlphDQafBxTUUtEidaO3uoa+mktrmL2pbO6O3Oj9xubOui/4xf23DQyM9KoyA79awRuUbn8UGbMonEiay0MFlpYa7Kzzrvc3r7+mlo66K2uZO6lq5Igbd0Uhct9A9qI8d8a3SeOFTUInEmFAxQlJNOUU76BZ93sdH5B0dbLjo6zx2VSk56mOz0cOTftBA5GWGy08Jn3B8mLRzQomiMqKhFEtTQR+eRIq9r7To9Oj9w7CQtnT00d/Rw8hwj9IFSggGy00Nkp0UK/CPlfkapRz4Pnb6dlRbS5lcXoKIWSWKDHZ0D9PT109LRQ0tnL80dPbR0RAq8pbOHlo7e07dPP3aym0PHT57+vPfMofsZRqWGyE4LnVHyH5b6qc9PPzbgvoyUYEKP5lXUIjIo4WCAcaNSGTdq6Pt1O+fo6OmLlvbZRX/q/oFFf+j4SVqjfxTaunov+PqhgEUK/lTRnzFqP1X+A0f3A5+TGvL3IquKWkRizszISAmRkRKiKGfoX9/b109rZ+9Zo/fzjepbOno42txBS2cvLR09dPX2X/D1U0OBAQX+0TI/52h+wP1ZaeGYXyFIRS0ivhcKBhiTmcKYzEu71mVnT985y/zUVE7LGSP7Y+3d7G1sP/143yCmbXLSw4wfncbqBxdcUsYLUVGLSMJLCwdJCwe5wLrqeTnnaO/u+7DMT35Y7gNH8y2dPYSDsRlZq6hFRC7AzBiVGmJUaojxXHzRNRZ0PIyIiM+pqEVEfE5FLSLicypqERGfU1GLiPicilpExOdU1CIiPqeiFhHxuZhc4cXMGoADl/jluUDjMMYZLso1NMo1NMo1NImYa4JzLu9cD8SkqC+HmVWe73I0XlKuoVGuoVGuoUm2XJr6EBHxORW1iIjP+bGoV3od4DyUa2iUa2iUa2iSKpfv5qhFROSj/DiiFhGRAVTUIiI+54uiNrNSM1trZtvMbKuZfd3rTABmlmZm75rZ5miuR7zONJCZBc1so5m95HWWgcxsv5ltMbNNZlbpdZ5TzGy0mT1lZh+Y2XYzu94HmaZFf06nPlrM7GGvcwGY2Tei/99Xm9mTZpbmdSYAM/t6NNNWL39WZvZzM6s3s+oB9401s1fNbFf03zHD8b18UdRAL/BN59wM4DrgITOb4XEmgC5gqXNuLjAPWG5m13kb6SO+Dmz3OsR53Oicm+ezY13/BVjjnJsOzMUHPzvn3I7oz2keUAacBJ71NhWYWTHwNaDcOTcLCAL3eJsKzGwW8GXgWiL/DW83s6s8ivMLYPkZ9/0V8JpzbgrwWvTzy+aLonbOHXXObYjebiXyC1TsbSpwEW3RT8PRD1+svppZCfAp4KdeZ4kHZpYDLAJ+BuCc63bONXka6mw3AXucc5d6Vu9wCwHpZhYCMoAjHucBuBpY75w76ZzrBdYBn/EiiHPuTeD4GXffCfwyevuXwF3D8b18UdQDmdlEYD6w3uMowOnphU1APfCqc84XuYAfAt8C+j3OcS4OeMXMqszsfq/DRF0JNAD/Hp0u+qmZZXod6gz3AE96HQLAOXcY+CfgIHAUaHbOveJtKgCqgYVmNs7MMoDbgFKPMw1U4Jw7Gr1dCxQMx4v6qqjNbBTwNPCwc67F6zwAzrm+6NvSEuDa6FsvT5nZ7UC9c67K6yzn8Qnn3DXArUSmsRZ5HYjI6PAa4CfOuflAO8P0tnQ4mFkKcAew2ussANG51TuJ/IEbD2Sa2Re8TQXOue3A94BXgDXAJqDPy0zn4yLHPg/LO3DfFLWZhYmU9OPOuWe8znOm6NvktZw9J+WFG4A7zGw/8BtgqZk95m2kD0VHYzjn6onMt17rbSIAaoCaAe+IniJS3H5xK7DBOVfndZCom4F9zrkG51wP8AywwONMADjnfuacK3POLQJOADu9zjRAnZkVAUT/rR+OF/VFUZuZEZk73O6c+4HXeU4xszwzGx29nQ7cAnzgaSjAOfdt51yJc24ikbfLrzvnPB/tAJhZppllnboNfJLI21VPOedqgUNmNi16103ANg8jnenz+GTaI+ogcJ2ZZUR/P2/CB4uvAGaWH/33CiLz0094m+gjXgC+GL39ReD54XjR0HC8yDC4AbgX2BKdDwb4a+fc77yLBEAR8EszCxL5o7bKOeerQ+F8qAB4NvK7TQh4wjm3xttIp30VeDw6zbAX+M8e5wFO/0G7BXjA6yynOOfWm9lTwAYiR2VtxD+nbT9tZuOAHuAhrxaFzexJYAmQa2Y1wHeA/wWsMrMvEdnquWJYvpdOIRcR8TdfTH2IiMj5qahFRHxORS0i4nMqahERn1NRi4j4nIpaRMTnVNQiIj73/wGilljbjvS1HAAAAABJRU5ErkJggg==",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "elbowPlot = pd.DataFrame(dist)\n",
        "elbowPlot.rename(columns={0: \"Inner cluster distance\"}, inplace=True)\n",
        "elbowPlot[\"Number of Clusters\"] = np.arange(2, 11)\n",
        "\n",
        "plt.plot(elbowPlot[\"Number of Clusters\"], elbowPlot[\"Inner cluster distance\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### DBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The DBSCAN algorithm is included in the cluster subdirectory of scikit-learn.\n",
        "\n",
        "To create the model, we need to decide our radius factor, `eps`, which tells us how large we think our clusters will be, and the minimum number of samples we want included in each cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DBSCAN(eps=40, min_samples=20)"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "cluster_DBSCAN = DBSCAN(eps=40, min_samples=20)\n",
        "cluster_DBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit the DBSCAN algorithm to our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DBSCAN(eps=40, min_samples=20)"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cluster_DBSCAN.fit(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "DBSCAN_predict = cluster_DBSCAN.fit_predict(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "How many clusters do we have? And what are they?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3\n",
            "(array([-1,  0,  1]), array([99, 42, 37]))\n"
          ]
        }
      ],
      "source": [
        "print(len(set(DBSCAN_predict)))\n",
        "print(np.unique(DBSCAN_predict, return_counts=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So DBSCAN found 3 clusters with some outliers (or observations with a -1 label)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Why are we seeing different results?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fbbc0b03670>"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(X)\n",
        "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=wine.target)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "OHoqoS6zCuES",
        "iIQhfBLiK0Zn",
        "CjRNjZ5WK4pO",
        "KX7SnsiDWQ43",
        "6e5r4Un57I2-",
        "QTHEycO9LFI2"
      ],
      "name": "Python_Workshop_Session_3_Applied_Machine_Learning.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
