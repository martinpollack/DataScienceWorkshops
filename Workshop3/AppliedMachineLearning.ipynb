{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JPYaq5eWQ4n"
      },
      "source": [
        "# Applied Machine Learning\n",
        "### Workshop 3 of DASIL's series on \"Data Science with Python\"\n",
        "### Created by Martin Pollack, Yusen He, and Declan O'Reilly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0FGuCgcWQ4p"
      },
      "source": [
        "In this Jupyter notebook we will teach you how to fit the machine learning models we talked about last week in Python using the `scikit-learn` package."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2B4_h-5j_Wqc"
      },
      "source": [
        "All of our example datasets come from the `datasets` sub-package within `scikit-learn`. So we import them now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "UiT01kfZWQ4q"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEOwnQpUWQ4t"
      },
      "source": [
        "## Supervised Learning - Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NHTB5d26lQO"
      },
      "source": [
        "#### Dataset introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7L_N9Q6WQ4u"
      },
      "source": [
        "Remember that in a regression problem the outcome variable is numeric and continuous. However, the predictor variables can either be continuous or discrete.\n",
        "\n",
        "An example of a regression problem can be found in the diabetes dataset within sklearn. Our outcome is a quantitative measure of disease progression that takes on numbers between 25 and 346."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "3ffUxHDLWQ4v"
      },
      "outputs": [],
      "source": [
        "diabetes = datasets.load_diabetes(as_frame=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CuLcLCoQ_Wqk"
      },
      "source": [
        "`diabetes` is a special scikit-learn dataset. Its `target` field is a pandas Series with our continuous outcome variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gAset6_s_Wqm",
        "outputId": "da8333dd-df5a-43af-c2c2-e3ac331fc008"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      151.0\n",
              "1       75.0\n",
              "2      141.0\n",
              "3      206.0\n",
              "4      135.0\n",
              "       ...  \n",
              "437    178.0\n",
              "438    104.0\n",
              "439    132.0\n",
              "440    220.0\n",
              "441     57.0\n",
              "Name: target, Length: 442, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "diabetes.target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Re8w01hY86c"
      },
      "source": [
        "And its `data` field is a pandas Dataframe of all of our potential predictor variables. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `diabetes` dataset contains the following variables:\n",
        "\n",
        "\n",
        "\n",
        "*   **age:** age in years\n",
        "*   **sex:** gender\n",
        "*   **bmi:** body mass index\n",
        "*   **bp:** average blood pressure\n",
        "*   **s1 tc:** total serum cholesterol\n",
        "*   **s2 ldl:** low-density lipoproteins\n",
        "*   **s3 hdl:** high-density lipoproteins\n",
        "*   **s4 tch:** total cholesterol / HDL\n",
        "*   **s5 ltg:** possibly log of serum triglycerides level\n",
        "*   **s6 glu:** blood sugar level\n",
        "\n",
        "Here, all 10 variables inside `diabetes` dataset have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\n"
      ],
      "metadata": {
        "id": "cjrEfXZuATy5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "uZND0mNpYxjS",
        "outputId": "3e11ac00-0ee1-4156-d387-0e25dae51ca3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          age       sex       bmi        bp        s1        s2        s3  \\\n",
              "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
              "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
              "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
              "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
              "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
              "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
              "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
              "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
              "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
              "\n",
              "           s4        s5        s6  \n",
              "0   -0.002592  0.019908 -0.017646  \n",
              "1   -0.039493 -0.068330 -0.092204  \n",
              "2   -0.002592  0.002864 -0.025930  \n",
              "3    0.034309  0.022692 -0.009362  \n",
              "4   -0.002592 -0.031991 -0.046641  \n",
              "..        ...       ...       ...  \n",
              "437 -0.002592  0.031193  0.007207  \n",
              "438  0.034309 -0.018118  0.044485  \n",
              "439 -0.011080 -0.046879  0.015491  \n",
              "440  0.026560  0.044528 -0.025930  \n",
              "441 -0.039493 -0.004220  0.003064  \n",
              "\n",
              "[442 rows x 10 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d08f300-20c6-4fcf-bd02-368a548e6ce5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>bp</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.038076</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.061696</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>-0.044223</td>\n",
              "      <td>-0.034821</td>\n",
              "      <td>-0.043401</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.019908</td>\n",
              "      <td>-0.017646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.001882</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.051474</td>\n",
              "      <td>-0.026328</td>\n",
              "      <td>-0.008449</td>\n",
              "      <td>-0.019163</td>\n",
              "      <td>0.074412</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.068330</td>\n",
              "      <td>-0.092204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.085299</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.044451</td>\n",
              "      <td>-0.005671</td>\n",
              "      <td>-0.045599</td>\n",
              "      <td>-0.034194</td>\n",
              "      <td>-0.032356</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>-0.025930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.089063</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.011595</td>\n",
              "      <td>-0.036656</td>\n",
              "      <td>0.012191</td>\n",
              "      <td>0.024991</td>\n",
              "      <td>-0.036038</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>0.022692</td>\n",
              "      <td>-0.009362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.005383</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.036385</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>0.003935</td>\n",
              "      <td>0.015596</td>\n",
              "      <td>0.008142</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>-0.031991</td>\n",
              "      <td>-0.046641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>0.041708</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.019662</td>\n",
              "      <td>0.059744</td>\n",
              "      <td>-0.005697</td>\n",
              "      <td>-0.002566</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.031193</td>\n",
              "      <td>0.007207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>-0.005515</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>-0.067642</td>\n",
              "      <td>0.049341</td>\n",
              "      <td>0.079165</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>-0.018118</td>\n",
              "      <td>0.044485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>0.041708</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>0.017282</td>\n",
              "      <td>-0.037344</td>\n",
              "      <td>-0.013840</td>\n",
              "      <td>-0.024993</td>\n",
              "      <td>-0.011080</td>\n",
              "      <td>-0.046879</td>\n",
              "      <td>0.015491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>-0.045472</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>0.001215</td>\n",
              "      <td>0.016318</td>\n",
              "      <td>0.015283</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>0.026560</td>\n",
              "      <td>0.044528</td>\n",
              "      <td>-0.025930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>-0.045472</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.073030</td>\n",
              "      <td>-0.081414</td>\n",
              "      <td>0.083740</td>\n",
              "      <td>0.027809</td>\n",
              "      <td>0.173816</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.004220</td>\n",
              "      <td>0.003064</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>442 rows × 10 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d08f300-20c6-4fcf-bd02-368a548e6ce5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d08f300-20c6-4fcf-bd02-368a548e6ce5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d08f300-20c6-4fcf-bd02-368a548e6ce5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "diabetes.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLh59zKN_Wqr"
      },
      "source": [
        "To make things easier, we will just rename our `target` to `Y` and our predictors to `X`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "mvjfRKLu_Wqs"
      },
      "outputs": [],
      "source": [
        "Y = diabetes.target\n",
        "X = diabetes.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amRvAyBZaNez"
      },
      "source": [
        "#### Splitting the dataset into Training and Test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ro8jKDFpwSh"
      },
      "source": [
        "To evaluate the performance of our models, we need to randomly split our features dataset `X` and outcomes `Y` into a training set `X_train`/`y_train` and testing set `X_test`/`Y_test`. Randomly, we will use some observations to train our models and others see how our model generalizes to new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40iJCmxjcLVC"
      },
      "source": [
        "The `sklearn.model_selection.train_test_split()` does the random split for the training and testing dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VADJGmpq-96"
      },
      "source": [
        "The `test_size` option controls proportion of the observations in our original data that we want to include in our test dataset. The `random_state` parameter controls the random selection process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "NZBrjZyeaTxa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WQ3sh-bKq0ko",
        "outputId": "e4d4c338-29cb-4256-d0f0-ca676fe584d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The shape of total input dataset is: (442, 10)\n",
            "The shape of training input is: (331, 10)\n",
            "The shape of test input is: (111, 10)\n",
            "The shape of total output is: (442,)\n",
            "The shape of training output is: (331,)\n",
            "The shape of test output is: (111,)\n"
          ]
        }
      ],
      "source": [
        "print(\"The shape of total input dataset is:\",X.shape)\n",
        "print(\"The shape of training input is:\",X_train.shape)\n",
        "print(\"The shape of test input is:\",X_test.shape)\n",
        "\n",
        "print(\"The shape of total output is:\",Y.shape)\n",
        "print(\"The shape of training output is:\",Y_train.shape)\n",
        "print(\"The shape of test output is:\",Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19ntU4ger8wA"
      },
      "source": [
        "#### Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjXs3btQvjH_"
      },
      "source": [
        "Let's fit our first machine learning model! We are going to first fit a linear regression, which is the simplest model we will consider since it has no hyperparameters.\n",
        "\n",
        "At a minimum this process takes two steps.\n",
        "\n",
        "First we create the model object, specifying any hyperparameters (but there are none for now). In this case we want to use the `LinearRegression` object from `sklearn.linear_model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "0ArrMz1IthGn"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor_LinReg = LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF0zkZimvm2Q"
      },
      "source": [
        "Second we have to actually fit the linear regression model using our training data. This is done by calling the `fit()` method on our model object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKYPHVBJvsnB",
        "outputId": "483a9923-1ea1-4471-c18e-52ef9061d8be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "regressor_LinReg.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQlOWLImv3tr"
      },
      "source": [
        "We can now make predictions for our test dataset using our model!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "eJt3Ymrsv6iI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fead04c3-0c41-46e2-9ab2-c5bd51907eda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([241.84730258, 250.12303941, 164.96456549, 119.11639346,\n",
              "       188.23120303, 260.56079379, 113.07583812, 190.54117538,\n",
              "       151.8883747 , 236.50848375, 168.76844138, 180.52719713,\n",
              "       109.16037049,  90.20148392, 244.73990469,  90.58113696,\n",
              "       152.51268196,  66.97735025,  98.0467335 , 215.39557064,\n",
              "       197.70737206, 160.9176914 , 162.88584001, 158.25373793,\n",
              "       202.44823294, 168.46663088, 119.87243699,  83.05669211,\n",
              "       189.9839726 , 163.02279586, 177.07828326,  82.6702699 ,\n",
              "       144.53204953, 146.07901596, 141.73841253, 195.18658206,\n",
              "       164.18043648, 189.14768927, 128.13330927, 206.12996392,\n",
              "        82.64273523, 164.94912645, 144.46057692, 182.0519825 ,\n",
              "       178.41355601,  72.5504089 , 142.69750371, 140.43671531,\n",
              "       121.75256103, 233.70553551, 162.07809758,  76.90270416,\n",
              "       155.68916375, 156.64052259, 238.11357481, 175.75735587,\n",
              "       190.82555855, 119.48230582, 131.3142863 , 172.2453037 ,\n",
              "       214.44479397, 171.30900357, 156.69146772, 110.9755974 ,\n",
              "       257.79427463, 154.6473623 ,  81.10560078, 227.26610365,\n",
              "       205.445138  ,  46.92383044,  78.28098211, 131.5335209 ,\n",
              "       105.63850688, 145.15896592, 133.85511669, 189.31799802,\n",
              "        99.29573544, 202.16752252, 221.67724342, 189.36681415,\n",
              "       150.25345002, 208.85311584,  48.03404661, 206.61925845,\n",
              "        76.63162703,  92.70630395, 148.19321808, 194.60105182,\n",
              "       133.07986975, 148.57002105,  97.51272455, 124.56889921,\n",
              "        82.48851826, 151.41937342, 124.81463753, 105.29002279,\n",
              "       236.2130895 , 227.49222218, 128.37518135, 164.29601063,\n",
              "       193.35752892, 111.83831907, 204.3691    ,  84.7480368 ,\n",
              "       217.70082325, 113.6130274 , 221.22851097, 267.69707418,\n",
              "       115.62235754, 113.98308423, 195.01301149])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "LinReg_pred = regressor_LinReg.predict(X_test)\n",
        "LinReg_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "artWZM1Q_Wqz"
      },
      "source": [
        "Also, we can use the `explained_variance_score()` method to get a quick idea of how our model did. For regression, the evaluation metric used is $R^2$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TiMcKvQ2_Wq0",
        "outputId": "01ea13e1-2419-4500-cf17-c95b175f0926"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The percentage of the variance explained by Linear Regression is:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3621901595972109"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "from sklearn.metrics import explained_variance_score\n",
        "print(\"The percentage of the variance explained by Linear Regression is:\")\n",
        "explained_variance_score(Y_test,LinReg_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1_xHJYlKcK-"
      },
      "source": [
        "#### Artificial Neural Network for regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhMzhu83KcK_"
      },
      "source": [
        "Now we are going to fit a much more complicated model to our data: an artificial neural network (ANN). ANNs can be very accurate; however, they have lots of hyperparameters that are hard to get right.\n",
        "\n",
        "We start by seeing what possible hyperparameters an ANN has and what their default values are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Les6YL4T_Wq1",
        "outputId": "e921ac5a-3d5d-48fe-c10d-2237b9a313c5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'activation': 'relu',\n",
              " 'alpha': 0.0001,\n",
              " 'batch_size': 'auto',\n",
              " 'beta_1': 0.9,\n",
              " 'beta_2': 0.999,\n",
              " 'early_stopping': False,\n",
              " 'epsilon': 1e-08,\n",
              " 'hidden_layer_sizes': (100,),\n",
              " 'learning_rate': 'constant',\n",
              " 'learning_rate_init': 0.001,\n",
              " 'max_fun': 15000,\n",
              " 'max_iter': 200,\n",
              " 'momentum': 0.9,\n",
              " 'n_iter_no_change': 10,\n",
              " 'nesterovs_momentum': True,\n",
              " 'power_t': 0.5,\n",
              " 'random_state': None,\n",
              " 'shuffle': True,\n",
              " 'solver': 'adam',\n",
              " 'tol': 0.0001,\n",
              " 'validation_fraction': 0.1,\n",
              " 'verbose': False,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "MLPRegressor().get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qXtJC-Gf_Wq2"
      },
      "source": [
        "Now we can set up an ANN model, this time specifying specific values for hyperparameters like the number of hidden layers. All hyperparameters that we don't specify values for will have their default values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "u1IhG5bQKcK_"
      },
      "outputs": [],
      "source": [
        "regressor_ANN_default = MLPRegressor(hidden_layer_sizes=(40,1), solver='lbfgs', max_iter=2000, learning_rate_init=0.000001, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kkFO9OI_Wq2"
      },
      "source": [
        "Next we fit this specific model with the `fit()` method and evaluate it with `score()` method."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKZVws6t_Wq3",
        "outputId": "2f9f8cb8-fe9f-4257-d94a-05ea11f62908"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.34888647829370967"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "regressor_ANN_default.fit(X_train, Y_train)\n",
        "regressor_ANN_default.score(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r27sd4IPZsW"
      },
      "source": [
        "So we just fit an ANN with one set of hyperparameters.\n",
        "\n",
        "But our choice of hyperparameters is going to have a big effect on how well our model does. Thus, ideally we want to try multiple combinations of hyperparameters and then pick the best one.\n",
        "\n",
        "The first method we use for \"hyperparameter tuning\" is the `GridSearchCV()` function. We give it specific values of hyperparameters we want to be considered. These hyperparameters are detailed using a dictionary of lists.\n",
        "\n",
        "Then when we fit our `GridSearchCV` object, we will actually be fitting many ANNs at once, one for each combination of hyperparameters. As part of the fitting process, Python does cross validation (CV) on each model and picks the best combination based on the model with the best overall evaluation metric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R-sVlyILri3",
        "outputId": "4d44ef10-17f9-4a5e-d7a9-239c62d21467"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:549: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=MLPRegressor(max_iter=5000, solver='lbfgs'),\n",
              "             param_grid={'hidden_layer_sizes': [(5, 1), (35, 1), (40, 1),\n",
              "                                                (200, 1)],\n",
              "                         'learning_rate_init': [0.0001, 1e-06]})"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "ANN = MLPRegressor(solver='lbfgs', max_iter=5000)\n",
        "parameters = {'learning_rate_init':[0.0001, 0.000001], 'hidden_layer_sizes':[(5,1), (35,1), (40,1), (200,1)]}\n",
        "regressor_ANN_tuned_grid = GridSearchCV(ANN, parameters)\n",
        "regressor_ANN_tuned_grid.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJoaF_SB_Wq8"
      },
      "source": [
        "To see all the results, access the `cv_results_` field of our `GridSearchCV` object. And to see the best combination, access the `best_estimator_` field of the same object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcrkGy2h_Wq9",
        "outputId": "36a06829-bfd6-4b04-9190-bc8ad387adb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLPRegressor(hidden_layer_sizes=(40, 1), learning_rate_init=1e-06,\n",
            "             max_iter=5000, solver='lbfgs')\n",
            "0.17047520457791765\n"
          ]
        }
      ],
      "source": [
        "print(regressor_ANN_tuned_grid.best_estimator_)\n",
        "print(regressor_ANN_tuned_grid.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHSGQkqh_Wq-"
      },
      "source": [
        "Again we can what are model predicts using the `predict()` method on our model object. Although we trained multiple ANNs at once, it will by default give us predictions from the best model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKeB6KumRoQ0",
        "outputId": "35f51bb8-1c71-4526-c7ac-ce1f56619732"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015, 151.92145015,\n",
              "       151.92145015, 151.92145015, 151.92145015])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "ANN_pred = regressor_ANN_tuned_grid.predict(X_test)\n",
        "ANN_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbtu3t5bwXWf"
      },
      "source": [
        "#### Performance Assessment using Testing Data\n",
        "\n",
        "We will compare the two models using these four metrics:\n",
        "*   Mean Absolute Error\n",
        "*   Mean Absolute Percentage Error\n",
        "*   Mean Square Error\n",
        "*   Root-Mean-Square Error"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEexDKqYx3cA"
      },
      "source": [
        "First, let's compute Mean Absolute Error (MAE) for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr21dcF-wqao",
        "outputId": "f5b0afc8-1917-4fe9-fdc1-93d0c6e83fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MAE of predictions provided by GLM is :\n",
            "45.120987683251\n",
            "The MAE of predictions provided by ANN is :\n",
            "58.31036172123785\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "MAE_GLM = mean_absolute_error(Y_test, LinReg_pred)\n",
        "MAE_ANN = mean_absolute_error(Y_test, ANN_pred)\n",
        "\n",
        "print(\"The MAE of predictions provided by GLM is :\")\n",
        "print(MAE_GLM)\n",
        "\n",
        "print(\"The MAE of predictions provided by ANN is :\")\n",
        "print(MAE_ANN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZCsUF1EyATg"
      },
      "source": [
        "Second, let's compute Mean Absolute Percentage Error (MAPE) for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpCMtL9S3U0h",
        "outputId": "633b3c3f-b6cd-4fc6-8ae4-df0df10dd24d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MAPE of predictions provided by GLM is :\n",
            "0.37961401187552524\n",
            "The MAPE of predictions provided by ANN is :\n",
            "0.5261272203265066\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "MAPE_GLM = mean_absolute_percentage_error(Y_test, LinReg_pred)\n",
        "MAPE_ANN = mean_absolute_percentage_error(Y_test, ANN_pred)\n",
        "\n",
        "print(\"The MAPE of predictions provided by GLM is :\")\n",
        "print(MAPE_GLM)\n",
        "\n",
        "print(\"The MAPE of predictions provided by ANN is :\")\n",
        "print(MAPE_ANN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2neFZEkyIJh"
      },
      "source": [
        "Third, let's compute Mean Square Error (MSE) for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v44igycf39JO",
        "outputId": "8275dc82-27be-4b55-bc92-8068d15726c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The MSE of predictions provided by GLM is :\n",
            "3180.1988368427265\n",
            "The MSE of predictions provided by ANN is :\n",
            "4965.126471649221\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "MSE_GLM = mean_squared_error(Y_test, LinReg_pred)\n",
        "MSE_ANN = mean_squared_error(Y_test, ANN_pred)\n",
        "\n",
        "print(\"The MSE of predictions provided by GLM is :\")\n",
        "print(MSE_GLM)\n",
        "\n",
        "print(\"The MSE of predictions provided by ANN is :\")\n",
        "print(MSE_ANN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKo8f8k5yOEh"
      },
      "source": [
        "Last, let's compute Root-Mean-Suqare-Error (RMSE) for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aBlPKXL5oAh",
        "outputId": "190e79e9-f55c-45d0-9d8f-afd5f0cd9171"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The RMSE of predictions provided by GLM is :\n",
            "56.39325169594964\n",
            "The RMSE of predictions provided by ANN is :\n",
            "70.46365355024689\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "RMSE_GLM = mean_squared_error(Y_test, LinReg_pred, squared=False)\n",
        "RMSE_ANN = mean_squared_error(Y_test, ANN_pred, squared=False)\n",
        "\n",
        "print(\"The RMSE of predictions provided by GLM is :\")\n",
        "print(RMSE_GLM)\n",
        "\n",
        "print(\"The RMSE of predictions provided by ANN is :\")\n",
        "print(RMSE_ANN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SarBlYm2WQ4x"
      },
      "source": [
        "## Supervised Learning - Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULypkTWU9hEp"
      },
      "source": [
        "#### Dataset Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29YqLUpTWQ4z"
      },
      "source": [
        "Now let's look at a classification problem, where the outcome can only take on 2 or more discrete values. But of course our predictors can be either continuous or discrete.\n",
        "\n",
        "Now we use `scikit-learn`'s breast cancer dataset. Here the outcome can take on a 0, for no breast cancer, or 1, for breast cancer. \n",
        "\n",
        "So in this case we actually have a *binary classification* problem, meaning our category can only take on 2 discrete values. In most binary classification problems, like in this case, the categories are 0 and 1 indiciating the presence or absence of some trait."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "0Jmrv4VMWQ41"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "breast_cancer = load_breast_cancer(as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZau-rgMWQ41",
        "outputId": "9bdfadbc-4068-4302-f45a-b8635c2671a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    357\n",
              "0    212\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "breast_cancer.target.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `breast cancer` dataset contains 30 predictive variables. For example:\n",
        "\n",
        "\n",
        "\n",
        "*    radius (mean of distances from center to points on the perimeter)\n",
        "\n",
        "*    texture (standard deviation of gray-scale values)\n",
        "\n",
        "*    perimeter\n",
        "\n",
        "*    area\n",
        "\n",
        "*    smoothness (local variation in radius lengths)\n",
        "\n",
        "*    compactness (perimeter^2 / area - 1.0)\n",
        "\n",
        "*    concavity (severity of concave portions of the contour)\n",
        "\n",
        "*    concave points (number of concave portions of the contour)\n",
        "\n",
        "*    symmetry\n",
        "\n",
        "*    fractal dimension (“coastline approximation” - 1)\n",
        "\n",
        "\n",
        "\n",
        "The mean, standard error, and “worst” or largest (mean of the three worst/largest values) of these features were computed for each image, resulting in 30 features. For instance, field 0 is Mean Radius, field 10 is Radius SE, field 20 is Worst Radius.\n",
        "\n"
      ],
      "metadata": {
        "id": "y6Kl5F0QBtSa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "NU-R05ZjXEbr",
        "outputId": "0f2977d9-51a3-4893-9fa2-f2d6b8884e45"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "0                   0.07871  ...        25.380          17.33   \n",
              "1                   0.05667  ...        24.990          23.41   \n",
              "2                   0.05999  ...        23.570          25.53   \n",
              "3                   0.09744  ...        14.910          26.50   \n",
              "4                   0.05883  ...        22.540          16.67   \n",
              "..                      ...  ...           ...            ...   \n",
              "564                 0.05623  ...        25.450          26.40   \n",
              "565                 0.05533  ...        23.690          38.25   \n",
              "566                 0.05648  ...        18.980          34.12   \n",
              "567                 0.07016  ...        25.740          39.42   \n",
              "568                 0.05884  ...         9.456          30.37   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "0             184.60      2019.0           0.16220            0.66560   \n",
              "1             158.80      1956.0           0.12380            0.18660   \n",
              "2             152.50      1709.0           0.14440            0.42450   \n",
              "3              98.87       567.7           0.20980            0.86630   \n",
              "4             152.20      1575.0           0.13740            0.20500   \n",
              "..               ...         ...               ...                ...   \n",
              "564           166.10      2027.0           0.14100            0.21130   \n",
              "565           155.00      1731.0           0.11660            0.19220   \n",
              "566           126.70      1124.0           0.11390            0.30940   \n",
              "567           184.60      1821.0           0.16500            0.86810   \n",
              "568            59.16       268.6           0.08996            0.06444   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "0             0.7119                0.2654          0.4601   \n",
              "1             0.2416                0.1860          0.2750   \n",
              "2             0.4504                0.2430          0.3613   \n",
              "3             0.6869                0.2575          0.6638   \n",
              "4             0.4000                0.1625          0.2364   \n",
              "..               ...                   ...             ...   \n",
              "564           0.4107                0.2216          0.2060   \n",
              "565           0.3215                0.1628          0.2572   \n",
              "566           0.3403                0.1418          0.2218   \n",
              "567           0.9387                0.2650          0.4087   \n",
              "568           0.0000                0.0000          0.2871   \n",
              "\n",
              "     worst fractal dimension  \n",
              "0                    0.11890  \n",
              "1                    0.08902  \n",
              "2                    0.08758  \n",
              "3                    0.17300  \n",
              "4                    0.07678  \n",
              "..                       ...  \n",
              "564                  0.07115  \n",
              "565                  0.06637  \n",
              "566                  0.07820  \n",
              "567                  0.12400  \n",
              "568                  0.07039  \n",
              "\n",
              "[569 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e9465e09-c1da-43b9-ae06-a2376e6fd3eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e9465e09-c1da-43b9-ae06-a2376e6fd3eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e9465e09-c1da-43b9-ae06-a2376e6fd3eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e9465e09-c1da-43b9-ae06-a2376e6fd3eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "breast_cancer.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnasUbL_9xOg"
      },
      "source": [
        "#### Define the predictor variable set and a target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQALRlB997O7"
      },
      "source": [
        "For the regression tasks, a feature set `X` and a target set `y` need to be defined first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "eWj12b_r98X8",
        "outputId": "e2c56145-fb79-43b2-d5e0-f45caeba7bea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "0                   0.07871  ...        25.380          17.33   \n",
              "1                   0.05667  ...        24.990          23.41   \n",
              "2                   0.05999  ...        23.570          25.53   \n",
              "3                   0.09744  ...        14.910          26.50   \n",
              "4                   0.05883  ...        22.540          16.67   \n",
              "..                      ...  ...           ...            ...   \n",
              "564                 0.05623  ...        25.450          26.40   \n",
              "565                 0.05533  ...        23.690          38.25   \n",
              "566                 0.05648  ...        18.980          34.12   \n",
              "567                 0.07016  ...        25.740          39.42   \n",
              "568                 0.05884  ...         9.456          30.37   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "0             184.60      2019.0           0.16220            0.66560   \n",
              "1             158.80      1956.0           0.12380            0.18660   \n",
              "2             152.50      1709.0           0.14440            0.42450   \n",
              "3              98.87       567.7           0.20980            0.86630   \n",
              "4             152.20      1575.0           0.13740            0.20500   \n",
              "..               ...         ...               ...                ...   \n",
              "564           166.10      2027.0           0.14100            0.21130   \n",
              "565           155.00      1731.0           0.11660            0.19220   \n",
              "566           126.70      1124.0           0.11390            0.30940   \n",
              "567           184.60      1821.0           0.16500            0.86810   \n",
              "568            59.16       268.6           0.08996            0.06444   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "0             0.7119                0.2654          0.4601   \n",
              "1             0.2416                0.1860          0.2750   \n",
              "2             0.4504                0.2430          0.3613   \n",
              "3             0.6869                0.2575          0.6638   \n",
              "4             0.4000                0.1625          0.2364   \n",
              "..               ...                   ...             ...   \n",
              "564           0.4107                0.2216          0.2060   \n",
              "565           0.3215                0.1628          0.2572   \n",
              "566           0.3403                0.1418          0.2218   \n",
              "567           0.9387                0.2650          0.4087   \n",
              "568           0.0000                0.0000          0.2871   \n",
              "\n",
              "     worst fractal dimension  \n",
              "0                    0.11890  \n",
              "1                    0.08902  \n",
              "2                    0.08758  \n",
              "3                    0.17300  \n",
              "4                    0.07678  \n",
              "..                       ...  \n",
              "564                  0.07115  \n",
              "565                  0.06637  \n",
              "566                  0.07820  \n",
              "567                  0.12400  \n",
              "568                  0.07039  \n",
              "\n",
              "[569 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-acb85c9a-4de6-44cf-bc79-da9806775573\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-acb85c9a-4de6-44cf-bc79-da9806775573')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-acb85c9a-4de6-44cf-bc79-da9806775573 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-acb85c9a-4de6-44cf-bc79-da9806775573');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "X = breast_cancer.data\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TkzBmuh6-B6J",
        "outputId": "c9c5a3b4-059e-4c2b-8575-777e042e1cbb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0      0\n",
              "1      0\n",
              "2      0\n",
              "3      0\n",
              "4      0\n",
              "      ..\n",
              "564    0\n",
              "565    0\n",
              "566    0\n",
              "567    0\n",
              "568    1\n",
              "Name: target, Length: 569, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "Y = breast_cancer.target\n",
        "Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56eOA-Y_9lcz"
      },
      "source": [
        "#### Split the dataset into training and test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89bteG4dHsXY"
      },
      "source": [
        "The `sklearn.model_selection.train_test_split` does the random split for the training and testing dataset.\n",
        "\n",
        "Note: Here, `stratify` means the test set has equal numbers of 0 & 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "HU4MmjqLHtaQ"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3, stratify=Y,  random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB6c_jrmIdF4"
      },
      "source": [
        "To evaluate the model performance, we need to randomly split the feature set `X` and the target set `y` into the training set `X_train` & `y_train` and test set `X_test` & `y_test`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qayqpBTIdp3"
      },
      "source": [
        "The `test_size` option controls the size of the test set. The `random_state` parameter controls the shuffling applied which can be ignored in this work."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elJ87AHnKp0t"
      },
      "source": [
        "#### XGBoost for Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoavtYx4_WrN"
      },
      "source": [
        "The first classification model we will try is XGBoost, considered one of the best models out there.\n",
        "\n",
        "Again we start by seeing what hyperparameters we can possibly tune."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yvLrjCf_WrN",
        "outputId": "0c7a6b01-ef06-40c7-bcb4-9db4bcbabd07"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'ccp_alpha': 0.0,\n",
              " 'criterion': 'friedman_mse',\n",
              " 'init': None,\n",
              " 'learning_rate': 0.1,\n",
              " 'loss': 'deviance',\n",
              " 'max_depth': 3,\n",
              " 'max_features': None,\n",
              " 'max_leaf_nodes': None,\n",
              " 'min_impurity_decrease': 0.0,\n",
              " 'min_samples_leaf': 1,\n",
              " 'min_samples_split': 2,\n",
              " 'min_weight_fraction_leaf': 0.0,\n",
              " 'n_estimators': 100,\n",
              " 'n_iter_no_change': None,\n",
              " 'random_state': None,\n",
              " 'subsample': 1.0,\n",
              " 'tol': 0.0001,\n",
              " 'validation_fraction': 0.1,\n",
              " 'verbose': 0,\n",
              " 'warm_start': False}"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "GradientBoostingClassifier().get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX6uFoxntutW"
      },
      "source": [
        "Now let's create a model with specific hyperparameters. We will name it as `classifier_XGB`.\n",
        "\n",
        "In this case, the score we get is the overall accuracy of our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apugvOWmtt8G",
        "outputId": "09c94242-e227-4dec-f6d8-9fedce599f6d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9949748743718593"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "classifier_XGB = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,max_depth=1, random_state=0)\n",
        "classifier_XGB.fit(X_train, Y_train)\n",
        "classifier_XGB.score(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WvJDUYxk_WrO"
      },
      "source": [
        "But again we probably want to do some hyperparameter tuning.\n",
        "\n",
        "The second main way to do this is `RandomizedSearchCV()`. Here we give distributions for our hyperparameters instead of specific values. Python will then randomly choose hyperparameters to try based on the given distributions.\n",
        "\n",
        "For example, for XGBoost we will use a normal distribution with mean of 0.5 and standard deviation of 0.1 for the \"minimum impurity decrease\". This means we will mostly try values close to 0.5, but occasionally some further from 0.5. We will then consider a uniform distribution for learning rate between 0 and 1, meaning any number in this range is equally likely to be chosen. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "A0jgh8n-_WrO"
      },
      "outputs": [],
      "source": [
        "XGB = GradientBoostingClassifier(n_estimators=100)\n",
        "\n",
        "from scipy.stats import norm, uniform\n",
        "distributions = {\"min_impurity_decrease\":norm(loc=0.5, scale=0.1), \"learning_rate\":uniform(loc=0.5, scale=0.5)}\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "classifier_XGB_tuned_random = RandomizedSearchCV(XGB, distributions, n_iter=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ga87hbM_WrQ"
      },
      "source": [
        "Now we fit our `RandomizedSearchCV` object. Since `n_iter` is 10 above, we will grab 10 combinations of hyperparameters from our two distributions. Then we will fit an XGBoost model for each combination, Python choosing the best one for us."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOBVHyUC_WrQ",
        "outputId": "c6392c04-ab40-4324-c703-ebcf4ada5da2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'learning_rate': 0.6645379272890424, 'min_impurity_decrease': 0.4456557904147318}\n",
            "0.942246835443038\n"
          ]
        }
      ],
      "source": [
        "classifier_XGB_tuned_random.fit(X_train, Y_train)\n",
        "XGB_pred = classifier_XGB_tuned_random.predict(X_test)\n",
        "\n",
        "print(classifier_XGB_tuned_random.best_params_)\n",
        "print(classifier_XGB_tuned_random.best_score_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIQhfBLiK0Zn"
      },
      "source": [
        "#### Support Vector Machine for Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp-UWCS8uBY0"
      },
      "source": [
        "Lastly, we will create an SVM model. \n",
        "\n",
        "We will just go back to using `GridSearchCV()` for our hyperparameter tuning. To know what to tune, let's see what the hyperparameters are."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-RYcxNYuQRJ",
        "outputId": "6468a485-c6d7-4453-b7f8-931cf04c2c9f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 1.0,\n",
              " 'break_ties': False,\n",
              " 'cache_size': 200,\n",
              " 'class_weight': None,\n",
              " 'coef0': 0.0,\n",
              " 'decision_function_shape': 'ovr',\n",
              " 'degree': 3,\n",
              " 'gamma': 'scale',\n",
              " 'kernel': 'rbf',\n",
              " 'max_iter': -1,\n",
              " 'probability': False,\n",
              " 'random_state': None,\n",
              " 'shrinking': True,\n",
              " 'tol': 0.001,\n",
              " 'verbose': False}"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "SVC().get_params()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enxTf2PI_WrS"
      },
      "source": [
        "We will now create and fit our model, leaving `gamma` fixed at `auto` and tuning `C`, which is by far the most important hyperparameter to get right."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKgykWtx_WrT",
        "outputId": "1d88d7c5-21dc-4cb4-9864-a7408c618de0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'C': 0.001}\n",
            "0.6281645569620252\n"
          ]
        }
      ],
      "source": [
        "SVC_model = SVC(gamma='auto', probability=True)\n",
        "\n",
        "parameters = {\"C\":[0.001, 0.1, 0.5, 1, 1.5]}\n",
        "\n",
        "classifier_SVM_tuned_grid = GridSearchCV(SVC_model, parameters)\n",
        "\n",
        "classifier_SVM_tuned_grid.fit(X_train, Y_train)\n",
        "print(classifier_SVM_tuned_grid.best_params_)\n",
        "print(classifier_SVM_tuned_grid.best_score_)\n",
        "\n",
        "SVM_pred = classifier_SVM_tuned_grid.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1fxh88pvQzj"
      },
      "source": [
        "#### Performance Assessment\n",
        "\n",
        "*   Confusion Matrix\n",
        "*   Accuracy\n",
        "*   Sensitivity\n",
        "*   Specificity\n",
        "*   AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDaIRwwW4BZi"
      },
      "source": [
        "We start by assessing XGBoost:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "sqsmOh8fz9Gn",
        "outputId": "e7f0a179-90e6-4843-c06c-898aeb2c7bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for XGB: \n",
            " [[ 57   7]\n",
            " [  6 101]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f02e769b1d0>"
            ]
          },
          "metadata": {},
          "execution_count": 82
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#Compute the confusion matrix\n",
        "cmXGB = confusion_matrix(Y_test,XGB_pred)\n",
        "print('Confusion Matrix for XGB: \\n', cmXGB)\n",
        "\n",
        "#Plot the confusion matrix using seaborn\n",
        "import seaborn as sns\n",
        "sns.heatmap(cmXGB, annot=True,fmt=\"d\", cmap=\"YlGnBu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute total test cases\n",
        "totalXGB=sum(sum(cmXGB))\n",
        "#####from confusion matrix calculate accuracy\n",
        "accuracyXGB=(cmXGB[0,0]+cmXGB[1,1])/totalXGB\n",
        "print ('Accuracy for XGB: ', accuracyXGB)\n",
        "\n",
        "sensitivityXGB = cmXGB[1,1]/(cmXGB[1,0]+cmXGB[1,1])\n",
        "print('Specificity for XGB: ', sensitivityXGB)\n",
        "\n",
        "specificityXGB = cmXGB[0,0]/(cmXGB[0,0]+cmXGB[0,1])\n",
        "print('Sensitivity for XGB: ', specificityXGB)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ7FFlnwElfz",
        "outputId": "12b1f99b-89ca-4bb4-90d9-4de94eeae55b"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for XGB:  0.9239766081871345\n",
            "Specificity for XGB:  0.9439252336448598\n",
            "Sensitivity for XGB:  0.890625\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ekaseon1kDu"
      },
      "source": [
        "Then, we compute the AUC. We use the `roc_auc_score` from `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8eqsAS210uf",
        "outputId": "ca8b341e-4e8c-4961-de5c-a452f4facc34"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC for XGB:  0.9764894859813085\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#We first compute the probability output from the SVM classifier\n",
        "XGB_prob = classifier_XGB_tuned_random.predict_proba(X_test)\n",
        "\n",
        "#We compute the AUC score\n",
        "aucSVM = roc_auc_score(Y_test,XGB_prob[:,1])\n",
        "print('AUC for XGB: ', aucSVM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKNTgE26_WrW"
      },
      "source": [
        "Now for SVM's prediction, we have:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "0cf5ec7d-b3c7-4411-9d89-8f2d561fe454",
        "id": "E9gsOWuR_WrW"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion Matrix for SVM: \n",
            " [[  0  64]\n",
            " [  0 107]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f02e75bda90>"
            ]
          },
          "metadata": {},
          "execution_count": 83
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#Compute the confusion matrix\n",
        "cmSVM = confusion_matrix(Y_test,SVM_pred)\n",
        "print('Confusion Matrix for SVM: \\n', cmSVM)\n",
        "\n",
        "#Plot the confusion matrix using seaborn\n",
        "import seaborn as sns\n",
        "sns.heatmap(cmSVM, annot=True,fmt=\"d\", cmap=\"YlGnBu\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compute total test cases\n",
        "totalSVM=sum(sum(cmSVM))\n",
        "#####from confusion matrix calculate accuracy\n",
        "accuracySVM=(cmSVM[0,0]+cmSVM[1,1])/totalSVM\n",
        "print ('Accuracy for SVM: ', accuracySVM)\n",
        "\n",
        "sensitivitySVM = cmSVM[1,1]/(cmSVM[1,0]+cmSVM[1,1])\n",
        "print('Specificity for SVM: ', sensitivitySVM)\n",
        "\n",
        "specificitySVM = cmSVM[0,0]/(cmSVM[0,0]+cmSVM[0,1])\n",
        "print('Sensitivity for SVM: ', specificitySVM)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDXSmoA0E6QI",
        "outputId": "4e4fbf8a-ac64-427f-8d55-207f6940b2c5"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for SVM:  0.6257309941520468\n",
            "Specificity for SVM:  1.0\n",
            "Sensitivity for SVM:  0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMzeHoOb_WrW"
      },
      "source": [
        "Then, we compute the AUC for SVM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d688f11-da66-4aee-d599-4ae38489f922",
        "id": "Q6N8mE2x_WrW"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AUC for SVM:  0.8879964953271028\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#We first compute the probability output from the SVM classifier\n",
        "SVM_prob = classifier_SVM_tuned_grid.predict_proba(X_test)\n",
        "\n",
        "#We compute the AUC score\n",
        "aucSVM = roc_auc_score(Y_test,SVM_prob[:,1])\n",
        "print('AUC for SVM: ', aucSVM)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX7SnsiDWQ43"
      },
      "source": [
        "## Unsupervised Learning - Clustering (and Dimension Reduction)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORhQRZbv7Cwc"
      },
      "source": [
        "#### Dataset Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5MeAadHWQ44"
      },
      "source": [
        "Lastly we want to consider an unsupervised learning problem, where we don't actually have an outcome at all, or our data is \"unlabeled.\" Instead of predicting something we just want to find patterns and structure in our data.\n",
        "\n",
        "Our data can be unlabeled for two reasons:\n",
        "\n",
        "• First, maybe our data does not have well-defined groupings. An example might be a company's customers: there are not clear and distinct groups that we can put people in. \n",
        "\n",
        "• Second, maybe the label of our data is missing. Suppose you are a wine vendor and you ordered three types of wine from your supplier. When you receive your wine shipment, however, you realize that the labels were not put on. You may want to learn about how the different wine bottles are related to one another to make an educated guess on which is what wine type.\n",
        "\n",
        "Our example below falls in this second case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "SL-PO7LrWQ45"
      },
      "outputs": [],
      "source": [
        "wine = datasets.load_wine(as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "c_SCElBgWQ45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87de5ef1-583b-4292-af58-2bfde08607d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n",
              "       'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n",
              "       'proanthocyanins', 'color_intensity', 'hue',\n",
              "       'od280/od315_of_diluted_wines', 'proline'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "wine.data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "4l4wK5z5YUC6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "57b2de59-c93b-4415-aab5-d200c7fde0ab"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "..       ...         ...   ...                ...        ...            ...   \n",
              "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
              "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
              "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
              "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
              "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
              "\n",
              "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0          3.06                  0.28             2.29             5.64  1.04   \n",
              "1          2.76                  0.26             1.28             4.38  1.05   \n",
              "2          3.24                  0.30             2.81             5.68  1.03   \n",
              "3          3.49                  0.24             2.18             7.80  0.86   \n",
              "4          2.69                  0.39             1.82             4.32  1.04   \n",
              "..          ...                   ...              ...              ...   ...   \n",
              "173        0.61                  0.52             1.06             7.70  0.64   \n",
              "174        0.75                  0.43             1.41             7.30  0.70   \n",
              "175        0.69                  0.43             1.35            10.20  0.59   \n",
              "176        0.68                  0.53             1.46             9.30  0.60   \n",
              "177        0.76                  0.56             1.35             9.20  0.61   \n",
              "\n",
              "     od280/od315_of_diluted_wines  proline  \n",
              "0                            3.92   1065.0  \n",
              "1                            3.40   1050.0  \n",
              "2                            3.17   1185.0  \n",
              "3                            3.45   1480.0  \n",
              "4                            2.93    735.0  \n",
              "..                            ...      ...  \n",
              "173                          1.74    740.0  \n",
              "174                          1.56    750.0  \n",
              "175                          1.56    835.0  \n",
              "176                          1.62    840.0  \n",
              "177                          1.60    560.0  \n",
              "\n",
              "[178 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-661a4926-ec4f-4210-a972-2f11d8b47c05\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-661a4926-ec4f-4210-a972-2f11d8b47c05')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-661a4926-ec4f-4210-a972-2f11d8b47c05 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-661a4926-ec4f-4210-a972-2f11d8b47c05');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "wine.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e5r4Un57I2-"
      },
      "source": [
        "#### Initialize the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzcQqq5r-QNs"
      },
      "source": [
        "Initialize the dataset as `X`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "ffGyVj1w-S7v"
      },
      "outputs": [],
      "source": [
        "X= wine.data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "fkCOINlx_Wre",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2716a14-ef99-4b58-9f63-e2cf82464b66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    71\n",
              "0    59\n",
              "2    48\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ],
      "source": [
        "wine.target.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0yRsiFz-_K0"
      },
      "source": [
        "#### Clustering using K-Means algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gyXR2eUBcfO"
      },
      "source": [
        "##### Intialize the K-Means Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u22oqn0-IRO"
      },
      "source": [
        "The K-Mean algorithm is included in the Scikit-leanr library. Define the number of clusters by `n_clusters` and random initialization state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "kN01QBb4-Pdt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b92f0661-9c50-49d8-e4a9-40416f55731d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=3, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "#Here we set n=3 in this workshop\n",
        "cluster_KMeans = KMeans(n_clusters=3, random_state=0)\n",
        "cluster_KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGumzwgl-1xt"
      },
      "source": [
        "##### Fit and predict using K-Mean algorithm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DJRbWuJ_cBG"
      },
      "source": [
        "Fit the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "a_ch__Ce-1Gx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40622868-8c92-45fc-d6b6-f03adbe4f57a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "KMeans(n_clusters=3, random_state=0)"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ],
      "source": [
        "cluster_KMeans.fit(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icvv8h9z_Oh8"
      },
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "weBqEwxW_hoE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7aa8bcbd-5393-4a14-9b0b-f2567b7e0575"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 2, 0, 2, 2, 0,\n",
              "       2, 2, 0, 0, 0, 2, 2, 1, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2,\n",
              "       0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0,\n",
              "       2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2,\n",
              "       2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 2, 0,\n",
              "       0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0,\n",
              "       0, 2], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ],
      "source": [
        "cluster_labels = cluster_KMeans.predict(X)\n",
        "cluster_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEL2KmZH1e3y"
      },
      "source": [
        "Compute inner cluster distances (Euclidean distances) within all clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "jLcypDGJ1kSZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a00f7c-7a91-4498-ff12-dd0f9db76b4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2370689.686782969"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ],
      "source": [
        "cluster_KMeans.inertia_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2VQS91NBUJN"
      },
      "source": [
        "##### Find the BEST k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcA2Ed-z1toI"
      },
      "source": [
        "Now, let's try different numbers of k to see how cluster centers change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "yVW1JGmP1s0P"
      },
      "outputs": [],
      "source": [
        "#Store the sum of inner cluster distances in a list and name is as dist\n",
        "dist=[]\n",
        "\n",
        "for i in range(2,11):\n",
        "  #Run k-mean clustering with i centers\n",
        "  cluster_KMeans = KMeans(n_clusters =i, random_state=0)\n",
        "  cluster_KMeans.fit(X)\n",
        "  #Store the summed inner cluster distances into the list namely 'dist'\n",
        "  dist.append(cluster_KMeans.inertia_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aRiilxo8bGJ"
      },
      "source": [
        "Display the inner cluster distances for all k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "RPTDSExDBY0v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c5585a9-bcbd-4fa1-8163-e5b5814c032d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4543749.614531861,\n",
              " 2370689.686782969,\n",
              " 1331903.062263718,\n",
              " 916379.1871539169,\n",
              " 647326.0020260848,\n",
              " 412137.5091004584,\n",
              " 324523.62500019534,\n",
              " 270954.9292415376,\n",
              " 217887.37856033302]"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ],
      "source": [
        "dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNud2CgJ8hYy"
      },
      "source": [
        "Now, let's use `matplotlib` library to visualize the inner cluster distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "dyljMec38NjX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MexfgXCq8o1Y"
      },
      "source": [
        "We can plot the inner cluster distance curve and use Elbow's method to seek for optimal k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "a8w02SxZ8P4j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "outputId": "813b19a6-0818-46b7-edb3-810c09de8748"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "elbowPlot = pd.DataFrame(dist)\n",
        "elbowPlot.rename(columns={0: \"Inner cluster distance\"}, inplace=True)\n",
        "elbowPlot[\"Number of Clusters\"] = np.arange(2, 11)\n",
        "\n",
        "plt.plot(elbowPlot[\"Number of Clusters\"], elbowPlot[\"Inner cluster distance\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x2eiPRk_Wrp"
      },
      "source": [
        "#### DBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "laqjJdOi_Wrp"
      },
      "source": [
        "The DBSCAN algorithm is included in the cluster subdirectory of scikit-learn.\n",
        "\n",
        "To create the model, we need to decide our radius factor, `eps`, which tells us how large we think our clusters will be, and the minimum number of samples we want included in each cluster."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "Vkx--XsM_Wrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fd475ae-dba0-424e-94d8-eb8e4f0b9f16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DBSCAN(eps=40, min_samples=20)"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ],
      "source": [
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "cluster_DBSCAN = DBSCAN(eps=40, min_samples=20)\n",
        "cluster_DBSCAN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELVwSwqD_Wrq"
      },
      "source": [
        "Fit the DBSCAN algorithm to our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "6dpsPBwt_Wrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e37982c6-291e-4aec-87e6-18ec63692349"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DBSCAN(eps=40, min_samples=20)"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "cluster_DBSCAN.fit(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRQ92Oea_Wrr"
      },
      "source": [
        "Predict the clustering groups using our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "tT2mHUUu_Wrs"
      },
      "outputs": [],
      "source": [
        "DBSCAN_predict = cluster_DBSCAN.fit_predict(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWWOdZq4_Wrs"
      },
      "source": [
        "Unlike k-means, DBSCAN tries to figure out the optimal number of clusters.\n",
        "\n",
        "How many clusters do we have in this fitted model? And what are they?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "QIaegMdi_Wrt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a83fb7ef-da6e-47da-c89b-c0e5ef0c18a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "(array([-1,  0,  1]), array([99, 42, 37]))\n"
          ]
        }
      ],
      "source": [
        "print(len(set(DBSCAN_predict)))\n",
        "print(np.unique(DBSCAN_predict, return_counts=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1YZ7cIH_Wrt"
      },
      "source": [
        "So here we have two groups (0 and 1) with some outliers (-1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRQlkn5s_Wrt"
      },
      "source": [
        "#### Why are we seeing different results using k-means and DBSCAN?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UgCdXtmh_Wrt"
      },
      "source": [
        "We use TSNE, another dimension reduction algorithm besides Principal Component Analysis, to visualize our data in two dimensions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "9sfnx8fq_Wrt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "ee0d8d7a-a495-4440-b349-5a6605e0cf71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7f02e749c390>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from sklearn.manifold import TSNE\n",
        "X_embedded = TSNE(n_components=2, learning_rate='auto', init='random').fit_transform(X)\n",
        "plt.scatter(X_embedded[:, 0], X_embedded[:, 1], c=wine.target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQTfykyp_Wru"
      },
      "source": [
        "It looks like two of the wines are hard to differentiate, and the third is still not that different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6GCmgQR7_Wru"
      },
      "source": [
        "## Your turn!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kMRNScr_Wru"
      },
      "source": [
        "It's time for a competition. \n",
        "\n",
        "You should have gotten a dataset on forest fires in Portugal taken from `kaggle.com`. We are going to try and predict the amount of area burned using variables like wind, rain, day of the week, and month of the year.\n",
        "\n",
        "Try different algorithms for regression tasks and tune their hyperparameters if necessary. The people with the 5 lowest mean square errors will receive a prize!\n",
        "\n",
        "*Hint*: The outcome variable, area burned, is very right-skewed, or most values are small and just a few are larger. Fitting models using the log of the outcome may help. Then when you predict values, exponentiate them to get them on the original scale. Use the `np.log()` and `np.exp()` functions to take the natural log/raise to the power of e."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "asFqMj9K_Wru",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "243ae368-5f5b-4881-9f12-13ae668df30a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-09db5b72edac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfires\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"forestfires.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfires\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'forestfires.csv'"
          ]
        }
      ],
      "source": [
        "fires = pd.read_csv(\"forestfires.csv\")\n",
        "fires.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nYMP-3L_Wru"
      },
      "source": [
        "A description of each variable is below:\n",
        "\n",
        "*   `X` is the x-coordinate of the fire on a map of the Portugal park (not very important)\n",
        "*   `Y` is the y-coordinate of the fire on a map of the Portugal park (not very important)\n",
        "*   `month` is the month the fire occured in\n",
        "*   `day` is the day of the week the fire occured on\n",
        "*   `FFMC` stands for \"Fine Fuel Moisture Code\" and indicates the moisture levels among the small leaves in the forest.\n",
        "*   `DMC` stands for \"Duff Moisture Code\" and indicates the moisture levels among decomposed organic material.\n",
        "*   `DC` stands for \"Drought Code\" and indicates how dry the deeper soil is.\n",
        "*   `ISI` stands for \"Initial Spread Index\" and takes into account the moisture of fuels for fire and windspeed to determine how likely things are to be spread around in the forest.\n",
        "*   `temp` is the temperature in Celsius during the fire.\n",
        "*   `RH` is the relative humidity in percentage terms.\n",
        "*   `wind` is the windspeed in $km/h$ during the fire.\n",
        "*   `rain` is the amount of rain in $mm/m^2$ during the fire.\n",
        "*   `area`, our outcome variable, is the amount of area burned by the fire in hectares.\n",
        "\n",
        "*Note*: a lot of these variables are correlated with one another. So it may be better to choose a subset of them when fitting models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QonX2cM1_Wrw"
      },
      "source": [
        "Then `scikit-learn` needs our outcome variable in a separate dataframe from our predictors. We create those two objects now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeLCaGTN_Wrw"
      },
      "outputs": [],
      "source": [
        "Y = fires[\"area\"]\n",
        "X = fires.drop(columns=\"area\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9vP5-yz_Wrx"
      },
      "source": [
        "Now we create our training and testing datasets. By making `random_state=0` we assure that everyone uses the same training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrhAYrTj_Wrx"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=.3,  random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5nkFstu_Wrx"
      },
      "source": [
        "OK take it away! Have fun creating your models!"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6e5r4Un57I2-"
      ],
      "name": "AppliedMachineLearning.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}