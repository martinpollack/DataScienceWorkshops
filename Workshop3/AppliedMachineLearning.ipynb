{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JPYaq5eWQ4n"
      },
      "source": [
        "# Introduction to Machine Learning\n",
        "### Workshop 3 of DASIL's series on \"Data Science with Python\"\n",
        "### Created by Yusen He & Martin Pollack"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0FGuCgcWQ4p"
      },
      "source": [
        "In this Jupyter notebook we will give you a quick introduction on how to fit machine learning models in Python with the `scikit-learn` package. \n",
        "\n",
        "Next week we will go much more into depth."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "UiT01kfZWQ4q"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEOwnQpUWQ4t"
      },
      "source": [
        "## Supervised Learning - Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NHTB5d26lQO"
      },
      "source": [
        "#### Dataset introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7L_N9Q6WQ4u"
      },
      "source": [
        "Remember that in a regression problem the outcome variable is numeric and continuous. However, the predictor variables can either be continuous or discrete.\n",
        "\n",
        "An example of a regression problem can be found in the diabetes dataset within sklearn. Our outcome is a quantitative measure of disease progression that takes on numbers between 25 and 346."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3ffUxHDLWQ4v"
      },
      "outputs": [],
      "source": [
        "diabetes = datasets.load_diabetes(as_frame=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`diabetes` is a special scikit-learn dataset. Its `target` field is a pandas Series with our continuous outcome variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      151.0\n",
              "1       75.0\n",
              "2      141.0\n",
              "3      206.0\n",
              "4      135.0\n",
              "       ...  \n",
              "437    178.0\n",
              "438    104.0\n",
              "439    132.0\n",
              "440    220.0\n",
              "441     57.0\n",
              "Name: target, Length: 442, dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diabetes.target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d-7lrwcWQ4w",
        "outputId": "5b54aafc-2a73-4c96-bdf5-d337a6b9f5f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "25.0\n",
            "346.0\n"
          ]
        }
      ],
      "source": [
        "print(min(diabetes.target))\n",
        "print(max(diabetes.target))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Re8w01hY86c"
      },
      "source": [
        "And its `data` field is a pandas Dataframe of all of our potential predictor variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "uZND0mNpYxjS",
        "outputId": "25c1b667-da38-44c5-8e13-bf5e77b9b2d6"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>bp</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.038076</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.061696</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>-0.044223</td>\n",
              "      <td>-0.034821</td>\n",
              "      <td>-0.043401</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.019908</td>\n",
              "      <td>-0.017646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.001882</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.051474</td>\n",
              "      <td>-0.026328</td>\n",
              "      <td>-0.008449</td>\n",
              "      <td>-0.019163</td>\n",
              "      <td>0.074412</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.068330</td>\n",
              "      <td>-0.092204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.085299</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.044451</td>\n",
              "      <td>-0.005671</td>\n",
              "      <td>-0.045599</td>\n",
              "      <td>-0.034194</td>\n",
              "      <td>-0.032356</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>-0.025930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.089063</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.011595</td>\n",
              "      <td>-0.036656</td>\n",
              "      <td>0.012191</td>\n",
              "      <td>0.024991</td>\n",
              "      <td>-0.036038</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>0.022692</td>\n",
              "      <td>-0.009362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.005383</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.036385</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>0.003935</td>\n",
              "      <td>0.015596</td>\n",
              "      <td>0.008142</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>-0.031991</td>\n",
              "      <td>-0.046641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>0.041708</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.019662</td>\n",
              "      <td>0.059744</td>\n",
              "      <td>-0.005697</td>\n",
              "      <td>-0.002566</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.031193</td>\n",
              "      <td>0.007207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>-0.005515</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>-0.067642</td>\n",
              "      <td>0.049341</td>\n",
              "      <td>0.079165</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>-0.018118</td>\n",
              "      <td>0.044485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>0.041708</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>0.017282</td>\n",
              "      <td>-0.037344</td>\n",
              "      <td>-0.013840</td>\n",
              "      <td>-0.024993</td>\n",
              "      <td>-0.011080</td>\n",
              "      <td>-0.046879</td>\n",
              "      <td>0.015491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>-0.045472</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>0.001215</td>\n",
              "      <td>0.016318</td>\n",
              "      <td>0.015283</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>0.026560</td>\n",
              "      <td>0.044528</td>\n",
              "      <td>-0.025930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>-0.045472</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.073030</td>\n",
              "      <td>-0.081414</td>\n",
              "      <td>0.083740</td>\n",
              "      <td>0.027809</td>\n",
              "      <td>0.173816</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.004220</td>\n",
              "      <td>0.003064</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>442 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          age       sex       bmi        bp        s1        s2        s3  \\\n",
              "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
              "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
              "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
              "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
              "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
              "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
              "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
              "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
              "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
              "\n",
              "           s4        s5        s6  \n",
              "0   -0.002592  0.019908 -0.017646  \n",
              "1   -0.039493 -0.068330 -0.092204  \n",
              "2   -0.002592  0.002864 -0.025930  \n",
              "3    0.034309  0.022692 -0.009362  \n",
              "4   -0.002592 -0.031991 -0.046641  \n",
              "..        ...       ...       ...  \n",
              "437 -0.002592  0.031193  0.007207  \n",
              "438  0.034309 -0.018118  0.044485  \n",
              "439 -0.011080 -0.046879  0.015491  \n",
              "440  0.026560  0.044528 -0.025930  \n",
              "441 -0.039493 -0.004220  0.003064  \n",
              "\n",
              "[442 rows x 10 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "diabetes.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LIxkNetfZdKT"
      },
      "source": [
        "#### Define the predictor variable set and a target\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bnxdeb4bctZ"
      },
      "source": [
        "For the regression tasks, a feature set `X` and a target set `y` need to be defined first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "3vEryq9hY7Ni",
        "outputId": "19005942-501b-499d-937c-7f686276330f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>sex</th>\n",
              "      <th>bmi</th>\n",
              "      <th>bp</th>\n",
              "      <th>s1</th>\n",
              "      <th>s2</th>\n",
              "      <th>s3</th>\n",
              "      <th>s4</th>\n",
              "      <th>s5</th>\n",
              "      <th>s6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.038076</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.061696</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>-0.044223</td>\n",
              "      <td>-0.034821</td>\n",
              "      <td>-0.043401</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.019908</td>\n",
              "      <td>-0.017646</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.001882</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.051474</td>\n",
              "      <td>-0.026328</td>\n",
              "      <td>-0.008449</td>\n",
              "      <td>-0.019163</td>\n",
              "      <td>0.074412</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.068330</td>\n",
              "      <td>-0.092204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.085299</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.044451</td>\n",
              "      <td>-0.005671</td>\n",
              "      <td>-0.045599</td>\n",
              "      <td>-0.034194</td>\n",
              "      <td>-0.032356</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.002864</td>\n",
              "      <td>-0.025930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.089063</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.011595</td>\n",
              "      <td>-0.036656</td>\n",
              "      <td>0.012191</td>\n",
              "      <td>0.024991</td>\n",
              "      <td>-0.036038</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>0.022692</td>\n",
              "      <td>-0.009362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.005383</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.036385</td>\n",
              "      <td>0.021872</td>\n",
              "      <td>0.003935</td>\n",
              "      <td>0.015596</td>\n",
              "      <td>0.008142</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>-0.031991</td>\n",
              "      <td>-0.046641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>0.041708</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>0.019662</td>\n",
              "      <td>0.059744</td>\n",
              "      <td>-0.005697</td>\n",
              "      <td>-0.002566</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>-0.002592</td>\n",
              "      <td>0.031193</td>\n",
              "      <td>0.007207</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>-0.005515</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>-0.067642</td>\n",
              "      <td>0.049341</td>\n",
              "      <td>0.079165</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>0.034309</td>\n",
              "      <td>-0.018118</td>\n",
              "      <td>0.044485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>0.041708</td>\n",
              "      <td>0.050680</td>\n",
              "      <td>-0.015906</td>\n",
              "      <td>0.017282</td>\n",
              "      <td>-0.037344</td>\n",
              "      <td>-0.013840</td>\n",
              "      <td>-0.024993</td>\n",
              "      <td>-0.011080</td>\n",
              "      <td>-0.046879</td>\n",
              "      <td>0.015491</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>-0.045472</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>0.039062</td>\n",
              "      <td>0.001215</td>\n",
              "      <td>0.016318</td>\n",
              "      <td>0.015283</td>\n",
              "      <td>-0.028674</td>\n",
              "      <td>0.026560</td>\n",
              "      <td>0.044528</td>\n",
              "      <td>-0.025930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>-0.045472</td>\n",
              "      <td>-0.044642</td>\n",
              "      <td>-0.073030</td>\n",
              "      <td>-0.081414</td>\n",
              "      <td>0.083740</td>\n",
              "      <td>0.027809</td>\n",
              "      <td>0.173816</td>\n",
              "      <td>-0.039493</td>\n",
              "      <td>-0.004220</td>\n",
              "      <td>0.003064</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>442 rows × 10 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          age       sex       bmi        bp        s1        s2        s3  \\\n",
              "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
              "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
              "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
              "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
              "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "437  0.041708  0.050680  0.019662  0.059744 -0.005697 -0.002566 -0.028674   \n",
              "438 -0.005515  0.050680 -0.015906 -0.067642  0.049341  0.079165 -0.028674   \n",
              "439  0.041708  0.050680 -0.015906  0.017282 -0.037344 -0.013840 -0.024993   \n",
              "440 -0.045472 -0.044642  0.039062  0.001215  0.016318  0.015283 -0.028674   \n",
              "441 -0.045472 -0.044642 -0.073030 -0.081414  0.083740  0.027809  0.173816   \n",
              "\n",
              "           s4        s5        s6  \n",
              "0   -0.002592  0.019908 -0.017646  \n",
              "1   -0.039493 -0.068330 -0.092204  \n",
              "2   -0.002592  0.002864 -0.025930  \n",
              "3    0.034309  0.022692 -0.009362  \n",
              "4   -0.002592 -0.031991 -0.046641  \n",
              "..        ...       ...       ...  \n",
              "437 -0.002592  0.031193  0.007207  \n",
              "438  0.034309 -0.018118  0.044485  \n",
              "439 -0.011080 -0.046879  0.015491  \n",
              "440  0.026560  0.044528 -0.025930  \n",
              "441 -0.039493 -0.004220  0.003064  \n",
              "\n",
              "[442 rows x 10 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = diabetes.data\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "zY4SVr_VbSqC",
        "outputId": "bedf0577-e871-425f-dc9c-f8899457a29f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0      151.0\n",
              "1       75.0\n",
              "2      141.0\n",
              "3      206.0\n",
              "4      135.0\n",
              "       ...  \n",
              "437    178.0\n",
              "438    104.0\n",
              "439    132.0\n",
              "440    220.0\n",
              "441     57.0\n",
              "Name: target, Length: 442, dtype: float64"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y = diabetes.target\n",
        "Y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "amRvAyBZaNez"
      },
      "source": [
        "#### Splitting the dataset into Training and Test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ro8jKDFpwSh"
      },
      "source": [
        "To evaluate the performance of our models, we need to randomly split our features dataset `X` and outcomes `Y` into a training set `X_train`/`y_train` and testing set `X_test`/`Y_test`. Randomly, we will use some observations to train our models and others see how our model generalizes to new data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40iJCmxjcLVC"
      },
      "source": [
        "The `sklearn.model_selection.train_test_split()` does the random split for the training and testing dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VADJGmpq-96"
      },
      "source": [
        "The `test_size` option controls the size of the test set. The `random_state` parameter controls the shuffling applied which can be ignored in this work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NZBrjZyeaTxa"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "WQ3sh-bKq0ko",
        "outputId": "991c2d8d-fe61-40f0-8257-303c0601b93b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(442, 10)\n",
            "(331, 10)\n",
            "(111, 10)\n",
            "(442,)\n",
            "(331,)\n",
            "(111,)\n"
          ]
        }
      ],
      "source": [
        "print(X.shape)\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "\n",
        "print(Y.shape)\n",
        "print(Y_train.shape)\n",
        "print(Y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19ntU4ger8wA"
      },
      "source": [
        "#### Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjXs3btQvjH_"
      },
      "source": [
        "Let's fit our first machine learning model!\n",
        "\n",
        "At a minimum this process takes two steps.\n",
        "\n",
        "First we create the model object, specifying any hyperparameters. In this case we want to use the `LinearRegression` object from `sklearn.linear_model`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "0ArrMz1IthGn"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "regressor_LinReg = LinearRegression()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF0zkZimvm2Q"
      },
      "source": [
        "Second we have to actually fit the linear regression model using our training data. This is done by calling the `fit()` method on our model object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKYPHVBJvsnB",
        "outputId": "a01f2f63-8b31-4037-9258-29a30220fa54"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LinearRegression()"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "regressor_LinReg.fit(X_train,Y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQlOWLImv3tr"
      },
      "source": [
        "Make predictions on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJt3Ymrsv6iI"
      },
      "outputs": [],
      "source": [
        "GLM_pred = regressor_LinReg.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1_xHJYlKcK-"
      },
      "source": [
        "#### Artificial Neural Network for regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhMzhu83KcK_"
      },
      "source": [
        "Set up the artifical neural network model. Name it as `regressor`. Define the number of hidden layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u1IhG5bQKcK_"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "regressor_ANN_default = MLPRegressor(solver='lbfgs', max_iter=2000, learning_rate_init=0.000001,hidden_layer_sizes=(40,1), random_state=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.34888647829370967"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "regressor_ANN_default.fit(X_train, Y_train)\n",
        "regressor_ANN_default.score(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1r27sd4IPZsW"
      },
      "source": [
        "Tuning the Parameters in our NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3R-sVlyILri3",
        "outputId": "dde81c53-15b8-4282-8831-b95055043d85"
      },
      "outputs": [],
      "source": [
        "parameters = {'solver':['lbfgs'], 'learning_rate_init':[0.001], 'hidden_layer_sizes':[(200,1)]}\n",
        "regressor_ANN_tuned_grid = GridSearchCV(regressor_ANN_default, parameters)\n",
        "\n",
        "#regressor_ANN_tuned_grid.fit(X_train,Y_train)\n",
        "#This is a lot of results\n",
        "#print(regressor_ANN_tuned_grid.cv_results_)\n",
        "#This is less (but more important)\n",
        "#ANN_pred = regressor_ANN_tuned_grid.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=MLPRegressor(hidden_layer_sizes=(40, 1),\n",
              "                                    learning_rate_init=1e-06, max_iter=2000,\n",
              "                                    random_state=1, solver='lbfgs'),\n",
              "             param_grid={'hidden_layer_sizes': [(200, 1)],\n",
              "                         'learning_rate_init': [0.001], 'solver': ['lbfgs']})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "regressor_ANN_tuned_grid.fit(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "MLPRegressor(hidden_layer_sizes=(200, 1), max_iter=2000, random_state=1,\n",
              "             solver='lbfgs')"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "regressor_ANN_tuned_grid.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qKeB6KumRoQ0",
        "outputId": "6d8cfc95-6088-46f2-a761-0ae13a9cb017"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([281., 220., 178.,  72., 200., 281.,  72., 202., 200., 200., 200.,\n",
              "       220.,  71.,  72., 220.,  71., 200.,  72.,  72., 220.,  71., 200.,\n",
              "       202., 200., 220., 109.,  48.,  72., 200.,  91., 202.,  72., 200.,\n",
              "       200.,  84., 200.,  91.,  91., 200., 220.,  72., 220., 109., 200.,\n",
              "       220.,  72.,  72., 200.,  91., 220.,  71.,  71., 200.,  91., 258.,\n",
              "       220., 220.,  72.,  84., 220., 200., 200.,  91.,  91., 281., 200.,\n",
              "        72., 220., 220.,  72.,  72.,  91.,  71.,  72.,  71., 220.,  91.,\n",
              "       220., 220., 109., 109., 220.,  72., 220.,  71.,  72.,  72., 220.,\n",
              "        72., 202.,  72.,  71.,  72.,  91.,  72.,  72., 281., 109.,  71.,\n",
              "       202., 200.,  72., 220.,  84., 220.,  91., 220., 220.,  72.,  71.,\n",
              "       202.])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ANN_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwgYE5sUKcK_"
      },
      "source": [
        "Fit the ANN model using the input `X_train` and output `y_train`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GPoEd2jWKcK_",
        "outputId": "e872d5bf-0555-43c8-b365-e9b69e76fb7b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:1109: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "MLPClassifier(alpha=1e-05, hidden_layer_sizes=(250, 1), random_state=1)"
            ]
          },
          "execution_count": 158,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "regressor_ANN.fit(X_train,y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lMXwRzRKcLA"
      },
      "source": [
        "Making predictions on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H_mOK2wVKcLA"
      },
      "outputs": [],
      "source": [
        "ANN_pred = regressor_ANN.predict(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8ALjumfss_Y"
      },
      "source": [
        "#### Support Vector Machine Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxPNfrcit2i_"
      },
      "source": [
        "Set up the support vector machine for regression. Name it as `regressor_SVR`. Use `rbf` as the kernel function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-m2IZ8etF24"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVR\n",
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZD23upduB_5"
      },
      "source": [
        "Fit the SVR model using the input `X_train` and output `y_train`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XXL8l4nuMiv",
        "outputId": "303b7b5a-c8c7-4e23-9b1b-4358faa0dbb5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SVR()"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Your code here\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vqAofH3wuRhJ"
      },
      "source": [
        "Make predictions on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3t33mmOuQ0a"
      },
      "outputs": [],
      "source": [
        "# your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbtu3t5bwXWf"
      },
      "source": [
        "#### Performance Assessment\n",
        "\n",
        "*   Mean Absolute Error\n",
        "*   Mean Absolute Percentage Error\n",
        "*   Mean Square Error\n",
        "*   Root-Mean-Square Error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xN5qPEBsJ4kr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEexDKqYx3cA"
      },
      "source": [
        "First, let's compute Mean Absolute Error (MAE) for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kr21dcF-wqao",
        "outputId": "54afc4b8-cfe8-423d-930b-3448a8183ab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The MAE of predictions provided by GLM is :\n",
            "45.120987683251\n",
            "The MAE of predictions provided by SVR is :\n",
            "52.45903046955925\n",
            "The MAE of predictions provided by ANN is :\n",
            "53.306306306306304\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "MAE_GLM = mean_absolute_error(y_test, GLM_pred)\n",
        "MAE_SVR = mean_absolute_error(y_test, SVR_pred)\n",
        "MAE_ANN = mean_absolute_error(y_test, ANN_pred)\n",
        "\n",
        "print(\"The MAE of predictions provided by GLM is :\")\n",
        "print(MAE_GLM)\n",
        "\n",
        "print(\"The MAE of predictions provided by SVR is :\")\n",
        "print(MAE_SVR)\n",
        "\n",
        "print(\"The MAE of predictions provided by ANN is :\")\n",
        "print(MAE_ANN)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZCsUF1EyATg"
      },
      "source": [
        "Second, let's compute Mean Absolute Percentage Error (MAPE) for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bpCMtL9S3U0h",
        "outputId": "2137e069-3202-43ce-f46e-bace10bc679b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The MAPE of predictions provided by GLM is :\n",
            "0.37961401187552524\n",
            "The MAPE of predictions provided by SVR is :\n",
            "0.4218772291282973\n",
            "The MAPE of predictions provided by ANN is :\n",
            "0.3592407768614211\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_absolute_percentage_error\n",
        "MAPE_GLM = mean_absolute_percentage_error(y_test, GLM_pred)\n",
        "MAPE_SVR = mean_absolute_percentage_error(y_test, SVR_pred)\n",
        "MAPE_ANN = mean_absolute_percentage_error(y_test, ANN_pred)\n",
        "\n",
        "print(\"The MAPE of predictions provided by GLM is :\")\n",
        "print(MAPE_GLM)\n",
        "\n",
        "print(\"The MAPE of predictions provided by SVR is :\")\n",
        "print(MAPE_SVR)\n",
        "\n",
        "print(\"The MAPE of predictions provided by ANN is :\")\n",
        "print(MAPE_ANN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2neFZEkyIJh"
      },
      "source": [
        "Third, let's compute Mean Square Error (MSE) for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v44igycf39JO",
        "outputId": "2984a3ab-a843-45c7-9b65-aa1c1af2ed96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The MSE of predictions provided by GLM is :\n",
            "3180.1988368427265\n",
            "The MSE of predictions provided by SVR is :\n",
            "4277.196345895227\n",
            "The MSE of predictions provided by ANN is :\n",
            "5218.369369369369\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "MSE_GLM = mean_squared_error(y_test, GLM_pred)\n",
        "MSE_SVR = mean_squared_error(y_test, SVR_pred)\n",
        "MSE_ANN = mean_squared_error(y_test, ANN_pred)\n",
        "\n",
        "print(\"The MSE of predictions provided by GLM is :\")\n",
        "print(MSE_GLM)\n",
        "\n",
        "print(\"The MSE of predictions provided by SVR is :\")\n",
        "print(MSE_SVR)\n",
        "\n",
        "print(\"The MSE of predictions provided by ANN is :\")\n",
        "print(MSE_ANN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKo8f8k5yOEh"
      },
      "source": [
        "Last, let's compute Root-Mean-Suqare-Error (RMSE) for predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5aBlPKXL5oAh",
        "outputId": "ff1d9716-605d-446c-9203-179093d3e60c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The RMSE of predictions provided by GLM is :\n",
            "56.39325169594964\n",
            "The RMSE of predictions provided by SVR is :\n",
            "65.4002778732264\n",
            "The RMSE of predictions provided by ANN is :\n",
            "72.23828188273424\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "RMSE_GLM = mean_squared_error(y_test, GLM_pred, squared=False)\n",
        "RMSE_SVR = mean_squared_error(y_test, SVR_pred, squared=False)\n",
        "RMSE_ANN = mean_squared_error(y_test, ANN_pred, squared=False)\n",
        "\n",
        "print(\"The RMSE of predictions provided by GLM is :\")\n",
        "print(RMSE_GLM)\n",
        "\n",
        "print(\"The RMSE of predictions provided by SVR is :\")\n",
        "print(RMSE_SVR)\n",
        "\n",
        "print(\"The RMSE of predictions provided by ANN is :\")\n",
        "print(RMSE_ANN)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SarBlYm2WQ4x"
      },
      "source": [
        "## Supervised Learning - Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULypkTWU9hEp"
      },
      "source": [
        "#### Dataset Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29YqLUpTWQ4z"
      },
      "source": [
        "Now let's look at a classification problem, where the outcome can only take on 2 or more discrete values. But of course our predictors can be either continuous or discrete.\n",
        "\n",
        "Now we use `scikit-learn`'s breast cancer dataset. Here the outcome can take on a 0, for no breast cancer, or 1, for breast cancer. \n",
        "\n",
        "So in this case we actually have a *binary classification* problem, meaning our category can only take on 2 discrete values. In most binary classification problems, like in this case, the categories are 0 and 1 indiciating the presence or absence of some trait."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Jmrv4VMWQ41"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "breast_cancer = load_breast_cancer(as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PZau-rgMWQ41",
        "outputId": "b2086757-82cd-4c3a-b6ee-f7b4113dc8d0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    357\n",
              "0    212\n",
              "Name: target, dtype: int64"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "breast_cancer.target.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "NU-R05ZjXEbr",
        "outputId": "2142159d-2011-4fb6-ea88-3df509bd5c1a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3d591af0-f0b4-464a-a007-65a751db1320\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d591af0-f0b4-464a-a007-65a751db1320')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d591af0-f0b4-464a-a007-65a751db1320 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d591af0-f0b4-464a-a007-65a751db1320');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "0                   0.07871  ...        25.380          17.33   \n",
              "1                   0.05667  ...        24.990          23.41   \n",
              "2                   0.05999  ...        23.570          25.53   \n",
              "3                   0.09744  ...        14.910          26.50   \n",
              "4                   0.05883  ...        22.540          16.67   \n",
              "..                      ...  ...           ...            ...   \n",
              "564                 0.05623  ...        25.450          26.40   \n",
              "565                 0.05533  ...        23.690          38.25   \n",
              "566                 0.05648  ...        18.980          34.12   \n",
              "567                 0.07016  ...        25.740          39.42   \n",
              "568                 0.05884  ...         9.456          30.37   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "0             184.60      2019.0           0.16220            0.66560   \n",
              "1             158.80      1956.0           0.12380            0.18660   \n",
              "2             152.50      1709.0           0.14440            0.42450   \n",
              "3              98.87       567.7           0.20980            0.86630   \n",
              "4             152.20      1575.0           0.13740            0.20500   \n",
              "..               ...         ...               ...                ...   \n",
              "564           166.10      2027.0           0.14100            0.21130   \n",
              "565           155.00      1731.0           0.11660            0.19220   \n",
              "566           126.70      1124.0           0.11390            0.30940   \n",
              "567           184.60      1821.0           0.16500            0.86810   \n",
              "568            59.16       268.6           0.08996            0.06444   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "0             0.7119                0.2654          0.4601   \n",
              "1             0.2416                0.1860          0.2750   \n",
              "2             0.4504                0.2430          0.3613   \n",
              "3             0.6869                0.2575          0.6638   \n",
              "4             0.4000                0.1625          0.2364   \n",
              "..               ...                   ...             ...   \n",
              "564           0.4107                0.2216          0.2060   \n",
              "565           0.3215                0.1628          0.2572   \n",
              "566           0.3403                0.1418          0.2218   \n",
              "567           0.9387                0.2650          0.4087   \n",
              "568           0.0000                0.0000          0.2871   \n",
              "\n",
              "     worst fractal dimension  \n",
              "0                    0.11890  \n",
              "1                    0.08902  \n",
              "2                    0.08758  \n",
              "3                    0.17300  \n",
              "4                    0.07678  \n",
              "..                       ...  \n",
              "564                  0.07115  \n",
              "565                  0.06637  \n",
              "566                  0.07820  \n",
              "567                  0.12400  \n",
              "568                  0.07039  \n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "breast_cancer.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SnasUbL_9xOg"
      },
      "source": [
        "#### Define the predictor variable set and a target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQALRlB997O7"
      },
      "source": [
        "For the regression tasks, a feature set `X` and a target set `y` need to be defined first"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "eWj12b_r98X8",
        "outputId": "edbc548a-c8e4-4437-98ed-638008618ae1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-88d269db-3ef0-4d14-a2f7-3a7c51c84c3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>...</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>...</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>...</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>...</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>...</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>...</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>...</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>...</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>...</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>...</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-88d269db-3ef0-4d14-a2f7-3a7c51c84c3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-88d269db-3ef0-4d14-a2f7-3a7c51c84c3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-88d269db-3ef0-4d14-a2f7-3a7c51c84c3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "0          17.99         10.38          122.80     1001.0          0.11840   \n",
              "1          20.57         17.77          132.90     1326.0          0.08474   \n",
              "2          19.69         21.25          130.00     1203.0          0.10960   \n",
              "3          11.42         20.38           77.58      386.1          0.14250   \n",
              "4          20.29         14.34          135.10     1297.0          0.10030   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "564        21.56         22.39          142.00     1479.0          0.11100   \n",
              "565        20.13         28.25          131.20     1261.0          0.09780   \n",
              "566        16.60         28.08          108.30      858.1          0.08455   \n",
              "567        20.60         29.33          140.10     1265.0          0.11780   \n",
              "568         7.76         24.54           47.92      181.0          0.05263   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "0             0.27760         0.30010              0.14710         0.2419   \n",
              "1             0.07864         0.08690              0.07017         0.1812   \n",
              "2             0.15990         0.19740              0.12790         0.2069   \n",
              "3             0.28390         0.24140              0.10520         0.2597   \n",
              "4             0.13280         0.19800              0.10430         0.1809   \n",
              "..                ...             ...                  ...            ...   \n",
              "564           0.11590         0.24390              0.13890         0.1726   \n",
              "565           0.10340         0.14400              0.09791         0.1752   \n",
              "566           0.10230         0.09251              0.05302         0.1590   \n",
              "567           0.27700         0.35140              0.15200         0.2397   \n",
              "568           0.04362         0.00000              0.00000         0.1587   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "0                   0.07871  ...        25.380          17.33   \n",
              "1                   0.05667  ...        24.990          23.41   \n",
              "2                   0.05999  ...        23.570          25.53   \n",
              "3                   0.09744  ...        14.910          26.50   \n",
              "4                   0.05883  ...        22.540          16.67   \n",
              "..                      ...  ...           ...            ...   \n",
              "564                 0.05623  ...        25.450          26.40   \n",
              "565                 0.05533  ...        23.690          38.25   \n",
              "566                 0.05648  ...        18.980          34.12   \n",
              "567                 0.07016  ...        25.740          39.42   \n",
              "568                 0.05884  ...         9.456          30.37   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "0             184.60      2019.0           0.16220            0.66560   \n",
              "1             158.80      1956.0           0.12380            0.18660   \n",
              "2             152.50      1709.0           0.14440            0.42450   \n",
              "3              98.87       567.7           0.20980            0.86630   \n",
              "4             152.20      1575.0           0.13740            0.20500   \n",
              "..               ...         ...               ...                ...   \n",
              "564           166.10      2027.0           0.14100            0.21130   \n",
              "565           155.00      1731.0           0.11660            0.19220   \n",
              "566           126.70      1124.0           0.11390            0.30940   \n",
              "567           184.60      1821.0           0.16500            0.86810   \n",
              "568            59.16       268.6           0.08996            0.06444   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "0             0.7119                0.2654          0.4601   \n",
              "1             0.2416                0.1860          0.2750   \n",
              "2             0.4504                0.2430          0.3613   \n",
              "3             0.6869                0.2575          0.6638   \n",
              "4             0.4000                0.1625          0.2364   \n",
              "..               ...                   ...             ...   \n",
              "564           0.4107                0.2216          0.2060   \n",
              "565           0.3215                0.1628          0.2572   \n",
              "566           0.3403                0.1418          0.2218   \n",
              "567           0.9387                0.2650          0.4087   \n",
              "568           0.0000                0.0000          0.2871   \n",
              "\n",
              "     worst fractal dimension  \n",
              "0                    0.11890  \n",
              "1                    0.08902  \n",
              "2                    0.08758  \n",
              "3                    0.17300  \n",
              "4                    0.07678  \n",
              "..                       ...  \n",
              "564                  0.07115  \n",
              "565                  0.06637  \n",
              "566                  0.07820  \n",
              "567                  0.12400  \n",
              "568                  0.07039  \n",
              "\n",
              "[569 rows x 30 columns]"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = pd.DataFrame(breast_cancer['data'])\n",
        "X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "TkzBmuh6-B6J",
        "outputId": "4d4fef68-0bc3-4f84-8222-ac04c84270f7"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3776d117-f015-4d20-98d6-73495d75935d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3776d117-f015-4d20-98d6-73495d75935d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3776d117-f015-4d20-98d6-73495d75935d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3776d117-f015-4d20-98d6-73495d75935d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     target\n",
              "0         0\n",
              "1         0\n",
              "2         0\n",
              "3         0\n",
              "4         0\n",
              "..      ...\n",
              "564       0\n",
              "565       0\n",
              "566       0\n",
              "567       0\n",
              "568       1\n",
              "\n",
              "[569 rows x 1 columns]"
            ]
          },
          "execution_count": 49,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y = pd.DataFrame(breast_cancer['target'])\n",
        "y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56eOA-Y_9lcz"
      },
      "source": [
        "#### Split the dataset into training and test set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89bteG4dHsXY"
      },
      "source": [
        "The `sklearn.model_selection.train_test_split` does the random split for the training and testing dataset.\n",
        "\n",
        "Note: Here, `stratify` means the test set has equal numbers of 0 & 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HU4MmjqLHtaQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, stratify=y,  random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XB6c_jrmIdF4"
      },
      "source": [
        "To evaluate the model performance, we need to randomly split the feature set `X` and the target set `y` into the training set `X_train` & `y_train` and test set `X_test` & `y_test`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qayqpBTIdp3"
      },
      "source": [
        "The `test_size` option controls the size of the test set. The `random_state` parameter controls the shuffling applied which can be ignored in this work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "5eLqQ1M6Ih1k",
        "outputId": "4dd50ede-6800-4669-b3c2-db5d850ae238"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-82179fa9-a53a-42ee-9a62-35e850f3a354\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>13.20</td>\n",
              "      <td>17.43</td>\n",
              "      <td>84.13</td>\n",
              "      <td>541.6</td>\n",
              "      <td>0.07215</td>\n",
              "      <td>0.04524</td>\n",
              "      <td>0.043360</td>\n",
              "      <td>0.011050</td>\n",
              "      <td>0.1487</td>\n",
              "      <td>0.05635</td>\n",
              "      <td>...</td>\n",
              "      <td>13.94</td>\n",
              "      <td>27.82</td>\n",
              "      <td>88.28</td>\n",
              "      <td>602.0</td>\n",
              "      <td>0.11010</td>\n",
              "      <td>0.15080</td>\n",
              "      <td>0.22980</td>\n",
              "      <td>0.04970</td>\n",
              "      <td>0.2767</td>\n",
              "      <td>0.07198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>11.22</td>\n",
              "      <td>33.81</td>\n",
              "      <td>70.79</td>\n",
              "      <td>386.8</td>\n",
              "      <td>0.07780</td>\n",
              "      <td>0.03574</td>\n",
              "      <td>0.004967</td>\n",
              "      <td>0.006434</td>\n",
              "      <td>0.1845</td>\n",
              "      <td>0.05828</td>\n",
              "      <td>...</td>\n",
              "      <td>12.36</td>\n",
              "      <td>41.78</td>\n",
              "      <td>78.44</td>\n",
              "      <td>470.9</td>\n",
              "      <td>0.09994</td>\n",
              "      <td>0.06885</td>\n",
              "      <td>0.02318</td>\n",
              "      <td>0.03002</td>\n",
              "      <td>0.2911</td>\n",
              "      <td>0.07307</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>14.54</td>\n",
              "      <td>27.54</td>\n",
              "      <td>96.73</td>\n",
              "      <td>658.8</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.15950</td>\n",
              "      <td>0.163900</td>\n",
              "      <td>0.073640</td>\n",
              "      <td>0.2303</td>\n",
              "      <td>0.07077</td>\n",
              "      <td>...</td>\n",
              "      <td>17.46</td>\n",
              "      <td>37.13</td>\n",
              "      <td>124.10</td>\n",
              "      <td>943.2</td>\n",
              "      <td>0.16780</td>\n",
              "      <td>0.65770</td>\n",
              "      <td>0.70260</td>\n",
              "      <td>0.17120</td>\n",
              "      <td>0.4218</td>\n",
              "      <td>0.13410</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>15.10</td>\n",
              "      <td>16.39</td>\n",
              "      <td>99.58</td>\n",
              "      <td>674.5</td>\n",
              "      <td>0.11500</td>\n",
              "      <td>0.18070</td>\n",
              "      <td>0.113800</td>\n",
              "      <td>0.085340</td>\n",
              "      <td>0.2001</td>\n",
              "      <td>0.06467</td>\n",
              "      <td>...</td>\n",
              "      <td>16.11</td>\n",
              "      <td>18.33</td>\n",
              "      <td>105.90</td>\n",
              "      <td>762.6</td>\n",
              "      <td>0.13860</td>\n",
              "      <td>0.28830</td>\n",
              "      <td>0.19600</td>\n",
              "      <td>0.14230</td>\n",
              "      <td>0.2590</td>\n",
              "      <td>0.07779</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>17.29</td>\n",
              "      <td>22.13</td>\n",
              "      <td>114.40</td>\n",
              "      <td>947.8</td>\n",
              "      <td>0.08999</td>\n",
              "      <td>0.12730</td>\n",
              "      <td>0.096970</td>\n",
              "      <td>0.075070</td>\n",
              "      <td>0.2108</td>\n",
              "      <td>0.05464</td>\n",
              "      <td>...</td>\n",
              "      <td>20.39</td>\n",
              "      <td>27.24</td>\n",
              "      <td>137.90</td>\n",
              "      <td>1295.0</td>\n",
              "      <td>0.11340</td>\n",
              "      <td>0.28670</td>\n",
              "      <td>0.22980</td>\n",
              "      <td>0.15280</td>\n",
              "      <td>0.3067</td>\n",
              "      <td>0.07484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>25.22</td>\n",
              "      <td>24.91</td>\n",
              "      <td>171.50</td>\n",
              "      <td>1878.0</td>\n",
              "      <td>0.10630</td>\n",
              "      <td>0.26650</td>\n",
              "      <td>0.333900</td>\n",
              "      <td>0.184500</td>\n",
              "      <td>0.1829</td>\n",
              "      <td>0.06782</td>\n",
              "      <td>...</td>\n",
              "      <td>30.00</td>\n",
              "      <td>33.62</td>\n",
              "      <td>211.70</td>\n",
              "      <td>2562.0</td>\n",
              "      <td>0.15730</td>\n",
              "      <td>0.60760</td>\n",
              "      <td>0.64760</td>\n",
              "      <td>0.28670</td>\n",
              "      <td>0.2355</td>\n",
              "      <td>0.10510</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>10.80</td>\n",
              "      <td>9.71</td>\n",
              "      <td>68.77</td>\n",
              "      <td>357.6</td>\n",
              "      <td>0.09594</td>\n",
              "      <td>0.05736</td>\n",
              "      <td>0.025310</td>\n",
              "      <td>0.016980</td>\n",
              "      <td>0.1381</td>\n",
              "      <td>0.06400</td>\n",
              "      <td>...</td>\n",
              "      <td>11.60</td>\n",
              "      <td>12.02</td>\n",
              "      <td>73.66</td>\n",
              "      <td>414.0</td>\n",
              "      <td>0.14360</td>\n",
              "      <td>0.12570</td>\n",
              "      <td>0.10470</td>\n",
              "      <td>0.04603</td>\n",
              "      <td>0.2090</td>\n",
              "      <td>0.07699</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>11.06</td>\n",
              "      <td>14.96</td>\n",
              "      <td>71.49</td>\n",
              "      <td>373.9</td>\n",
              "      <td>0.10330</td>\n",
              "      <td>0.09097</td>\n",
              "      <td>0.053970</td>\n",
              "      <td>0.033410</td>\n",
              "      <td>0.1776</td>\n",
              "      <td>0.06907</td>\n",
              "      <td>...</td>\n",
              "      <td>11.92</td>\n",
              "      <td>19.90</td>\n",
              "      <td>79.76</td>\n",
              "      <td>440.0</td>\n",
              "      <td>0.14180</td>\n",
              "      <td>0.22100</td>\n",
              "      <td>0.22990</td>\n",
              "      <td>0.10750</td>\n",
              "      <td>0.3301</td>\n",
              "      <td>0.09080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>11.99</td>\n",
              "      <td>24.89</td>\n",
              "      <td>77.61</td>\n",
              "      <td>441.3</td>\n",
              "      <td>0.10300</td>\n",
              "      <td>0.09218</td>\n",
              "      <td>0.054410</td>\n",
              "      <td>0.042740</td>\n",
              "      <td>0.1820</td>\n",
              "      <td>0.06850</td>\n",
              "      <td>...</td>\n",
              "      <td>12.98</td>\n",
              "      <td>30.36</td>\n",
              "      <td>84.48</td>\n",
              "      <td>513.9</td>\n",
              "      <td>0.13110</td>\n",
              "      <td>0.18220</td>\n",
              "      <td>0.16090</td>\n",
              "      <td>0.12020</td>\n",
              "      <td>0.2599</td>\n",
              "      <td>0.08251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>12.39</td>\n",
              "      <td>17.48</td>\n",
              "      <td>80.64</td>\n",
              "      <td>462.9</td>\n",
              "      <td>0.10420</td>\n",
              "      <td>0.12970</td>\n",
              "      <td>0.058920</td>\n",
              "      <td>0.028800</td>\n",
              "      <td>0.1779</td>\n",
              "      <td>0.06588</td>\n",
              "      <td>...</td>\n",
              "      <td>14.18</td>\n",
              "      <td>23.13</td>\n",
              "      <td>95.23</td>\n",
              "      <td>600.5</td>\n",
              "      <td>0.14270</td>\n",
              "      <td>0.35930</td>\n",
              "      <td>0.32060</td>\n",
              "      <td>0.09804</td>\n",
              "      <td>0.2819</td>\n",
              "      <td>0.11180</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>398 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-82179fa9-a53a-42ee-9a62-35e850f3a354')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-82179fa9-a53a-42ee-9a62-35e850f3a354 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-82179fa9-a53a-42ee-9a62-35e850f3a354');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "246        13.20         17.43           84.13      541.6          0.07215   \n",
              "232        11.22         33.81           70.79      386.8          0.07780   \n",
              "15         14.54         27.54           96.73      658.8          0.11390   \n",
              "128        15.10         16.39           99.58      674.5          0.11500   \n",
              "262        17.29         22.13          114.40      947.8          0.08999   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "82         25.22         24.91          171.50     1878.0          0.10630   \n",
              "166        10.80          9.71           68.77      357.6          0.09594   \n",
              "342        11.06         14.96           71.49      373.9          0.10330   \n",
              "445        11.99         24.89           77.61      441.3          0.10300   \n",
              "383        12.39         17.48           80.64      462.9          0.10420   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "246           0.04524        0.043360             0.011050         0.1487   \n",
              "232           0.03574        0.004967             0.006434         0.1845   \n",
              "15            0.15950        0.163900             0.073640         0.2303   \n",
              "128           0.18070        0.113800             0.085340         0.2001   \n",
              "262           0.12730        0.096970             0.075070         0.2108   \n",
              "..                ...             ...                  ...            ...   \n",
              "82            0.26650        0.333900             0.184500         0.1829   \n",
              "166           0.05736        0.025310             0.016980         0.1381   \n",
              "342           0.09097        0.053970             0.033410         0.1776   \n",
              "445           0.09218        0.054410             0.042740         0.1820   \n",
              "383           0.12970        0.058920             0.028800         0.1779   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "246                 0.05635  ...         13.94          27.82   \n",
              "232                 0.05828  ...         12.36          41.78   \n",
              "15                  0.07077  ...         17.46          37.13   \n",
              "128                 0.06467  ...         16.11          18.33   \n",
              "262                 0.05464  ...         20.39          27.24   \n",
              "..                      ...  ...           ...            ...   \n",
              "82                  0.06782  ...         30.00          33.62   \n",
              "166                 0.06400  ...         11.60          12.02   \n",
              "342                 0.06907  ...         11.92          19.90   \n",
              "445                 0.06850  ...         12.98          30.36   \n",
              "383                 0.06588  ...         14.18          23.13   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "246            88.28       602.0           0.11010            0.15080   \n",
              "232            78.44       470.9           0.09994            0.06885   \n",
              "15            124.10       943.2           0.16780            0.65770   \n",
              "128           105.90       762.6           0.13860            0.28830   \n",
              "262           137.90      1295.0           0.11340            0.28670   \n",
              "..               ...         ...               ...                ...   \n",
              "82            211.70      2562.0           0.15730            0.60760   \n",
              "166            73.66       414.0           0.14360            0.12570   \n",
              "342            79.76       440.0           0.14180            0.22100   \n",
              "445            84.48       513.9           0.13110            0.18220   \n",
              "383            95.23       600.5           0.14270            0.35930   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "246          0.22980               0.04970          0.2767   \n",
              "232          0.02318               0.03002          0.2911   \n",
              "15           0.70260               0.17120          0.4218   \n",
              "128          0.19600               0.14230          0.2590   \n",
              "262          0.22980               0.15280          0.3067   \n",
              "..               ...                   ...             ...   \n",
              "82           0.64760               0.28670          0.2355   \n",
              "166          0.10470               0.04603          0.2090   \n",
              "342          0.22990               0.10750          0.3301   \n",
              "445          0.16090               0.12020          0.2599   \n",
              "383          0.32060               0.09804          0.2819   \n",
              "\n",
              "     worst fractal dimension  \n",
              "246                  0.07198  \n",
              "232                  0.07307  \n",
              "15                   0.13410  \n",
              "128                  0.07779  \n",
              "262                  0.07484  \n",
              "..                       ...  \n",
              "82                   0.10510  \n",
              "166                  0.07699  \n",
              "342                  0.09080  \n",
              "445                  0.08251  \n",
              "383                  0.11180  \n",
              "\n",
              "[398 rows x 30 columns]"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "e5pjq0pjIlWx",
        "outputId": "53f4d988-cb12-4b75-9ff6-07e293667127"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-2c9d847f-d6e3-4a58-80ef-20b60cc05fea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>398 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c9d847f-d6e3-4a58-80ef-20b60cc05fea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c9d847f-d6e3-4a58-80ef-20b60cc05fea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c9d847f-d6e3-4a58-80ef-20b60cc05fea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     target\n",
              "246       1\n",
              "232       1\n",
              "15        0\n",
              "128       1\n",
              "262       0\n",
              "..      ...\n",
              "82        0\n",
              "166       1\n",
              "342       1\n",
              "445       1\n",
              "383       1\n",
              "\n",
              "[398 rows x 1 columns]"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "k0vJoDw7IlcD",
        "outputId": "24f345c0-556b-48eb-fecb-111629f6172c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bf9ec9f9-ac01-46d2-acd7-059905bac69e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>...</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>17.08</td>\n",
              "      <td>27.15</td>\n",
              "      <td>111.20</td>\n",
              "      <td>930.9</td>\n",
              "      <td>0.09898</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.10070</td>\n",
              "      <td>0.06431</td>\n",
              "      <td>0.1793</td>\n",
              "      <td>0.06281</td>\n",
              "      <td>...</td>\n",
              "      <td>22.960</td>\n",
              "      <td>34.49</td>\n",
              "      <td>152.10</td>\n",
              "      <td>1648.0</td>\n",
              "      <td>0.16000</td>\n",
              "      <td>0.24440</td>\n",
              "      <td>0.26390</td>\n",
              "      <td>0.15550</td>\n",
              "      <td>0.3010</td>\n",
              "      <td>0.09060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>12.77</td>\n",
              "      <td>22.47</td>\n",
              "      <td>81.72</td>\n",
              "      <td>506.3</td>\n",
              "      <td>0.09055</td>\n",
              "      <td>0.05761</td>\n",
              "      <td>0.04711</td>\n",
              "      <td>0.02704</td>\n",
              "      <td>0.1585</td>\n",
              "      <td>0.06065</td>\n",
              "      <td>...</td>\n",
              "      <td>14.490</td>\n",
              "      <td>33.37</td>\n",
              "      <td>92.04</td>\n",
              "      <td>653.6</td>\n",
              "      <td>0.14190</td>\n",
              "      <td>0.15230</td>\n",
              "      <td>0.21770</td>\n",
              "      <td>0.09331</td>\n",
              "      <td>0.2829</td>\n",
              "      <td>0.08067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>14.25</td>\n",
              "      <td>22.15</td>\n",
              "      <td>96.42</td>\n",
              "      <td>645.7</td>\n",
              "      <td>0.10490</td>\n",
              "      <td>0.20080</td>\n",
              "      <td>0.21350</td>\n",
              "      <td>0.08653</td>\n",
              "      <td>0.1949</td>\n",
              "      <td>0.07292</td>\n",
              "      <td>...</td>\n",
              "      <td>17.670</td>\n",
              "      <td>29.51</td>\n",
              "      <td>119.10</td>\n",
              "      <td>959.5</td>\n",
              "      <td>0.16400</td>\n",
              "      <td>0.62470</td>\n",
              "      <td>0.69220</td>\n",
              "      <td>0.17850</td>\n",
              "      <td>0.2844</td>\n",
              "      <td>0.11320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>12.45</td>\n",
              "      <td>16.41</td>\n",
              "      <td>82.85</td>\n",
              "      <td>476.7</td>\n",
              "      <td>0.09514</td>\n",
              "      <td>0.15110</td>\n",
              "      <td>0.15440</td>\n",
              "      <td>0.04846</td>\n",
              "      <td>0.2082</td>\n",
              "      <td>0.07325</td>\n",
              "      <td>...</td>\n",
              "      <td>13.780</td>\n",
              "      <td>21.03</td>\n",
              "      <td>97.82</td>\n",
              "      <td>580.6</td>\n",
              "      <td>0.11750</td>\n",
              "      <td>0.40610</td>\n",
              "      <td>0.48960</td>\n",
              "      <td>0.13420</td>\n",
              "      <td>0.3231</td>\n",
              "      <td>0.10340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>16.35</td>\n",
              "      <td>23.29</td>\n",
              "      <td>109.00</td>\n",
              "      <td>840.4</td>\n",
              "      <td>0.09742</td>\n",
              "      <td>0.14970</td>\n",
              "      <td>0.18110</td>\n",
              "      <td>0.08773</td>\n",
              "      <td>0.2175</td>\n",
              "      <td>0.06218</td>\n",
              "      <td>...</td>\n",
              "      <td>19.380</td>\n",
              "      <td>31.03</td>\n",
              "      <td>129.30</td>\n",
              "      <td>1165.0</td>\n",
              "      <td>0.14150</td>\n",
              "      <td>0.46650</td>\n",
              "      <td>0.70870</td>\n",
              "      <td>0.22480</td>\n",
              "      <td>0.4824</td>\n",
              "      <td>0.09614</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>14.86</td>\n",
              "      <td>16.94</td>\n",
              "      <td>94.89</td>\n",
              "      <td>673.7</td>\n",
              "      <td>0.08924</td>\n",
              "      <td>0.07074</td>\n",
              "      <td>0.03346</td>\n",
              "      <td>0.02877</td>\n",
              "      <td>0.1573</td>\n",
              "      <td>0.05703</td>\n",
              "      <td>...</td>\n",
              "      <td>16.310</td>\n",
              "      <td>20.54</td>\n",
              "      <td>102.30</td>\n",
              "      <td>777.5</td>\n",
              "      <td>0.12180</td>\n",
              "      <td>0.15500</td>\n",
              "      <td>0.12200</td>\n",
              "      <td>0.07971</td>\n",
              "      <td>0.2525</td>\n",
              "      <td>0.06827</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>13.61</td>\n",
              "      <td>24.98</td>\n",
              "      <td>88.05</td>\n",
              "      <td>582.7</td>\n",
              "      <td>0.09488</td>\n",
              "      <td>0.08511</td>\n",
              "      <td>0.08625</td>\n",
              "      <td>0.04489</td>\n",
              "      <td>0.1609</td>\n",
              "      <td>0.05871</td>\n",
              "      <td>...</td>\n",
              "      <td>16.990</td>\n",
              "      <td>35.27</td>\n",
              "      <td>108.60</td>\n",
              "      <td>906.5</td>\n",
              "      <td>0.12650</td>\n",
              "      <td>0.19430</td>\n",
              "      <td>0.31690</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.2651</td>\n",
              "      <td>0.07397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>13.00</td>\n",
              "      <td>20.78</td>\n",
              "      <td>83.51</td>\n",
              "      <td>519.4</td>\n",
              "      <td>0.11350</td>\n",
              "      <td>0.07589</td>\n",
              "      <td>0.03136</td>\n",
              "      <td>0.02645</td>\n",
              "      <td>0.2540</td>\n",
              "      <td>0.06087</td>\n",
              "      <td>...</td>\n",
              "      <td>14.160</td>\n",
              "      <td>24.11</td>\n",
              "      <td>90.82</td>\n",
              "      <td>616.7</td>\n",
              "      <td>0.12970</td>\n",
              "      <td>0.11050</td>\n",
              "      <td>0.08112</td>\n",
              "      <td>0.06296</td>\n",
              "      <td>0.3196</td>\n",
              "      <td>0.06435</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>511</th>\n",
              "      <td>14.81</td>\n",
              "      <td>14.70</td>\n",
              "      <td>94.66</td>\n",
              "      <td>680.7</td>\n",
              "      <td>0.08472</td>\n",
              "      <td>0.05016</td>\n",
              "      <td>0.03416</td>\n",
              "      <td>0.02541</td>\n",
              "      <td>0.1659</td>\n",
              "      <td>0.05348</td>\n",
              "      <td>...</td>\n",
              "      <td>15.610</td>\n",
              "      <td>17.58</td>\n",
              "      <td>101.70</td>\n",
              "      <td>760.2</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.10110</td>\n",
              "      <td>0.11010</td>\n",
              "      <td>0.07955</td>\n",
              "      <td>0.2334</td>\n",
              "      <td>0.06142</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>9.72</td>\n",
              "      <td>18.22</td>\n",
              "      <td>60.73</td>\n",
              "      <td>288.1</td>\n",
              "      <td>0.06950</td>\n",
              "      <td>0.02344</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1653</td>\n",
              "      <td>0.06447</td>\n",
              "      <td>...</td>\n",
              "      <td>9.968</td>\n",
              "      <td>20.83</td>\n",
              "      <td>62.25</td>\n",
              "      <td>303.8</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.02729</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1909</td>\n",
              "      <td>0.06559</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>171 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf9ec9f9-ac01-46d2-acd7-059905bac69e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bf9ec9f9-ac01-46d2-acd7-059905bac69e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bf9ec9f9-ac01-46d2-acd7-059905bac69e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
              "460        17.08         27.15          111.20      930.9          0.09898   \n",
              "135        12.77         22.47           81.72      506.3          0.09055   \n",
              "62         14.25         22.15           96.42      645.7          0.10490   \n",
              "485        12.45         16.41           82.85      476.7          0.09514   \n",
              "370        16.35         23.29          109.00      840.4          0.09742   \n",
              "..           ...           ...             ...        ...              ...   \n",
              "434        14.86         16.94           94.89      673.7          0.08924   \n",
              "100        13.61         24.98           88.05      582.7          0.09488   \n",
              "150        13.00         20.78           83.51      519.4          0.11350   \n",
              "511        14.81         14.70           94.66      680.7          0.08472   \n",
              "192         9.72         18.22           60.73      288.1          0.06950   \n",
              "\n",
              "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
              "460           0.11100         0.10070              0.06431         0.1793   \n",
              "135           0.05761         0.04711              0.02704         0.1585   \n",
              "62            0.20080         0.21350              0.08653         0.1949   \n",
              "485           0.15110         0.15440              0.04846         0.2082   \n",
              "370           0.14970         0.18110              0.08773         0.2175   \n",
              "..                ...             ...                  ...            ...   \n",
              "434           0.07074         0.03346              0.02877         0.1573   \n",
              "100           0.08511         0.08625              0.04489         0.1609   \n",
              "150           0.07589         0.03136              0.02645         0.2540   \n",
              "511           0.05016         0.03416              0.02541         0.1659   \n",
              "192           0.02344         0.00000              0.00000         0.1653   \n",
              "\n",
              "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
              "460                 0.06281  ...        22.960          34.49   \n",
              "135                 0.06065  ...        14.490          33.37   \n",
              "62                  0.07292  ...        17.670          29.51   \n",
              "485                 0.07325  ...        13.780          21.03   \n",
              "370                 0.06218  ...        19.380          31.03   \n",
              "..                      ...  ...           ...            ...   \n",
              "434                 0.05703  ...        16.310          20.54   \n",
              "100                 0.05871  ...        16.990          35.27   \n",
              "150                 0.06087  ...        14.160          24.11   \n",
              "511                 0.05348  ...        15.610          17.58   \n",
              "192                 0.06447  ...         9.968          20.83   \n",
              "\n",
              "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
              "460           152.10      1648.0           0.16000            0.24440   \n",
              "135            92.04       653.6           0.14190            0.15230   \n",
              "62            119.10       959.5           0.16400            0.62470   \n",
              "485            97.82       580.6           0.11750            0.40610   \n",
              "370           129.30      1165.0           0.14150            0.46650   \n",
              "..               ...         ...               ...                ...   \n",
              "434           102.30       777.5           0.12180            0.15500   \n",
              "100           108.60       906.5           0.12650            0.19430   \n",
              "150            90.82       616.7           0.12970            0.11050   \n",
              "511           101.70       760.2           0.11390            0.10110   \n",
              "192            62.25       303.8           0.07117            0.02729   \n",
              "\n",
              "     worst concavity  worst concave points  worst symmetry  \\\n",
              "460          0.26390               0.15550          0.3010   \n",
              "135          0.21770               0.09331          0.2829   \n",
              "62           0.69220               0.17850          0.2844   \n",
              "485          0.48960               0.13420          0.3231   \n",
              "370          0.70870               0.22480          0.4824   \n",
              "..               ...                   ...             ...   \n",
              "434          0.12200               0.07971          0.2525   \n",
              "100          0.31690               0.11840          0.2651   \n",
              "150          0.08112               0.06296          0.3196   \n",
              "511          0.11010               0.07955          0.2334   \n",
              "192          0.00000               0.00000          0.1909   \n",
              "\n",
              "     worst fractal dimension  \n",
              "460                  0.09060  \n",
              "135                  0.08067  \n",
              "62                   0.11320  \n",
              "485                  0.10340  \n",
              "370                  0.09614  \n",
              "..                       ...  \n",
              "434                  0.06827  \n",
              "100                  0.07397  \n",
              "150                  0.06435  \n",
              "511                  0.06142  \n",
              "192                  0.06559  \n",
              "\n",
              "[171 rows x 30 columns]"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "joZSDcGzIlo4",
        "outputId": "004ca059-526b-4d73-c50b-5380f6019558"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7c1bed8f-c098-42f4-b7c5-50cd90c8e851\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>511</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>171 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c1bed8f-c098-42f4-b7c5-50cd90c8e851')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c1bed8f-c098-42f4-b7c5-50cd90c8e851 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c1bed8f-c098-42f4-b7c5-50cd90c8e851');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     target\n",
              "460       0\n",
              "135       0\n",
              "62        0\n",
              "485       1\n",
              "370       0\n",
              "..      ...\n",
              "434       1\n",
              "100       0\n",
              "150       1\n",
              "511       1\n",
              "192       1\n",
              "\n",
              "[171 rows x 1 columns]"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elJ87AHnKp0t"
      },
      "source": [
        "#### XGBoost for Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hX6uFoxntutW"
      },
      "source": [
        "Set up the XGBoost model. Name it as `classifier_XGB`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apugvOWmtt8G",
        "outputId": "c114e71c-060d-4b81-d856-f4e16f5638df"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=0)"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "classifier_XGB = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0,max_depth=1, random_state=0)\n",
        "classifier_XGB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV3-d1_6t3cf"
      },
      "source": [
        "Fit the XGBoost model using the input `X_train` and output `y_train`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZi_gQXvt9zz",
        "outputId": "e7b37997-281c-4412-c26b-0624a22269d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_gb.py:494: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "GradientBoostingClassifier(learning_rate=1.0, max_depth=1, random_state=0)"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_XGB.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBdQJKdot7A_"
      },
      "source": [
        "Make predictions on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LVRfYuUt-Nv",
        "outputId": "b1d744b7-0925-445d-d464-6f7aada70222"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1,\n",
              "       1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
              "       1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
              "       0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0,\n",
              "       0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
              "       1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0])"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "XGB_pred = classifier_XGB.predict(X_test)\n",
        "XGB_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iIQhfBLiK0Zn"
      },
      "source": [
        "#### Support Vector Machine for Binary Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pp-UWCS8uBY0"
      },
      "source": [
        "Set up the SVM model. Name it as `classifier_SVM`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b-RYcxNYuQRJ",
        "outputId": "af150a16-6fc7-438f-d4f2-3ebddff71109"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SVC(gamma='auto')"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.svm import SVC\n",
        "classifier_SVM = SVC(gamma='auto')\n",
        "classifier_SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QWx1-qp-uBjO"
      },
      "source": [
        "Fit the SVM model using the input `X_train` and output `y_train`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAIa6UZsuQx5",
        "outputId": "9cd47209-f6f8-4453-88e2-f160f43cdccd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SVC(gamma='auto')"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "classifier_SVM.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIcdWkkyuBue"
      },
      "source": [
        "Make predictions on test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6e-BwZvnuROf",
        "outputId": "607a7f32-0c06-435b-ed9d-90942c093121"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "SVM_pred = classifier_SVM.predict(X_test)\n",
        "SVM_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1fxh88pvQzj"
      },
      "source": [
        "#### Performance Assessment\n",
        "\n",
        "*   Accuracy\n",
        "*   Sensitivity\n",
        "*   Specificity\n",
        "*   AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlOUmIEUz2z0"
      },
      "source": [
        "First, let's compute the confusion matrix for predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oDaIRwwW4BZi"
      },
      "source": [
        "For example: for Naive Bayes's prediction, we have:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqsmOh8fz9Gn",
        "outputId": "2ab94478-5e06-4ceb-d426-5e84736da852"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Confusion Matrix for Naive Bayes: \n",
            " [[ 57   7]\n",
            " [  6 101]]\n",
            "Accuracy for Naive Bayes:  0.9239766081871345\n",
            "Sensitivity for Naive Bayes:  0.890625\n",
            "Specificity for Naive Bayes:  0.9439252336448598\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "#Compute the confusion matrix\n",
        "cmNB = confusion_matrix(y_test,NB_pred)\n",
        "print('Confusion Matrix for Naive Bayes: \\n', cmNB)\n",
        "#Compute total test cases\n",
        "totalNB=sum(sum(cmNB))\n",
        "#####from confusion matrix calculate accuracy\n",
        "accuracyNB=(cmNB[0,0]+cmNB[1,1])/totalNB\n",
        "print ('Accuracy for Naive Bayes: ', accuracyNB)\n",
        "\n",
        "sensitivityNB = cmNB[0,0]/(cmNB[0,0]+cmNB[0,1])\n",
        "print('Sensitivity for Naive Bayes: ', sensitivityNB)\n",
        "\n",
        "specificityNB = cmNB[1,1]/(cmNB[1,0]+cmNB[1,1])\n",
        "print('Specificity for Naive Bayes: ', specificityNB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Ekaseon1kDu"
      },
      "source": [
        "Then, we compute the AUC. We use the `roc_auc_score` from `sklearn`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8eqsAS210uf",
        "outputId": "971a77a0-ccbe-4023-dadd-c481cc0fba2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AUC for Naive Bayes:  0.9767815420560748\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "#We first compute the probability output from the Naive Bayes classifier\n",
        "NB_prob = classifier_NB.predict_proba(X_test)\n",
        "\n",
        "#We compute the AUC score\n",
        "aucNB = roc_auc_score(y_test,NB_prob[:,1])\n",
        "print('AUC for Naive Bayes: ', aucNB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KX7SnsiDWQ43"
      },
      "source": [
        "## Unsupervised Learning - Clustering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ORhQRZbv7Cwc"
      },
      "source": [
        "#### Dataset Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5MeAadHWQ44"
      },
      "source": [
        "Lastly we want to consider an unsupervised learning problem, where we don't actually have an outcome at all, or our data is \"unlabeled.\" Instead of predicting something we just want to find patterns and structure in our data.\n",
        "\n",
        "Our data can be unlabeled for two reasons:\n",
        "\n",
        "• First, maybe our data does not have well-defined groupings. An example might be a company's customers: there are not clear and distinct groups that we can put people in. \n",
        "\n",
        "• Second, maybe the label of our data is missing. Suppose you are a wine vendor and you ordered three types of wine from your supplier. When you receive your wine shipment, however, you realize that the labels were not put on. You may want to learn about how the different wine bottles are related to one another to make an educated guess on which is what wine type.\n",
        "\n",
        "Our example below falls in this second case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL-PO7LrWQ45"
      },
      "outputs": [],
      "source": [
        "wine = datasets.load_wine(as_frame=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_SCElBgWQ45",
        "outputId": "2da23c14-9dc9-4f02-c95e-1c6a13c61be5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n",
              "       'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n",
              "       'proanthocyanins', 'color_intensity', 'hue',\n",
              "       'od280/od315_of_diluted_wines', 'proline'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 169,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wine.data.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "4l4wK5z5YUC6",
        "outputId": "ac30d0dd-42ee-4cee-b958-aaf136904852"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c6e1e5b2-5f35-4ca5-9d88-01d41f37c0fa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 13 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6e1e5b2-5f35-4ca5-9d88-01d41f37c0fa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6e1e5b2-5f35-4ca5-9d88-01d41f37c0fa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6e1e5b2-5f35-4ca5-9d88-01d41f37c0fa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "..       ...         ...   ...                ...        ...            ...   \n",
              "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
              "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
              "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
              "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
              "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
              "\n",
              "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0          3.06                  0.28             2.29             5.64  1.04   \n",
              "1          2.76                  0.26             1.28             4.38  1.05   \n",
              "2          3.24                  0.30             2.81             5.68  1.03   \n",
              "3          3.49                  0.24             2.18             7.80  0.86   \n",
              "4          2.69                  0.39             1.82             4.32  1.04   \n",
              "..          ...                   ...              ...              ...   ...   \n",
              "173        0.61                  0.52             1.06             7.70  0.64   \n",
              "174        0.75                  0.43             1.41             7.30  0.70   \n",
              "175        0.69                  0.43             1.35            10.20  0.59   \n",
              "176        0.68                  0.53             1.46             9.30  0.60   \n",
              "177        0.76                  0.56             1.35             9.20  0.61   \n",
              "\n",
              "     od280/od315_of_diluted_wines  proline  \n",
              "0                            3.92   1065.0  \n",
              "1                            3.40   1050.0  \n",
              "2                            3.17   1185.0  \n",
              "3                            3.45   1480.0  \n",
              "4                            2.93    735.0  \n",
              "..                            ...      ...  \n",
              "173                          1.74    740.0  \n",
              "174                          1.56    750.0  \n",
              "175                          1.56    835.0  \n",
              "176                          1.62    840.0  \n",
              "177                          1.60    560.0  \n",
              "\n",
              "[178 rows x 13 columns]"
            ]
          },
          "execution_count": 170,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wine.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6e5r4Un57I2-"
      },
      "source": [
        "#### Initialize the dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzcQqq5r-QNs"
      },
      "source": [
        "Initialize the dataset as `X`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ffGyVj1w-S7v"
      },
      "outputs": [],
      "source": [
        "X= wine.data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0yRsiFz-_K0"
      },
      "source": [
        "#### Clustering using K-Means algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0gyXR2eUBcfO"
      },
      "source": [
        "##### Intialize the K-Means Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5u22oqn0-IRO"
      },
      "source": [
        "The K-Mean algorithm is included in the Scikit-leanr library. Define the number of clusters by `n_clusters` and random initialization state."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kN01QBb4-Pdt",
        "outputId": "bee71b5a-38c7-4edd-d72c-045d5c1333ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KMeans(n_clusters=3, random_state=0)"
            ]
          },
          "execution_count": 172,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.cluster import KMeans\n",
        "#Here we set n=3 in this workshop\n",
        "cluster_KMeans = KMeans(n_clusters =3, random_state=0)\n",
        "cluster_KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGumzwgl-1xt"
      },
      "source": [
        "##### Fit and predict using K-Mean algorithm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8DJRbWuJ_cBG"
      },
      "source": [
        "Fit the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_ch__Ce-1Gx",
        "outputId": "63a9b541-9617-4f37-d5d1-7bde072c6da5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "KMeans(n_clusters=3, random_state=0)"
            ]
          },
          "execution_count": 173,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cluster_KMeans.fit(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icvv8h9z_Oh8"
      },
      "source": [
        "Prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weBqEwxW_hoE",
        "outputId": "54343e0c-2609-4edb-8a6a-28e6810c4575"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "       1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 2, 0, 2, 2, 0,\n",
              "       2, 2, 0, 0, 0, 2, 2, 1, 0, 2, 2, 2, 0, 2, 2, 0, 0, 2, 2, 2, 2, 2,\n",
              "       0, 0, 2, 2, 2, 2, 2, 0, 0, 2, 0, 2, 0, 2, 2, 2, 0, 2, 2, 2, 2, 0,\n",
              "       2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 0, 2, 2, 2, 2, 2, 2, 2, 2, 2, 0, 2,\n",
              "       2, 0, 0, 0, 0, 2, 2, 2, 0, 0, 2, 2, 0, 0, 2, 0, 0, 2, 2, 2, 2, 0,\n",
              "       0, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 2, 0, 0, 0, 0, 2, 2, 0, 0, 0, 0,\n",
              "       0, 2], dtype=int32)"
            ]
          },
          "execution_count": 174,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cluster_labels = cluster_KMeans.predict(X)\n",
        "cluster_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrzc0S1G_mwV"
      },
      "source": [
        "Each data point in `X` is now assigned with a label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "tuEPjAGK_rov",
        "outputId": "6ecadd91-4609-4c3b-807b-8f54ecc0f738"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-43d064ce-a260-433f-9500-d460701c6dfa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>alcohol</th>\n",
              "      <th>malic_acid</th>\n",
              "      <th>ash</th>\n",
              "      <th>alcalinity_of_ash</th>\n",
              "      <th>magnesium</th>\n",
              "      <th>total_phenols</th>\n",
              "      <th>flavanoids</th>\n",
              "      <th>nonflavanoid_phenols</th>\n",
              "      <th>proanthocyanins</th>\n",
              "      <th>color_intensity</th>\n",
              "      <th>hue</th>\n",
              "      <th>od280/od315_of_diluted_wines</th>\n",
              "      <th>proline</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>14.23</td>\n",
              "      <td>1.71</td>\n",
              "      <td>2.43</td>\n",
              "      <td>15.6</td>\n",
              "      <td>127.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.06</td>\n",
              "      <td>0.28</td>\n",
              "      <td>2.29</td>\n",
              "      <td>5.64</td>\n",
              "      <td>1.04</td>\n",
              "      <td>3.92</td>\n",
              "      <td>1065.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>13.20</td>\n",
              "      <td>1.78</td>\n",
              "      <td>2.14</td>\n",
              "      <td>11.2</td>\n",
              "      <td>100.0</td>\n",
              "      <td>2.65</td>\n",
              "      <td>2.76</td>\n",
              "      <td>0.26</td>\n",
              "      <td>1.28</td>\n",
              "      <td>4.38</td>\n",
              "      <td>1.05</td>\n",
              "      <td>3.40</td>\n",
              "      <td>1050.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13.16</td>\n",
              "      <td>2.36</td>\n",
              "      <td>2.67</td>\n",
              "      <td>18.6</td>\n",
              "      <td>101.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>3.24</td>\n",
              "      <td>0.30</td>\n",
              "      <td>2.81</td>\n",
              "      <td>5.68</td>\n",
              "      <td>1.03</td>\n",
              "      <td>3.17</td>\n",
              "      <td>1185.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>14.37</td>\n",
              "      <td>1.95</td>\n",
              "      <td>2.50</td>\n",
              "      <td>16.8</td>\n",
              "      <td>113.0</td>\n",
              "      <td>3.85</td>\n",
              "      <td>3.49</td>\n",
              "      <td>0.24</td>\n",
              "      <td>2.18</td>\n",
              "      <td>7.80</td>\n",
              "      <td>0.86</td>\n",
              "      <td>3.45</td>\n",
              "      <td>1480.0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>13.24</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.87</td>\n",
              "      <td>21.0</td>\n",
              "      <td>118.0</td>\n",
              "      <td>2.80</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0.39</td>\n",
              "      <td>1.82</td>\n",
              "      <td>4.32</td>\n",
              "      <td>1.04</td>\n",
              "      <td>2.93</td>\n",
              "      <td>735.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>13.71</td>\n",
              "      <td>5.65</td>\n",
              "      <td>2.45</td>\n",
              "      <td>20.5</td>\n",
              "      <td>95.0</td>\n",
              "      <td>1.68</td>\n",
              "      <td>0.61</td>\n",
              "      <td>0.52</td>\n",
              "      <td>1.06</td>\n",
              "      <td>7.70</td>\n",
              "      <td>0.64</td>\n",
              "      <td>1.74</td>\n",
              "      <td>740.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>13.40</td>\n",
              "      <td>3.91</td>\n",
              "      <td>2.48</td>\n",
              "      <td>23.0</td>\n",
              "      <td>102.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.41</td>\n",
              "      <td>7.30</td>\n",
              "      <td>0.70</td>\n",
              "      <td>1.56</td>\n",
              "      <td>750.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>13.27</td>\n",
              "      <td>4.28</td>\n",
              "      <td>2.26</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.59</td>\n",
              "      <td>0.69</td>\n",
              "      <td>0.43</td>\n",
              "      <td>1.35</td>\n",
              "      <td>10.20</td>\n",
              "      <td>0.59</td>\n",
              "      <td>1.56</td>\n",
              "      <td>835.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>13.17</td>\n",
              "      <td>2.59</td>\n",
              "      <td>2.37</td>\n",
              "      <td>20.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1.65</td>\n",
              "      <td>0.68</td>\n",
              "      <td>0.53</td>\n",
              "      <td>1.46</td>\n",
              "      <td>9.30</td>\n",
              "      <td>0.60</td>\n",
              "      <td>1.62</td>\n",
              "      <td>840.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>14.13</td>\n",
              "      <td>4.10</td>\n",
              "      <td>2.74</td>\n",
              "      <td>24.5</td>\n",
              "      <td>96.0</td>\n",
              "      <td>2.05</td>\n",
              "      <td>0.76</td>\n",
              "      <td>0.56</td>\n",
              "      <td>1.35</td>\n",
              "      <td>9.20</td>\n",
              "      <td>0.61</td>\n",
              "      <td>1.60</td>\n",
              "      <td>560.0</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>178 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43d064ce-a260-433f-9500-d460701c6dfa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-43d064ce-a260-433f-9500-d460701c6dfa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-43d064ce-a260-433f-9500-d460701c6dfa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "     alcohol  malic_acid   ash  alcalinity_of_ash  magnesium  total_phenols  \\\n",
              "0      14.23        1.71  2.43               15.6      127.0           2.80   \n",
              "1      13.20        1.78  2.14               11.2      100.0           2.65   \n",
              "2      13.16        2.36  2.67               18.6      101.0           2.80   \n",
              "3      14.37        1.95  2.50               16.8      113.0           3.85   \n",
              "4      13.24        2.59  2.87               21.0      118.0           2.80   \n",
              "..       ...         ...   ...                ...        ...            ...   \n",
              "173    13.71        5.65  2.45               20.5       95.0           1.68   \n",
              "174    13.40        3.91  2.48               23.0      102.0           1.80   \n",
              "175    13.27        4.28  2.26               20.0      120.0           1.59   \n",
              "176    13.17        2.59  2.37               20.0      120.0           1.65   \n",
              "177    14.13        4.10  2.74               24.5       96.0           2.05   \n",
              "\n",
              "     flavanoids  nonflavanoid_phenols  proanthocyanins  color_intensity   hue  \\\n",
              "0          3.06                  0.28             2.29             5.64  1.04   \n",
              "1          2.76                  0.26             1.28             4.38  1.05   \n",
              "2          3.24                  0.30             2.81             5.68  1.03   \n",
              "3          3.49                  0.24             2.18             7.80  0.86   \n",
              "4          2.69                  0.39             1.82             4.32  1.04   \n",
              "..          ...                   ...              ...              ...   ...   \n",
              "173        0.61                  0.52             1.06             7.70  0.64   \n",
              "174        0.75                  0.43             1.41             7.30  0.70   \n",
              "175        0.69                  0.43             1.35            10.20  0.59   \n",
              "176        0.68                  0.53             1.46             9.30  0.60   \n",
              "177        0.76                  0.56             1.35             9.20  0.61   \n",
              "\n",
              "     od280/od315_of_diluted_wines  proline  label  \n",
              "0                            3.92   1065.0      1  \n",
              "1                            3.40   1050.0      1  \n",
              "2                            3.17   1185.0      1  \n",
              "3                            3.45   1480.0      1  \n",
              "4                            2.93    735.0      0  \n",
              "..                            ...      ...    ...  \n",
              "173                          1.74    740.0      0  \n",
              "174                          1.56    750.0      0  \n",
              "175                          1.56    835.0      0  \n",
              "176                          1.62    840.0      0  \n",
              "177                          1.60    560.0      2  \n",
              "\n",
              "[178 rows x 14 columns]"
            ]
          },
          "execution_count": 175,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X['label']=cluster_labels\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nEL2KmZH1e3y"
      },
      "source": [
        "Compute inner cluster distances (Euclidean distances) within all clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jLcypDGJ1kSZ",
        "outputId": "502808f9-3700-4382-ca85-d6dc43cd558c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2370689.686782969"
            ]
          },
          "execution_count": 176,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cluster_KMeans.inertia_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2VQS91NBUJN"
      },
      "source": [
        "##### Find the BEST k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vcA2Ed-z1toI"
      },
      "source": [
        "Now, let's try different numbers of k to see how cluster centers change"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yVW1JGmP1s0P"
      },
      "outputs": [],
      "source": [
        "#Store the sum of inner cluster distances in a list and name is as dist\n",
        "dist=[]\n",
        "\n",
        "for i in range(1,10):\n",
        "  #Run k-mean clustering with i centers\n",
        "  cluster_KMeans = KMeans(n_clusters =i+1, random_state=0)\n",
        "  cluster_KMeans.fit(X)\n",
        "  #Store the summed inner cluster distances into the list namely 'dist'\n",
        "  dist.append(cluster_KMeans.inertia_)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8aRiilxo8bGJ"
      },
      "source": [
        "Display the inner cluster distances for all k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPTDSExDBY0v",
        "outputId": "38f29446-7c42-426e-868c-1b09a61bfca8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[4543877.621627203,\n",
              " 2370689.686782969,\n",
              " 1331920.430684771,\n",
              " 916415.1871539169,\n",
              " 647362.0020260848,\n",
              " 412137.5091004584,\n",
              " 324553.044355034,\n",
              " 270954.9292415376,\n",
              " 217887.37856033302]"
            ]
          },
          "execution_count": 178,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dist"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNud2CgJ8hYy"
      },
      "source": [
        "Now, let's use `matplotlib` library to visualize the inner cluster distances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyljMec38NjX"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MexfgXCq8o1Y"
      },
      "source": [
        "We can plot the inner cluster distance curve and use Elbow's method to seek for optimal k"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 276
        },
        "id": "a8w02SxZ8P4j",
        "outputId": "94fb1a0f-6b8d-4085-9799-06c4695687e2"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(dist)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTHEycO9LFI2"
      },
      "source": [
        "#### Compute the Silhouette Coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgQFzE3ELJC1"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import silhouette_score\n",
        "#Store the Silhouette Coefficient in a list and name is as distS\n",
        "distS=[]\n",
        "\n",
        "for i in range(1,20):\n",
        "  #Run k-mean clustering with i centers\n",
        "  cluster_KMeans = KMeans(n_clusters =i+1, random_state=0)\n",
        "  cluster_KMeans.fit(X)\n",
        "\n",
        "  #Obtain the clustering labels\n",
        "  cluster_labels = cluster_KMeans.predict(X)\n",
        "  \n",
        "  #Compute the \n",
        "  silhouette_avg = silhouette_score(X, cluster_labels)\n",
        "\n",
        "  #Store the Silhouette Coefficient into the list namely 'distS'\n",
        "  distS.append(silhouette_avg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "gPGcdFT_MjVk",
        "outputId": "1ffeed73-59c8-4a70-f8d2-bc79eb45daea"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(distS)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "OHoqoS6zCuES",
        "iIQhfBLiK0Zn",
        "CjRNjZ5WK4pO",
        "KX7SnsiDWQ43",
        "6e5r4Un57I2-",
        "QTHEycO9LFI2"
      ],
      "name": "Python_Workshop_Session_3_Applied_Machine_Learning.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
